{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# fix seeds\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 2019\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.enabled = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_class = pd.read_csv('../data/class.csv')\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_train = df_train[['img_file', 'class']]\n",
    "df_train.replace(196, 0, inplace=True)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train['img_file'], df_train['class'], stratify=df_train['class'], test_size=0.2, random_state=SEED)\n",
    "\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values\n",
    "\n",
    "TRAIN_DATA_PATH = '../data/train_crop/'\n",
    "TEST_DATA_PATH = '../data/test_crop/'\n",
    "\n",
    "class TrainImages(Dataset):\n",
    "    def __init__(self, images, labels, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TRAIN_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "class TestImages(Dataset):\n",
    "    def __init__(self, images, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TEST_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_dataset = TrainImages(images=X_train, labels=y_train, mode='train', transforms=transform)\n",
    "val_dataset = TrainImages(images=X_val, labels=y_val, mode='val', transforms=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}\n",
    "\n",
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, device, PATH, epochs=20):\n",
    "    start = time.time()\n",
    "\n",
    "    num_classes = 196\n",
    "\n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(\"EPOCH {} / {}: \".format(epoch+1, epochs))\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        epoch_loss = 0.0\n",
    "        phase = 'train'\n",
    "\n",
    "        for batch_index, (batch_inputs, batch_labels) in enumerate(dataloaders[phase]):\n",
    "            batch_inputs = batch_inputs.cuda()\n",
    "            batch_labels = batch_labels.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            batch_loss = criterion(outputs, batch_labels)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item() * batch_inputs.size(0)\n",
    "            if batch_index % 5 == 0:\n",
    "                print(\"EPOCH {} BATCH {}: training batch loss: {}\".format(epoch+1, batch_index+1, batch_loss.item()))\n",
    "\n",
    "            if batch_index % 10 == 0:\n",
    "                phase = 'val'\n",
    "                val_preds = np.zeros((dataset_sizes['val'], 1))\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for val_batch_index, (val_batch_inputs, val_batch_labels) in enumerate(dataloaders[phase]):\n",
    "\n",
    "                        val_batch_inputs = val_batch_inputs.cuda()\n",
    "                        val_batch_labels = val_batch_labels.cuda()\n",
    "\n",
    "                        val_outputs = model(val_batch_inputs).detach()\n",
    "                        _, val_batch_preds = torch.max(val_outputs, 1)\n",
    "                        val_batch_loss = criterion(val_outputs, val_batch_labels)\n",
    "                        val_preds[val_batch_index * batch_size: (val_batch_index+1) * batch_size] = val_batch_preds.cpu().view(-1, 1).numpy()\n",
    "                        val_loss += val_batch_loss.item() * val_batch_inputs.size(0)\n",
    "\n",
    "                    val_score = f1_score(y_val, val_preds, average='micro')\n",
    "                    print()\n",
    "                    print(\">>>>>>  EPOCH {} BATCH {}: validation score {}\".format(epoch+1, batch_index+1, val_score))\n",
    "                    print()\n",
    "                    if val_score > best_f1:\n",
    "                        best_f1 = val_score\n",
    "                        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "                        torch.save(model.state_dict(), '../{}/best_model_{}_{}.pt'.format(PATH, epoch+1, batch_index+1))\n",
    "\n",
    "                phase = 'train'\n",
    "                model.train()\n",
    "\n",
    "        epoch_loss = epoch_loss / dataset_sizes['train']\n",
    "        print(\"EPOCH {}: EPOCH_LOSS: {}\".format(epoch+1, epoch_loss))\n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(\"Training COMPLETED: {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"BEST VALIDATION F1: {:4f}\".format(best_f1))\n",
    "\n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model\n",
    "\n",
    "\n",
    "# model_res.to(device)\n",
    "# optimizer = optim.Adam(model_res.parameters(), lr=0.000001)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# model_res = train_model(model=model_res, dataloaders=dataloaders, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=100, PATH='model/ten_crop/fine_tune')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('../model/ten_crop/tune2/best_model_8_91.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 / 10: \n",
      "----------\n",
      "EPOCH 1 BATCH 1: training batch loss: 0.08228839188814163\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 1: validation score 0.8928928928928928\n",
      "\n",
      "EPOCH 1 BATCH 6: training batch loss: 0.05276988819241524\n",
      "EPOCH 1 BATCH 11: training batch loss: 0.046658001840114594\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 11: validation score 0.9054054054054054\n",
      "\n",
      "EPOCH 1 BATCH 16: training batch loss: 0.041372254490852356\n",
      "EPOCH 1 BATCH 21: training batch loss: 0.06828468292951584\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 21: validation score 0.9074074074074074\n",
      "\n",
      "EPOCH 1 BATCH 26: training batch loss: 0.03543846309185028\n",
      "EPOCH 1 BATCH 31: training batch loss: 0.07012776285409927\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 31: validation score 0.9054054054054054\n",
      "\n",
      "EPOCH 1 BATCH 36: training batch loss: 0.052548304200172424\n",
      "EPOCH 1 BATCH 41: training batch loss: 0.04351343214511871\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 41: validation score 0.9119119119119119\n",
      "\n",
      "EPOCH 1 BATCH 46: training batch loss: 0.04557860642671585\n",
      "EPOCH 1 BATCH 51: training batch loss: 0.021260283887386322\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 51: validation score 0.9109109109109109\n",
      "\n",
      "EPOCH 1 BATCH 56: training batch loss: 0.0739145427942276\n",
      "EPOCH 1 BATCH 61: training batch loss: 0.059288229793310165\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 61: validation score 0.9099099099099099\n",
      "\n",
      "EPOCH 1 BATCH 66: training batch loss: 0.029003895819187164\n",
      "EPOCH 1 BATCH 71: training batch loss: 0.06553249061107635\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 71: validation score 0.9124124124124123\n",
      "\n",
      "EPOCH 1 BATCH 76: training batch loss: 0.03140944242477417\n",
      "EPOCH 1 BATCH 81: training batch loss: 0.05591277778148651\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 81: validation score 0.9124124124124123\n",
      "\n",
      "EPOCH 1 BATCH 86: training batch loss: 0.06842140108346939\n",
      "EPOCH 1 BATCH 91: training batch loss: 0.0692153126001358\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 91: validation score 0.9109109109109109\n",
      "\n",
      "EPOCH 1 BATCH 96: training batch loss: 0.04923643171787262\n",
      "EPOCH 1 BATCH 101: training batch loss: 0.021518416702747345\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 101: validation score 0.9104104104104104\n",
      "\n",
      "EPOCH 1 BATCH 106: training batch loss: 0.02361314371228218\n",
      "EPOCH 1 BATCH 111: training batch loss: 0.025590285658836365\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 111: validation score 0.9104104104104104\n",
      "\n",
      "EPOCH 1 BATCH 116: training batch loss: 0.03462037444114685\n",
      "EPOCH 1 BATCH 121: training batch loss: 0.03736690804362297\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 121: validation score 0.9114114114114115\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [13:51<2:04:43, 831.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: EPOCH_LOSS: 0.0478987575241097\n",
      "EPOCH 2 / 10: \n",
      "----------\n",
      "EPOCH 2 BATCH 1: training batch loss: 0.04848185181617737\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 1: validation score 0.9134134134134134\n",
      "\n",
      "EPOCH 2 BATCH 6: training batch loss: 0.06022125482559204\n",
      "EPOCH 2 BATCH 11: training batch loss: 0.030838459730148315\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 11: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 2 BATCH 16: training batch loss: 0.04105565696954727\n",
      "EPOCH 2 BATCH 21: training batch loss: 0.04485087841749191\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 21: validation score 0.913913913913914\n",
      "\n",
      "EPOCH 2 BATCH 26: training batch loss: 0.04826447367668152\n",
      "EPOCH 2 BATCH 31: training batch loss: 0.028922419995069504\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 31: validation score 0.9119119119119119\n",
      "\n",
      "EPOCH 2 BATCH 36: training batch loss: 0.013672314584255219\n",
      "EPOCH 2 BATCH 41: training batch loss: 0.022655636072158813\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 41: validation score 0.9134134134134134\n",
      "\n",
      "EPOCH 2 BATCH 46: training batch loss: 0.02171725034713745\n",
      "EPOCH 2 BATCH 51: training batch loss: 0.022292811423540115\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 51: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 2 BATCH 56: training batch loss: 0.026677265763282776\n",
      "EPOCH 2 BATCH 61: training batch loss: 0.020684421062469482\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 61: validation score 0.9144144144144143\n",
      "\n",
      "EPOCH 2 BATCH 66: training batch loss: 0.034441038966178894\n",
      "EPOCH 2 BATCH 71: training batch loss: 0.0491957925260067\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 71: validation score 0.9129129129129129\n",
      "\n",
      "EPOCH 2 BATCH 76: training batch loss: 0.02722390741109848\n",
      "EPOCH 2 BATCH 81: training batch loss: 0.031765617430210114\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 81: validation score 0.914914914914915\n",
      "\n",
      "EPOCH 2 BATCH 86: training batch loss: 0.024216562509536743\n",
      "EPOCH 2 BATCH 91: training batch loss: 0.025797538459300995\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 91: validation score 0.9174174174174174\n",
      "\n",
      "EPOCH 2 BATCH 96: training batch loss: 0.023627273738384247\n",
      "EPOCH 2 BATCH 101: training batch loss: 0.01752973347902298\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 101: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 2 BATCH 106: training batch loss: 0.014686010777950287\n",
      "EPOCH 2 BATCH 111: training batch loss: 0.03669712319970131\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 111: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 2 BATCH 116: training batch loss: 0.030342623591423035\n",
      "EPOCH 2 BATCH 121: training batch loss: 0.05242764204740524\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 121: validation score 0.9124124124124123\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [27:42<1:50:49, 831.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: EPOCH_LOSS: 0.030731403333199275\n",
      "EPOCH 3 / 10: \n",
      "----------\n",
      "EPOCH 3 BATCH 1: training batch loss: 0.025953002274036407\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 1: validation score 0.9144144144144143\n",
      "\n",
      "EPOCH 3 BATCH 6: training batch loss: 0.017689935863018036\n",
      "EPOCH 3 BATCH 11: training batch loss: 0.011263072490692139\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 11: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 3 BATCH 16: training batch loss: 0.034100234508514404\n",
      "EPOCH 3 BATCH 21: training batch loss: 0.01744462549686432\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 21: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 3 BATCH 26: training batch loss: 0.03080083429813385\n",
      "EPOCH 3 BATCH 31: training batch loss: 0.03105621039867401\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 31: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 3 BATCH 36: training batch loss: 0.029327332973480225\n",
      "EPOCH 3 BATCH 41: training batch loss: 0.012172400951385498\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 41: validation score 0.914914914914915\n",
      "\n",
      "EPOCH 3 BATCH 46: training batch loss: 0.02569584548473358\n",
      "EPOCH 3 BATCH 51: training batch loss: 0.027973853051662445\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 51: validation score 0.9174174174174174\n",
      "\n",
      "EPOCH 3 BATCH 56: training batch loss: 0.033146932721138\n",
      "EPOCH 3 BATCH 61: training batch loss: 0.01668514311313629\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 61: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 3 BATCH 66: training batch loss: 0.017162609845399857\n",
      "EPOCH 3 BATCH 71: training batch loss: 0.029891349375247955\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 71: validation score 0.9154154154154154\n",
      "\n",
      "EPOCH 3 BATCH 76: training batch loss: 0.03025367110967636\n",
      "EPOCH 3 BATCH 81: training batch loss: 0.05592313036322594\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 81: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 3 BATCH 86: training batch loss: 0.029380585998296738\n",
      "EPOCH 3 BATCH 91: training batch loss: 0.02333264797925949\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 91: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 3 BATCH 96: training batch loss: 0.019729167222976685\n",
      "EPOCH 3 BATCH 101: training batch loss: 0.019636370241642\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 101: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 3 BATCH 106: training batch loss: 0.022619329392910004\n",
      "EPOCH 3 BATCH 111: training batch loss: 0.01703295111656189\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 111: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 3 BATCH 116: training batch loss: 0.009751372039318085\n",
      "EPOCH 3 BATCH 121: training batch loss: 0.012557074427604675\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 121: validation score 0.9194194194194194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [41:32<1:36:56, 830.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3: EPOCH_LOSS: 0.02337380858684505\n",
      "EPOCH 4 / 10: \n",
      "----------\n",
      "EPOCH 4 BATCH 1: training batch loss: 0.024378828704357147\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 1: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 4 BATCH 6: training batch loss: 0.020179763436317444\n",
      "EPOCH 4 BATCH 11: training batch loss: 0.019267529249191284\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 11: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 4 BATCH 16: training batch loss: 0.019304849207401276\n",
      "EPOCH 4 BATCH 21: training batch loss: 0.015996553003787994\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 21: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 4 BATCH 26: training batch loss: 0.014765970408916473\n",
      "EPOCH 4 BATCH 31: training batch loss: 0.020187579095363617\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 31: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 4 BATCH 36: training batch loss: 0.024215087294578552\n",
      "EPOCH 4 BATCH 41: training batch loss: 0.024176180362701416\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 41: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 4 BATCH 46: training batch loss: 0.02856183797121048\n",
      "EPOCH 4 BATCH 51: training batch loss: 0.013851575553417206\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 51: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 4 BATCH 56: training batch loss: 0.021127521991729736\n",
      "EPOCH 4 BATCH 61: training batch loss: 0.01788351684808731\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 61: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 4 BATCH 66: training batch loss: 0.018482014536857605\n",
      "EPOCH 4 BATCH 71: training batch loss: 0.008563242852687836\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 71: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 4 BATCH 76: training batch loss: 0.01545008271932602\n",
      "EPOCH 4 BATCH 81: training batch loss: 0.011293016374111176\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 81: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 4 BATCH 86: training batch loss: 0.03327542543411255\n",
      "EPOCH 4 BATCH 91: training batch loss: 0.014661043882369995\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-ff41890511fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model_res = train_model(model=model_res, dataloaders=dataloaders, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=10, \n\u001b[0;32m----> 6\u001b[0;31m         PATH='model/ten_crop/lr_00001')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a593b4ddb92d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, criterion, optimizer, device, PATH, epochs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mval_batch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                         \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mval_batch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_res.to(device)\n",
    "optimizer = optim.Adam(model_res.parameters(), lr=0.00001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_res = train_model(model=model_res, dataloaders=dataladers, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=10, \n",
    "        PATH='model/ten_crop/lr_000001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 / 10: \n",
      "----------\n",
      "EPOCH 1 BATCH 1: training batch loss: 0.03172450512647629\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 1: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 1 BATCH 6: training batch loss: 0.014794662594795227\n",
      "EPOCH 1 BATCH 11: training batch loss: 0.009986512362957\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 11: validation score 0.91991991991992\n",
      "\n",
      "EPOCH 1 BATCH 16: training batch loss: 0.04364961385726929\n",
      "EPOCH 1 BATCH 21: training batch loss: 0.011511467397212982\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 21: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 1 BATCH 26: training batch loss: 0.08644595742225647\n",
      "EPOCH 1 BATCH 31: training batch loss: 0.015699051320552826\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 31: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 1 BATCH 36: training batch loss: 0.01607094705104828\n",
      "EPOCH 1 BATCH 41: training batch loss: 0.036269813776016235\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 41: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 1 BATCH 46: training batch loss: 0.03038366138935089\n",
      "EPOCH 1 BATCH 51: training batch loss: 0.021399974822998047\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 51: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 1 BATCH 56: training batch loss: 0.019046619534492493\n",
      "EPOCH 1 BATCH 61: training batch loss: 0.014906845986843109\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 61: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 1 BATCH 66: training batch loss: 0.01225346326828003\n",
      "EPOCH 1 BATCH 71: training batch loss: 0.01788248121738434\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 71: validation score 0.9219219219219219\n",
      "\n",
      "EPOCH 1 BATCH 76: training batch loss: 0.01131315529346466\n",
      "EPOCH 1 BATCH 81: training batch loss: 0.014638416469097137\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 81: validation score 0.9214214214214215\n",
      "\n",
      "EPOCH 1 BATCH 86: training batch loss: 0.020041249692440033\n",
      "EPOCH 1 BATCH 91: training batch loss: 0.00979553908109665\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 91: validation score 0.9219219219219219\n",
      "\n",
      "EPOCH 1 BATCH 96: training batch loss: 0.035634201020002365\n",
      "EPOCH 1 BATCH 101: training batch loss: 0.01796756684780121\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 101: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 1 BATCH 106: training batch loss: 0.017453834414482117\n",
      "EPOCH 1 BATCH 111: training batch loss: 0.02164699137210846\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 111: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 1 BATCH 116: training batch loss: 0.021773435175418854\n",
      "EPOCH 1 BATCH 121: training batch loss: 0.015434227883815765\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 121: validation score 0.9164164164164165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|█         | 1/10 [13:47<2:04:03, 827.02s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: EPOCH_LOSS: 0.02057485068934756\n",
      "EPOCH 2 / 10: \n",
      "----------\n",
      "EPOCH 2 BATCH 1: training batch loss: 0.02636047452688217\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 1: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 2 BATCH 6: training batch loss: 0.01388617604970932\n",
      "EPOCH 2 BATCH 11: training batch loss: 0.01684536784887314\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 11: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 2 BATCH 16: training batch loss: 0.022331316024065018\n",
      "EPOCH 2 BATCH 21: training batch loss: 0.028845056891441345\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 21: validation score 0.91991991991992\n",
      "\n",
      "EPOCH 2 BATCH 26: training batch loss: 0.011186376214027405\n",
      "EPOCH 2 BATCH 31: training batch loss: 0.023941881954669952\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 31: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 2 BATCH 36: training batch loss: 0.015141338109970093\n",
      "EPOCH 2 BATCH 41: training batch loss: 0.008480347692966461\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 41: validation score 0.91991991991992\n",
      "\n",
      "EPOCH 2 BATCH 46: training batch loss: 0.015148505568504333\n",
      "EPOCH 2 BATCH 51: training batch loss: 0.009018898010253906\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 51: validation score 0.9219219219219219\n",
      "\n",
      "EPOCH 2 BATCH 56: training batch loss: 0.01671629399061203\n",
      "EPOCH 2 BATCH 61: training batch loss: 0.01697155088186264\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 61: validation score 0.9174174174174174\n",
      "\n",
      "EPOCH 2 BATCH 66: training batch loss: 0.019068226218223572\n",
      "EPOCH 2 BATCH 71: training batch loss: 0.01233675330877304\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 71: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 2 BATCH 76: training batch loss: 0.012919872999191284\n",
      "EPOCH 2 BATCH 81: training batch loss: 0.016026653349399567\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 81: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 2 BATCH 86: training batch loss: 0.04043600708246231\n",
      "EPOCH 2 BATCH 91: training batch loss: 0.014083795249462128\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 91: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 2 BATCH 96: training batch loss: 0.01827646791934967\n",
      "EPOCH 2 BATCH 101: training batch loss: 0.016322679817676544\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 101: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 2 BATCH 106: training batch loss: 0.018074315041303635\n",
      "EPOCH 2 BATCH 111: training batch loss: 0.01696184277534485\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 111: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 2 BATCH 116: training batch loss: 0.012356750667095184\n",
      "EPOCH 2 BATCH 121: training batch loss: 0.02106192708015442\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 121: validation score 0.9194194194194194\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 20%|██        | 2/10 [27:32<1:50:13, 826.66s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: EPOCH_LOSS: 0.018671545294207614\n",
      "EPOCH 3 / 10: \n",
      "----------\n",
      "EPOCH 3 BATCH 1: training batch loss: 0.013096287846565247\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 1: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 3 BATCH 6: training batch loss: 0.04175562039017677\n",
      "EPOCH 3 BATCH 11: training batch loss: 0.035639502108097076\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 11: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 3 BATCH 16: training batch loss: 0.014602474868297577\n",
      "EPOCH 3 BATCH 21: training batch loss: 0.02623210847377777\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 21: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 3 BATCH 26: training batch loss: 0.013742581009864807\n",
      "EPOCH 3 BATCH 31: training batch loss: 0.011445358395576477\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 31: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 3 BATCH 36: training batch loss: 0.01198994368314743\n",
      "EPOCH 3 BATCH 41: training batch loss: 0.03660137951374054\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 41: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 3 BATCH 46: training batch loss: 0.019747436046600342\n",
      "EPOCH 3 BATCH 51: training batch loss: 0.012036614120006561\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 51: validation score 0.9164164164164165\n",
      "\n",
      "EPOCH 3 BATCH 56: training batch loss: 0.014271862804889679\n",
      "EPOCH 3 BATCH 61: training batch loss: 0.023806869983673096\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 61: validation score 0.9169169169169169\n",
      "\n",
      "EPOCH 3 BATCH 66: training batch loss: 0.02085043489933014\n",
      "EPOCH 3 BATCH 71: training batch loss: 0.025719933211803436\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 71: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 3 BATCH 76: training batch loss: 0.011250816285610199\n",
      "EPOCH 3 BATCH 81: training batch loss: 0.012313932180404663\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 81: validation score 0.9204204204204204\n",
      "\n",
      "EPOCH 3 BATCH 86: training batch loss: 0.014081694185733795\n",
      "EPOCH 3 BATCH 91: training batch loss: 0.015780538320541382\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 91: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 3 BATCH 96: training batch loss: 0.050098076462745667\n",
      "EPOCH 3 BATCH 101: training batch loss: 0.011907622218132019\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 101: validation score 0.9204204204204204\n",
      "\n",
      "EPOCH 3 BATCH 106: training batch loss: 0.015203222632408142\n",
      "EPOCH 3 BATCH 111: training batch loss: 0.023137420415878296\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 111: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 3 BATCH 116: training batch loss: 0.020859278738498688\n",
      "EPOCH 3 BATCH 121: training batch loss: 0.01774153858423233\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 121: validation score 0.9234234234234234\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 30%|███       | 3/10 [41:22<1:36:31, 827.41s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3: EPOCH_LOSS: 0.018710608033834397\n",
      "EPOCH 4 / 10: \n",
      "----------\n",
      "EPOCH 4 BATCH 1: training batch loss: 0.0095771923661232\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 1: validation score 0.9219219219219219\n",
      "\n",
      "EPOCH 4 BATCH 6: training batch loss: 0.013685844838619232\n",
      "EPOCH 4 BATCH 11: training batch loss: 0.01091853529214859\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 11: validation score 0.9214214214214215\n",
      "\n",
      "EPOCH 4 BATCH 16: training batch loss: 0.017253145575523376\n",
      "EPOCH 4 BATCH 21: training batch loss: 0.011878661811351776\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 21: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 4 BATCH 26: training batch loss: 0.017823953181505203\n",
      "EPOCH 4 BATCH 31: training batch loss: 0.0398125946521759\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 31: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 4 BATCH 36: training batch loss: 0.00965166836977005\n",
      "EPOCH 4 BATCH 41: training batch loss: 0.00947549194097519\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 41: validation score 0.9219219219219219\n",
      "\n",
      "EPOCH 4 BATCH 46: training batch loss: 0.013937041163444519\n",
      "EPOCH 4 BATCH 51: training batch loss: 0.02130476012825966\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 51: validation score 0.9214214214214215\n",
      "\n",
      "EPOCH 4 BATCH 56: training batch loss: 0.019844919443130493\n",
      "EPOCH 4 BATCH 61: training batch loss: 0.009211592376232147\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 61: validation score 0.9224224224224224\n",
      "\n",
      "EPOCH 4 BATCH 66: training batch loss: 0.010654479265213013\n",
      "EPOCH 4 BATCH 71: training batch loss: 0.015789002180099487\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 71: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 4 BATCH 76: training batch loss: 0.017221063375473022\n",
      "EPOCH 4 BATCH 81: training batch loss: 0.02092074602842331\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 81: validation score 0.9204204204204204\n",
      "\n",
      "EPOCH 4 BATCH 86: training batch loss: 0.01836305856704712\n",
      "EPOCH 4 BATCH 91: training batch loss: 0.02086213231086731\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 91: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 4 BATCH 96: training batch loss: 0.024856820702552795\n",
      "EPOCH 4 BATCH 101: training batch loss: 0.010779783129692078\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 101: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 4 BATCH 106: training batch loss: 0.03225003927946091\n",
      "EPOCH 4 BATCH 111: training batch loss: 0.012245729565620422\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 111: validation score 0.9154154154154154\n",
      "\n",
      "EPOCH 4 BATCH 116: training batch loss: 0.017984949052333832\n",
      "EPOCH 4 BATCH 121: training batch loss: 0.024773970246315002\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 121: validation score 0.9179179179179179\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 40%|████      | 4/10 [55:13<1:22:52, 828.68s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4: EPOCH_LOSS: 0.017857775670122932\n",
      "EPOCH 5 / 10: \n",
      "----------\n",
      "EPOCH 5 BATCH 1: training batch loss: 0.010121278464794159\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 1: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 5 BATCH 6: training batch loss: 0.013596661388874054\n",
      "EPOCH 5 BATCH 11: training batch loss: 0.012511976063251495\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 11: validation score 0.91991991991992\n",
      "\n",
      "EPOCH 5 BATCH 16: training batch loss: 0.011072732508182526\n",
      "EPOCH 5 BATCH 21: training batch loss: 0.010629832744598389\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 21: validation score 0.9194194194194194\n",
      "\n",
      "EPOCH 5 BATCH 26: training batch loss: 0.014546878635883331\n",
      "EPOCH 5 BATCH 31: training batch loss: 0.014782153069972992\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 31: validation score 0.915915915915916\n",
      "\n",
      "EPOCH 5 BATCH 36: training batch loss: 0.016953110694885254\n",
      "EPOCH 5 BATCH 41: training batch loss: 0.013016700744628906\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 41: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 5 BATCH 46: training batch loss: 0.013035997748374939\n",
      "EPOCH 5 BATCH 51: training batch loss: 0.013959221541881561\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 51: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 5 BATCH 56: training batch loss: 0.013980671763420105\n",
      "EPOCH 5 BATCH 61: training batch loss: 0.018905818462371826\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 61: validation score 0.9224224224224224\n",
      "\n",
      "EPOCH 5 BATCH 66: training batch loss: 0.013487271964550018\n",
      "EPOCH 5 BATCH 71: training batch loss: 0.011481858789920807\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 71: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 5 BATCH 76: training batch loss: 0.012282192707061768\n",
      "EPOCH 5 BATCH 81: training batch loss: 0.014886565506458282\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 81: validation score 0.9179179179179179\n",
      "\n",
      "EPOCH 5 BATCH 86: training batch loss: 0.022722117602825165\n",
      "EPOCH 5 BATCH 91: training batch loss: 0.019378766417503357\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 91: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 5 BATCH 96: training batch loss: 0.0324116051197052\n",
      "EPOCH 5 BATCH 101: training batch loss: 0.010384202003479004\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 101: validation score 0.9204204204204204\n",
      "\n",
      "EPOCH 5 BATCH 106: training batch loss: 0.009889401495456696\n",
      "EPOCH 5 BATCH 111: training batch loss: 0.009340688586235046\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 111: validation score 0.91991991991992\n",
      "\n",
      "EPOCH 5 BATCH 116: training batch loss: 0.007020600140094757\n",
      "EPOCH 5 BATCH 121: training batch loss: 0.011422939598560333\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 121: validation score 0.9209209209209209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 50%|█████     | 5/10 [1:09:02<1:09:03, 828.68s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5: EPOCH_LOSS: 0.015716561685885873\n",
      "EPOCH 6 / 10: \n",
      "----------\n",
      "EPOCH 6 BATCH 1: training batch loss: 0.009658291935920715\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 1: validation score 0.9179179179179179\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-77d112855cbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m model_res = train_model(model=model_res, dataloaders=dataloaders, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=10, \n\u001b[0;32m---> 10\u001b[0;31m         PATH='model/ten_crop/lr_000001')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a593b4ddb92d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, criterion, optimizer, device, PATH, epochs)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m             \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('../model/ten_crop/lr_00001/best_model_3_111.pt'))\n",
    "model_res.to(device)\n",
    "optimizer = optim.Adam(model_res.parameters(), lr=0.000001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_res = train_model(model=model_res, dataloaders=dataloaders, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=10, \n",
    "        PATH='model/ten_crop/lr_000001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 / 4: \n",
      "----------\n",
      "EPOCH 1 BATCH 1: training batch loss: 0.013814657926559448\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 1: validation score 0.9229229229229229\n",
      "\n",
      "EPOCH 1 BATCH 6: training batch loss: 0.019834503531455994\n",
      "EPOCH 1 BATCH 11: training batch loss: 0.01316262036561966\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 11: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 1 BATCH 16: training batch loss: 0.011571168899536133\n",
      "EPOCH 1 BATCH 21: training batch loss: 0.03169119730591774\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 21: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 1 BATCH 26: training batch loss: 0.029147803783416748\n",
      "EPOCH 1 BATCH 31: training batch loss: 0.010605335235595703\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 31: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 1 BATCH 36: training batch loss: 0.017316393554210663\n",
      "EPOCH 1 BATCH 41: training batch loss: 0.018457621335983276\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 41: validation score 0.91991991991992\n",
      "\n",
      "EPOCH 1 BATCH 46: training batch loss: 0.015717744827270508\n",
      "EPOCH 1 BATCH 51: training batch loss: 0.033132731914520264\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 51: validation score 0.918918918918919\n",
      "\n",
      "EPOCH 1 BATCH 56: training batch loss: 0.01888011395931244\n",
      "EPOCH 1 BATCH 61: training batch loss: 0.015987034887075424\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 61: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 1 BATCH 66: training batch loss: 0.014098085463047028\n",
      "EPOCH 1 BATCH 71: training batch loss: 0.020794004201889038\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 71: validation score 0.9224224224224224\n",
      "\n",
      "EPOCH 1 BATCH 76: training batch loss: 0.014227047562599182\n",
      "EPOCH 1 BATCH 81: training batch loss: 0.013265572488307953\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 81: validation score 0.9229229229229229\n",
      "\n",
      "EPOCH 1 BATCH 86: training batch loss: 0.017547011375427246\n",
      "EPOCH 1 BATCH 91: training batch loss: 0.03010093793272972\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 91: validation score 0.9184184184184183\n",
      "\n",
      "EPOCH 1 BATCH 96: training batch loss: 0.027180463075637817\n",
      "EPOCH 1 BATCH 101: training batch loss: 0.011606574058532715\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 101: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 1 BATCH 106: training batch loss: 0.01673128455877304\n",
      "EPOCH 1 BATCH 111: training batch loss: 0.008953392505645752\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 111: validation score 0.9209209209209209\n",
      "\n",
      "EPOCH 1 BATCH 116: training batch loss: 0.010195888578891754\n",
      "EPOCH 1 BATCH 121: training batch loss: 0.013429269194602966\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 121: validation score 0.9209209209209209\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██▌       | 1/4 [13:46<41:20, 826.92s/it]\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: EPOCH_LOSS: 0.01748569445168083\n",
      "EPOCH 2 / 4: \n",
      "----------\n",
      "EPOCH 2 BATCH 1: training batch loss: 0.010323449969291687\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-7a8d312b57ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m model_res = train_model(model=model_res, dataloaders=dataloaders, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=4, \n\u001b[0;32m---> 10\u001b[0;31m         PATH='model/ten_crop/lr_1e-7')\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-a593b4ddb92d>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, criterion, optimizer, device, PATH, epochs)\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mval_batch_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                         \u001b[0mval_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m                         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mval_batch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('../model/ten_crop/lr_000001/best_model_3_121.pt'))\n",
    "model_res.to(device)\n",
    "optimizer = optim.Adam(model_res.parameters(), lr=1e-7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model_res = train_model(model=model_res, dataloaders=dataloaders, dataset_sizes=dataset_sizes, criterion=criterion, optimizer=optimizer, device=device, epochs=4, \n",
    "        PATH='model/ten_crop/lr_1e-7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('../model/ten_crop/lr_000001/best_model_3_121.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "X_test = df_test['img_file'].values\n",
    "\n",
    "test_dataset = TestImages(X_test, mode='test', transforms=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "model_res.eval()\n",
    "test_preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, images in enumerate(test_loader):\n",
    "        images = images.cuda()\n",
    "    \n",
    "        preds = model_res(images).detach()\n",
    "        test_preds.append(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "for _ in test_preds:\n",
    "    predicted_class_indices=np.argmax(_, axis=1).tolist()\n",
    "    outputs.append(predicted_class_indices)\n",
    "\n",
    "result = np.concatenate(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00001.jpg</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00002.jpg</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00003.jpg</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_00004.jpg</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_00005.jpg</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_file  class\n",
       "0  test_00001.jpg    124\n",
       "1  test_00002.jpg     98\n",
       "2  test_00003.jpg    157\n",
       "3  test_00004.jpg     94\n",
       "4  test_00005.jpg     18"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('../data/sample_submission.csv')\n",
    "submission[\"class\"] = result\n",
    "submission[\"class\"].replace(0, 196, inplace=True) # 196에서 0으로 수정했던걸 다시 되돌려준다 \n",
    "submission.to_csv(\"../data/submission.csv\", index=False)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
