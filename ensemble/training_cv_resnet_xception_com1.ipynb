{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# fix seeds\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 2019\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.enabled = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFOLD\n",
    "- 5 folds for ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preser9191/.local/lib/python3.6/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_train.replace(196, 0, inplace=True)\n",
    "df_train['fold'] = 999\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=False)\n",
    "for index, (_, val_index) in enumerate(skf.split(df_train['img_file'], df_train['class'])):\n",
    "    df_train['fold'].iloc[val_index] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fold_dataset(df_train, fold):\n",
    "    X_train = df_train[df_train['fold']!=fold]['img_file']\n",
    "    X_val = df_train[df_train['fold']==fold]['img_file']\n",
    "    y_train = df_train[df_train['fold']!=fold]['class']\n",
    "    y_val = df_train[df_train['fold']==fold]['class']\n",
    "    \n",
    "    return X_train.values, X_val.values, y_train.values, y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, 0)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print(\"-\"*8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Image resize\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Datapath\n",
    "TRAIN_DATA_PATH = '../data/train_crop/'\n",
    "TEST_DATA_PATH = '../data/test_crop/'\n",
    "\n",
    "# torch dataset\n",
    "class TrainImages(Dataset):\n",
    "    def __init__(self, images, labels, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TRAIN_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "class TestImages(Dataset):\n",
    "    def __init__(self, images, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TEST_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(X_train, X_val, y_train, y_val):\n",
    "    train_dataset = TrainImages(images=X_train, labels=y_train, mode='train', transforms=transform)\n",
    "    val_dataset = TrainImages(images=X_val, labels=y_val, mode='val', transforms=transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': train_dataloader,\n",
    "        'val': val_dataloader\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        'train': len(train_dataset),\n",
    "        'val': len(val_dataset)\n",
    "    }\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_index, (batch_image, batch_target) in enumerate(dataloader):\n",
    "        batch_image, batch_target = batch_image.to(device), batch_target.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = model(batch_image)\n",
    "        loss = criterion(batch_output, batch_target)\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() / len(dataloader)\n",
    "#         if batch_index % (len(dataloader)//3) == 0:\n",
    "        if batch_index % 30 == 0:\n",
    "            print(\". . . batch: {}, batch_loss: {}\".format(batch_index, loss.item()))\n",
    "    return train_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, dataset_sizes):\n",
    "    model.eval()\n",
    "    \n",
    "    val_preds = np.zeros((dataset_sizes['val'], 1))\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (batch_image, batch_target) in enumerate(dataloader):\n",
    "            batch_image, batch_target = batch_image.to(device), batch_target.to(device)\n",
    "            \n",
    "            batch_output = model(batch_image).detach()\n",
    "            _, batch_preds = torch.max(batch_output, 1)\n",
    "            \n",
    "            loss = criterion(batch_output, batch_target)\n",
    "            val_loss += loss.item() / len(dataloader)\n",
    "            \n",
    "            val_preds[batch_index * batch_size: (batch_index+1) * batch_size] = batch_preds.cpu().view(-1, 1).numpy()\n",
    "\n",
    "        val_score = f1_score(y_val, val_preds, average='micro')\n",
    "        \n",
    "    return val_loss, val_score\n",
    "\n",
    "def train_model(model, dataloaders, lr, dataset_sizes, num_epochs, PATH):\n",
    "    \n",
    "    best_score = 0.0\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    results = {\n",
    "        'best_epoch': 0,\n",
    "        'best_score': 0,\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"{} / {}\".format(epoch+1, num_epochs))\n",
    "        train_loss = train(model, dataloaders['train'], criterion, optimizer)\n",
    "        val_loss, val_score = validate(model, dataloaders['val'], criterion, dataset_sizes)\n",
    "        \n",
    "        print(\"EPOCH: {}, train_loss: {}, val_loss: {}, val_score: {}\".format(epoch+1, train_loss, val_loss, val_score))\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            torch.save(model.state_dict(), './{}/best_model_epoch_{}_score_{}.pt'.format(PATH, epoch+1, val_score))\n",
    "            results['best_epoch'] = epoch+1\n",
    "            results['best_score'] = best_score\n",
    "            print(\">>>>>>  EPOCH {}: validation score {}\".format(epoch+1, val_score))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 5.383825302124023\n",
      ". . . batch: 41, batch_loss: 5.299849033355713\n",
      ". . . batch: 82, batch_loss: 5.233278751373291\n",
      ". . . batch: 123, batch_loss: 5.312289714813232\n",
      "EPOCH: 1, train_loss: 5.291198522813858, val_loss: 5.228442495519465, val_score: 0.01878612716763006\n",
      ">>>>>>  EPOCH 1: validation score 0.01878612716763006\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 5.282308101654053\n",
      ". . . batch: 41, batch_loss: 5.1560540199279785\n",
      ". . . batch: 82, batch_loss: 5.07704496383667\n",
      ". . . batch: 123, batch_loss: 5.177755355834961\n",
      "EPOCH: 2, train_loss: 5.137968890128598, val_loss: 5.100189252333208, val_score: 0.0197495183044316\n",
      ">>>>>>  EPOCH 2: validation score 0.0197495183044316\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 5.020870685577393\n",
      ". . . batch: 41, batch_loss: 4.926645755767822\n",
      ". . . batch: 82, batch_loss: 5.113419532775879\n",
      ". . . batch: 123, batch_loss: 4.968969345092773\n",
      "EPOCH: 3, train_loss: 5.035809605352338, val_loss: 5.145202521121862, val_score: 0.016377649325626204\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 4.953311920166016\n",
      ". . . batch: 41, batch_loss: 4.784001350402832\n",
      ". . . batch: 82, batch_loss: 4.673601150512695\n",
      ". . . batch: 123, batch_loss: 4.725433349609375\n",
      "EPOCH: 4, train_loss: 4.838701348150931, val_loss: 4.840043067932128, val_score: 0.03564547206165703\n",
      ">>>>>>  EPOCH 4: validation score 0.03564547206165703\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 4.690493106842041\n",
      ". . . batch: 41, batch_loss: 4.528688430786133\n",
      ". . . batch: 82, batch_loss: 4.520097255706787\n",
      ". . . batch: 123, batch_loss: 4.463616847991943\n",
      "EPOCH: 5, train_loss: 4.529774565850534, val_loss: 4.905718471064712, val_score: 0.03901734104046243\n",
      ">>>>>>  EPOCH 5: validation score 0.03901734104046243\n",
      "{'best_epoch': 5, 'best_score': 0.03901734104046243}\n"
     ]
    }
   ],
   "source": [
    "# 0번째 fold\n",
    "fold = 0\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 4.246837615966797\n",
      ". . . batch: 41, batch_loss: 4.343574523925781\n",
      ". . . batch: 82, batch_loss: 4.252584934234619\n",
      ". . . batch: 123, batch_loss: 4.106612205505371\n",
      "EPOCH: 1, train_loss: 4.250045176475279, val_loss: 4.246904828331687, val_score: 0.07996146435452794\n",
      ">>>>>>  EPOCH 1: validation score 0.07996146435452794\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 4.149881839752197\n",
      ". . . batch: 41, batch_loss: 3.9386115074157715\n",
      ". . . batch: 82, batch_loss: 3.77221417427063\n",
      ". . . batch: 123, batch_loss: 3.844247341156006\n",
      "EPOCH: 2, train_loss: 3.908779055841508, val_loss: 3.8655671784372045, val_score: 0.10886319845857419\n",
      ">>>>>>  EPOCH 2: validation score 0.10886319845857419\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 3.5502612590789795\n",
      ". . . batch: 41, batch_loss: 3.8402698040008545\n",
      ". . . batch: 82, batch_loss: 3.587817668914795\n",
      ". . . batch: 123, batch_loss: 3.235092878341675\n",
      "EPOCH: 3, train_loss: 3.611608159157541, val_loss: 3.884415417006521, val_score: 0.12379576107899808\n",
      ">>>>>>  EPOCH 3: validation score 0.12379576107899808\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 3.0473897457122803\n",
      ". . . batch: 41, batch_loss: 3.2178311347961426\n",
      ". . . batch: 82, batch_loss: 3.3181562423706055\n",
      ". . . batch: 123, batch_loss: 3.1219820976257324\n",
      "EPOCH: 4, train_loss: 3.248041241399703, val_loss: 3.416328285679673, val_score: 0.19219653179190754\n",
      ">>>>>>  EPOCH 4: validation score 0.19219653179190754\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 2.8582446575164795\n",
      ". . . batch: 41, batch_loss: 2.830639600753784\n",
      ". . . batch: 82, batch_loss: 2.931617259979248\n",
      ". . . batch: 123, batch_loss: 2.903578519821167\n",
      "EPOCH: 5, train_loss: 2.8939737350709978, val_loss: 3.3143193577275136, val_score: 0.19653179190751446\n",
      ">>>>>>  EPOCH 5: validation score 0.19653179190751446\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 2.460219621658325\n",
      ". . . batch: 41, batch_loss: 2.413177728652954\n",
      ". . . batch: 82, batch_loss: 2.7885491847991943\n",
      ". . . batch: 123, batch_loss: 2.430300235748291\n",
      "EPOCH: 6, train_loss: 2.5141041721067117, val_loss: 2.611470865480828, val_score: 0.342485549132948\n",
      ">>>>>>  EPOCH 6: validation score 0.342485549132948\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 2.136598825454712\n",
      ". . . batch: 41, batch_loss: 2.2568233013153076\n",
      ". . . batch: 82, batch_loss: 1.74003005027771\n",
      ". . . batch: 123, batch_loss: 2.08760142326355\n",
      "EPOCH: 7, train_loss: 2.1314251749746256, val_loss: 2.647846041303692, val_score: 0.33236994219653176\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 1.812044382095337\n",
      ". . . batch: 41, batch_loss: 1.8911529779434204\n",
      ". . . batch: 82, batch_loss: 2.0538134574890137\n",
      ". . . batch: 123, batch_loss: 1.5412712097167969\n",
      "EPOCH: 8, train_loss: 1.8107605288105637, val_loss: 2.368409077326457, val_score: 0.3752408477842004\n",
      ">>>>>>  EPOCH 8: validation score 0.3752408477842004\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 1.5071673393249512\n",
      ". . . batch: 41, batch_loss: 1.5958070755004883\n",
      ". . . batch: 82, batch_loss: 1.219062328338623\n",
      ". . . batch: 123, batch_loss: 1.6381218433380127\n",
      "EPOCH: 9, train_loss: 1.5479134369281025, val_loss: 1.9295076565309002, val_score: 0.47832369942196534\n",
      ">>>>>>  EPOCH 9: validation score 0.47832369942196534\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 1.5183156728744507\n",
      ". . . batch: 41, batch_loss: 1.4012386798858643\n",
      ". . . batch: 82, batch_loss: 1.262334942817688\n",
      ". . . batch: 123, batch_loss: 1.5234886407852173\n",
      "EPOCH: 10, train_loss: 1.30449401611282, val_loss: 2.188221682201732, val_score: 0.4508670520231214\n",
      "{'best_epoch': 9, 'best_score': 0.47832369942196534}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_5_score_0.03901734104046243.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 1.6552002429962158\n",
      ". . . batch: 41, batch_loss: 1.444204330444336\n",
      ". . . batch: 82, batch_loss: 0.9600077867507935\n",
      ". . . batch: 123, batch_loss: 1.1740903854370117\n",
      "EPOCH: 1, train_loss: 1.3083350216188747, val_loss: 1.9234032558672352, val_score: 0.5048169556840078\n",
      ">>>>>>  EPOCH 1: validation score 0.5048169556840078\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 1.0093985795974731\n",
      ". . . batch: 41, batch_loss: 0.9463107585906982\n",
      ". . . batch: 82, batch_loss: 1.211683988571167\n",
      ". . . batch: 123, batch_loss: 1.2292311191558838\n",
      "EPOCH: 2, train_loss: 1.0798399501269869, val_loss: 1.9095017332019228, val_score: 0.49614643545279385\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 1.0029034614562988\n",
      ". . . batch: 41, batch_loss: 1.1067020893096924\n",
      ". . . batch: 82, batch_loss: 0.8739738464355469\n",
      ". . . batch: 123, batch_loss: 1.1196417808532715\n",
      "EPOCH: 3, train_loss: 0.9829437910549103, val_loss: 1.5341745994307776, val_score: 0.5814065510597303\n",
      ">>>>>>  EPOCH 3: validation score 0.5814065510597303\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 1.157421588897705\n",
      ". . . batch: 41, batch_loss: 0.8023973703384399\n",
      ". . . batch: 82, batch_loss: 0.943950891494751\n",
      ". . . batch: 123, batch_loss: 1.2912423610687256\n",
      "EPOCH: 4, train_loss: 0.842440106455357, val_loss: 1.6118978659311933, val_score: 0.5915221579961464\n",
      ">>>>>>  EPOCH 4: validation score 0.5915221579961464\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 0.6595814824104309\n",
      ". . . batch: 41, batch_loss: 0.847517728805542\n",
      ". . . batch: 82, batch_loss: 0.7691802382469177\n",
      ". . . batch: 123, batch_loss: 0.658896803855896\n",
      "EPOCH: 5, train_loss: 0.753384583179028, val_loss: 1.554417570432027, val_score: 0.5973025048169557\n",
      ">>>>>>  EPOCH 5: validation score 0.5973025048169557\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 0.6718743443489075\n",
      ". . . batch: 41, batch_loss: 0.6136841773986816\n",
      ". . . batch: 82, batch_loss: 0.7794466018676758\n",
      ". . . batch: 123, batch_loss: 0.8669793009757996\n",
      "EPOCH: 6, train_loss: 0.6626722574714693, val_loss: 1.7090022925174595, val_score: 0.5751445086705202\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 0.43103456497192383\n",
      ". . . batch: 41, batch_loss: 0.511823832988739\n",
      ". . . batch: 82, batch_loss: 0.5790030360221863\n",
      ". . . batch: 123, batch_loss: 0.5938624143600464\n",
      "EPOCH: 7, train_loss: 0.6242400037665521, val_loss: 1.4402682672847402, val_score: 0.6127167630057804\n",
      ">>>>>>  EPOCH 7: validation score 0.6127167630057804\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 0.4517046809196472\n",
      ". . . batch: 41, batch_loss: 0.38463863730430603\n",
      ". . . batch: 82, batch_loss: 0.7506340146064758\n",
      ". . . batch: 123, batch_loss: 0.509239673614502\n",
      "EPOCH: 8, train_loss: 0.5280559091798719, val_loss: 1.5129623015721636, val_score: 0.6180154142581888\n",
      ">>>>>>  EPOCH 8: validation score 0.6180154142581888\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 0.48947593569755554\n",
      ". . . batch: 41, batch_loss: 0.5386035442352295\n",
      ". . . batch: 82, batch_loss: 0.4448235034942627\n",
      ". . . batch: 123, batch_loss: 0.4290955066680908\n",
      "EPOCH: 9, train_loss: 0.4577255550651781, val_loss: 1.4537493442044116, val_score: 0.6271676300578035\n",
      ">>>>>>  EPOCH 9: validation score 0.6271676300578035\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 0.46351537108421326\n",
      ". . . batch: 41, batch_loss: 0.753371000289917\n",
      ". . . batch: 82, batch_loss: 0.39037010073661804\n",
      ". . . batch: 123, batch_loss: 0.45858052372932434\n",
      "EPOCH: 10, train_loss: 0.4317118268339864, val_loss: 1.6258621504812527, val_score: 0.5934489402697495\n",
      "{'best_epoch': 9, 'best_score': 0.6271676300578035}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_9_score_0.47832369942196534.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.37338078022003174\n",
      ". . . batch: 41, batch_loss: 0.32476985454559326\n",
      ". . . batch: 82, batch_loss: 0.3499756455421448\n",
      ". . . batch: 123, batch_loss: 0.41411399841308594\n",
      "EPOCH: 1, train_loss: 0.5039797786983754, val_loss: 1.8053203134825735, val_score: 0.5948940269749519\n",
      ">>>>>>  EPOCH 1: validation score 0.5948940269749519\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.37293627858161926\n",
      ". . . batch: 41, batch_loss: 0.32039737701416016\n",
      ". . . batch: 82, batch_loss: 0.37813687324523926\n",
      ". . . batch: 123, batch_loss: 0.3415590524673462\n",
      "EPOCH: 2, train_loss: 0.4132883915257068, val_loss: 1.3744796911875405, val_score: 0.6551059730250481\n",
      ">>>>>>  EPOCH 2: validation score 0.6551059730250481\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.37042543292045593\n",
      ". . . batch: 41, batch_loss: 0.30435675382614136\n",
      ". . . batch: 82, batch_loss: 0.445711225271225\n",
      ". . . batch: 123, batch_loss: 0.5060069561004639\n",
      "EPOCH: 3, train_loss: 0.37092277083185426, val_loss: 1.4581100145975752, val_score: 0.6488439306358381\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.2237655371427536\n",
      ". . . batch: 41, batch_loss: 0.2576567530632019\n",
      ". . . batch: 82, batch_loss: 0.2429797351360321\n",
      ". . . batch: 123, batch_loss: 0.4393986761569977\n",
      "EPOCH: 4, train_loss: 0.33006408125642817, val_loss: 1.497027724078207, val_score: 0.6421001926782274\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.3941466510295868\n",
      ". . . batch: 41, batch_loss: 0.2602291405200958\n",
      ". . . batch: 82, batch_loss: 0.3448876738548279\n",
      ". . . batch: 123, batch_loss: 0.26735052466392517\n",
      "EPOCH: 5, train_loss: 0.2981158329714691, val_loss: 1.3118934197859324, val_score: 0.6685934489402697\n",
      ">>>>>>  EPOCH 5: validation score 0.6685934489402697\n",
      "{'best_epoch': 5, 'best_score': 0.6685934489402697}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_9_score_0.6271676300578035.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr changed to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.26603302359580994\n",
      ". . . batch: 41, batch_loss: 0.11748883128166199\n",
      ". . . batch: 82, batch_loss: 0.10489501804113388\n",
      ". . . batch: 123, batch_loss: 0.20275545120239258\n",
      "EPOCH: 1, train_loss: 0.14286818845017302, val_loss: 0.8847493773156948, val_score: 0.779383429672447\n",
      ">>>>>>  EPOCH 1: validation score 0.779383429672447\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.13722552359104156\n",
      ". . . batch: 41, batch_loss: 0.07206806540489197\n",
      ". . . batch: 82, batch_loss: 0.15307839214801788\n",
      ". . . batch: 123, batch_loss: 0.09004052728414536\n",
      "EPOCH: 2, train_loss: 0.08164021179019924, val_loss: 0.8492354479703037, val_score: 0.785645472061657\n",
      ">>>>>>  EPOCH 2: validation score 0.785645472061657\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.038217902183532715\n",
      ". . . batch: 41, batch_loss: 0.09447608143091202\n",
      ". . . batch: 82, batch_loss: 0.08864694088697433\n",
      ". . . batch: 123, batch_loss: 0.1042739674448967\n",
      "EPOCH: 3, train_loss: 0.06729429539653563, val_loss: 0.927479602170713, val_score: 0.7827552986512524\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.04233287274837494\n",
      ". . . batch: 41, batch_loss: 0.0703224316239357\n",
      ". . . batch: 82, batch_loss: 0.0892648994922638\n",
      ". . . batch: 123, batch_loss: 0.07265786826610565\n",
      "EPOCH: 4, train_loss: 0.06202249793756392, val_loss: 1.1000714658787756, val_score: 0.7760115606936416\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.04759419709444046\n",
      ". . . batch: 41, batch_loss: 0.030626654624938965\n",
      ". . . batch: 82, batch_loss: 0.05312336981296539\n",
      ". . . batch: 123, batch_loss: 0.11420699208974838\n",
      "EPOCH: 5, train_loss: 0.05296175449245399, val_loss: 0.9563788252346442, val_score: 0.7813102119460502\n",
      "{'best_epoch': 2, 'best_score': 0.785645472061657}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_5_score_0.6685934489402697.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.0001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3\n",
      ". . . batch: 0, batch_loss: 0.10267733782529831\n",
      ". . . batch: 41, batch_loss: 0.051810793578624725\n",
      ". . . batch: 82, batch_loss: 0.06250932812690735\n",
      ". . . batch: 123, batch_loss: 0.11724892258644104\n",
      "EPOCH: 1, train_loss: 0.07666434596983658, val_loss: 0.8477138425364639, val_score: 0.7870905587668593\n",
      ">>>>>>  EPOCH 1: validation score 0.7870905587668593\n",
      "2 / 3\n",
      ". . . batch: 0, batch_loss: 0.10274454951286316\n",
      ". . . batch: 41, batch_loss: 0.05277039855718613\n",
      ". . . batch: 82, batch_loss: 0.06517122685909271\n",
      ". . . batch: 123, batch_loss: 0.12235032021999359\n",
      "EPOCH: 2, train_loss: 0.06382877607980082, val_loss: 0.9512522459933253, val_score: 0.7764932562620422\n",
      "3 / 3\n",
      ". . . batch: 0, batch_loss: 0.08058720827102661\n",
      ". . . batch: 41, batch_loss: 0.06236293166875839\n",
      ". . . batch: 82, batch_loss: 0.05246765911579132\n",
      ". . . batch: 123, batch_loss: 0.04324960708618164\n",
      "EPOCH: 3, train_loss: 0.05411495618341911, val_loss: 0.8722764127182238, val_score: 0.785645472061657\n",
      "{'best_epoch': 1, 'best_score': 0.7870905587668593}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_2_score_0.785645472061657.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.0001, dataset_sizes, 3, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr changed to 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 0.04467710852622986\n",
      ". . . batch: 41, batch_loss: 0.027035189792513847\n",
      ". . . batch: 82, batch_loss: 0.11692338436841965\n",
      ". . . batch: 123, batch_loss: 0.028341684490442276\n",
      "EPOCH: 1, train_loss: 0.05913375088224002, val_loss: 0.8829545604460166, val_score: 0.7914258188824663\n",
      ">>>>>>  EPOCH 1: validation score 0.7914258188824663\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 0.05197174474596977\n",
      ". . . batch: 41, batch_loss: 0.06104442477226257\n",
      ". . . batch: 82, batch_loss: 0.03625480830669403\n",
      ". . . batch: 123, batch_loss: 0.0462426133453846\n",
      "EPOCH: 2, train_loss: 0.05352216397201823, val_loss: 0.8743639619964542, val_score: 0.785645472061657\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 0.037354402244091034\n",
      ". . . batch: 41, batch_loss: 0.051488082855939865\n",
      ". . . batch: 82, batch_loss: 0.04191826656460762\n",
      ". . . batch: 123, batch_loss: 0.01837806962430477\n",
      "EPOCH: 3, train_loss: 0.053001852105221445, val_loss: 0.87860474848386, val_score: 0.791907514450867\n",
      ">>>>>>  EPOCH 3: validation score 0.791907514450867\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 0.0345434732735157\n",
      ". . . batch: 41, batch_loss: 0.057416513562202454\n",
      ". . . batch: 82, batch_loss: 0.08384521305561066\n",
      ". . . batch: 123, batch_loss: 0.020036909729242325\n",
      "EPOCH: 4, train_loss: 0.05243130541977383, val_loss: 0.8772105633309393, val_score: 0.7875722543352601\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 0.04210113361477852\n",
      ". . . batch: 41, batch_loss: 0.12569484114646912\n",
      ". . . batch: 82, batch_loss: 0.017913274466991425\n",
      ". . . batch: 123, batch_loss: 0.048036880791187286\n",
      "EPOCH: 5, train_loss: 0.05086861309715577, val_loss: 0.8812867570104022, val_score: 0.789980732177264\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 0.049345895648002625\n",
      ". . . batch: 41, batch_loss: 0.06963817030191422\n",
      ". . . batch: 82, batch_loss: 0.032964304089546204\n",
      ". . . batch: 123, batch_loss: 0.047105852514505386\n",
      "EPOCH: 6, train_loss: 0.048034182284027345, val_loss: 0.8900954655625606, val_score: 0.7904624277456648\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 0.03807713836431503\n",
      ". . . batch: 41, batch_loss: 0.062261104583740234\n",
      ". . . batch: 82, batch_loss: 0.0696101114153862\n",
      ". . . batch: 123, batch_loss: 0.03835670277476311\n",
      "EPOCH: 7, train_loss: 0.04650859612851375, val_loss: 0.8753344263091232, val_score: 0.7909441233140655\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 0.022748028859496117\n",
      ". . . batch: 41, batch_loss: 0.01956932060420513\n",
      ". . . batch: 82, batch_loss: 0.10802997648715973\n",
      ". . . batch: 123, batch_loss: 0.15286335349082947\n",
      "EPOCH: 8, train_loss: 0.04637923642181822, val_loss: 0.8950835728284087, val_score: 0.789980732177264\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 0.043077677488327026\n",
      ". . . batch: 41, batch_loss: 0.03525177761912346\n",
      ". . . batch: 82, batch_loss: 0.06529812514781952\n",
      ". . . batch: 123, batch_loss: 0.040857572108507156\n",
      "EPOCH: 9, train_loss: 0.045736794585301985, val_loss: 0.9287911414196998, val_score: 0.7880539499036608\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 0.04600878059864044\n",
      ". . . batch: 41, batch_loss: 0.07668454200029373\n",
      ". . . batch: 82, batch_loss: 0.03854244202375412\n",
      ". . . batch: 123, batch_loss: 0.04099080711603165\n",
      "EPOCH: 10, train_loss: 0.04531997663059061, val_loss: 0.8709051943186558, val_score: 0.7909441233140655\n",
      "{'best_epoch': 3, 'best_score': 0.791907514450867}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_1_score_0.7870905587668593.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.00001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 0.11710284650325775\n",
      ". . . batch: 41, batch_loss: 0.03234390914440155\n",
      ". . . batch: 82, batch_loss: 0.08893438428640366\n",
      ". . . batch: 123, batch_loss: 0.04258214682340622\n",
      "EPOCH: 1, train_loss: 0.050638629769485806, val_loss: 0.9253194088285621, val_score: 0.7870905587668593\n",
      ">>>>>>  EPOCH 1: validation score 0.7870905587668593\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 0.06959838420152664\n",
      ". . . batch: 41, batch_loss: 0.0741816982626915\n",
      ". . . batch: 82, batch_loss: 0.0527956485748291\n",
      ". . . batch: 123, batch_loss: 0.08831766992807388\n",
      "EPOCH: 2, train_loss: 0.051807586749595014, val_loss: 0.9722666853305066, val_score: 0.7842003853564548\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 0.04893384873867035\n",
      ". . . batch: 41, batch_loss: 0.05226784199476242\n",
      ". . . batch: 82, batch_loss: 0.04128000885248184\n",
      ". . . batch: 123, batch_loss: 0.0834939256310463\n",
      "EPOCH: 3, train_loss: 0.05059158180149332, val_loss: 0.9425019495414965, val_score: 0.789980732177264\n",
      ">>>>>>  EPOCH 3: validation score 0.789980732177264\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 0.023958228528499603\n",
      ". . . batch: 41, batch_loss: 0.04184021055698395\n",
      ". . . batch: 82, batch_loss: 0.05338679626584053\n",
      ". . . batch: 123, batch_loss: 0.10429608076810837\n",
      "EPOCH: 4, train_loss: 0.04922089700196538, val_loss: 0.8570327998110742, val_score: 0.7904624277456648\n",
      ">>>>>>  EPOCH 4: validation score 0.7904624277456648\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 0.02719520963728428\n",
      ". . . batch: 41, batch_loss: 0.046402037143707275\n",
      ". . . batch: 82, batch_loss: 0.03236202523112297\n",
      ". . . batch: 123, batch_loss: 0.09552756696939468\n",
      "EPOCH: 5, train_loss: 0.05372763560303759, val_loss: 0.8653778876319075, val_score: 0.7885356454720617\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 0.03824109584093094\n",
      ". . . batch: 41, batch_loss: 0.0325571671128273\n",
      ". . . batch: 82, batch_loss: 0.0508679524064064\n",
      ". . . batch: 123, batch_loss: 0.03279593959450722\n",
      "EPOCH: 6, train_loss: 0.04669392409343871, val_loss: 0.870419733000524, val_score: 0.789980732177264\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 0.08185221254825592\n",
      ". . . batch: 41, batch_loss: 0.03459974005818367\n",
      ". . . batch: 82, batch_loss: 0.05380600690841675\n",
      ". . . batch: 123, batch_loss: 0.0392308309674263\n",
      "EPOCH: 7, train_loss: 0.04936917357507253, val_loss: 0.8563286102179327, val_score: 0.7875722543352601\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 0.032137881964445114\n",
      ". . . batch: 41, batch_loss: 0.0873379036784172\n",
      ". . . batch: 82, batch_loss: 0.09402362257242203\n",
      ". . . batch: 123, batch_loss: 0.07748664170503616\n",
      "EPOCH: 8, train_loss: 0.0517860690522338, val_loss: 0.9652134834816963, val_score: 0.7851637764932563\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 0.03428276255726814\n",
      ". . . batch: 41, batch_loss: 0.047557130455970764\n",
      ". . . batch: 82, batch_loss: 0.04348762705922127\n",
      ". . . batch: 123, batch_loss: 0.0744650587439537\n",
      "EPOCH: 9, train_loss: 0.04958169109698747, val_loss: 0.8451551655025195, val_score: 0.7880539499036608\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 0.10569979250431061\n",
      ". . . batch: 41, batch_loss: 0.0633280798792839\n",
      ". . . batch: 82, batch_loss: 0.04008481651544571\n",
      ". . . batch: 123, batch_loss: 0.1458704173564911\n",
      "EPOCH: 10, train_loss: 0.049793511891977914, val_loss: 0.870501151139086, val_score: 0.7890173410404624\n",
      "{'best_epoch': 4, 'best_score': 0.7904624277456648}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_3_score_0.791907514450867.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.000001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr change to 0.0000001\n",
    "- with EPOCH: 3, train_loss: 0.053001852105221445, val_loss: 0.87860474848386, val_score: 0.791907514450867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.05719216167926788\n",
      ". . . batch: 41, batch_loss: 0.04256844520568848\n",
      ". . . batch: 82, batch_loss: 0.05564809590578079\n",
      ". . . batch: 123, batch_loss: 0.03641868755221367\n",
      "EPOCH: 1, train_loss: 0.05317618748954228, val_loss: 0.8727182687231991, val_score: 0.7943159922928708\n",
      ">>>>>>  EPOCH 1: validation score 0.7943159922928708\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.058001965284347534\n",
      ". . . batch: 41, batch_loss: 0.0617021769285202\n",
      ". . . batch: 82, batch_loss: 0.02316904254257679\n",
      ". . . batch: 123, batch_loss: 0.06976498663425446\n",
      "EPOCH: 2, train_loss: 0.049729162211259496, val_loss: 0.8796036704020066, val_score: 0.7890173410404624\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.04677455499768257\n",
      ". . . batch: 41, batch_loss: 0.060270022600889206\n",
      ". . . batch: 82, batch_loss: 0.01879439502954483\n",
      ". . . batch: 123, batch_loss: 0.027426855638623238\n",
      "EPOCH: 3, train_loss: 0.05180054671701884, val_loss: 0.8766368586908686, val_score: 0.7904624277456648\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.07763092964887619\n",
      ". . . batch: 41, batch_loss: 0.021512489765882492\n",
      ". . . batch: 82, batch_loss: 0.05150999873876572\n",
      ". . . batch: 123, batch_loss: 0.0375295914709568\n",
      "EPOCH: 4, train_loss: 0.05035420175972247, val_loss: 0.8618030859665436, val_score: 0.7914258188824663\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.04613475874066353\n",
      ". . . batch: 41, batch_loss: 0.030328379943966866\n",
      ". . . batch: 82, batch_loss: 0.0568937323987484\n",
      ". . . batch: 123, batch_loss: 0.02057383395731449\n",
      "EPOCH: 5, train_loss: 0.051052083351439036, val_loss: 0.8554841925700505, val_score: 0.791907514450867\n",
      "{'best_epoch': 1, 'best_score': 0.7943159922928708}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_3_score_0.791907514450867.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.0000001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 17\n",
      ". . . batch: 0, batch_loss: 2.213510751724243\n",
      ". . . batch: 41, batch_loss: 2.493255853652954\n",
      ". . . batch: 82, batch_loss: 2.096853017807007\n",
      ". . . batch: 123, batch_loss: 2.075301170349121\n",
      "EPOCH: 1, train_loss: 2.083425149917603, val_loss: 2.211641475558281, val_score: 0.4224730127576055\n",
      ">>>>>>  EPOCH 1: validation score 0.4224730127576055\n",
      "2 / 17\n",
      ". . . batch: 0, batch_loss: 1.8076348304748535\n",
      ". . . batch: 41, batch_loss: 1.4508056640625\n",
      ". . . batch: 82, batch_loss: 1.4822258949279785\n",
      ". . . batch: 123, batch_loss: 1.59770929813385\n",
      "EPOCH: 2, train_loss: 1.687532978057861, val_loss: 2.630184233188629, val_score: 0.36653581943081454\n",
      "3 / 17\n",
      ". . . batch: 0, batch_loss: 1.4839547872543335\n",
      ". . . batch: 41, batch_loss: 1.0785847902297974\n",
      ". . . batch: 82, batch_loss: 1.9365373849868774\n",
      ". . . batch: 123, batch_loss: 1.2683528661727905\n",
      "EPOCH: 3, train_loss: 1.4572910642623902, val_loss: 1.7044905424118042, val_score: 0.5637880274779196\n",
      ">>>>>>  EPOCH 3: validation score 0.5637880274779196\n",
      "4 / 17\n",
      ". . . batch: 0, batch_loss: 1.1280542612075806\n",
      ". . . batch: 41, batch_loss: 1.249547004699707\n",
      ". . . batch: 82, batch_loss: 1.2485723495483398\n",
      ". . . batch: 123, batch_loss: 1.2061355113983154\n",
      "EPOCH: 4, train_loss: 1.240157905101776, val_loss: 1.61523312702775, val_score: 0.5716388616290481\n",
      ">>>>>>  EPOCH 4: validation score 0.5716388616290481\n",
      "5 / 17\n",
      ". . . batch: 0, batch_loss: 0.857215166091919\n",
      ". . . batch: 41, batch_loss: 1.2108291387557983\n",
      ". . . batch: 82, batch_loss: 0.8605177998542786\n",
      ". . . batch: 123, batch_loss: 1.1260865926742554\n",
      "EPOCH: 5, train_loss: 1.0473632488250726, val_loss: 1.9020113721489906, val_score: 0.5078508341511285\n",
      "6 / 17\n",
      ". . . batch: 0, batch_loss: 0.9852778315544128\n",
      ". . . batch: 41, batch_loss: 0.6324396133422852\n",
      ". . . batch: 82, batch_loss: 0.7536989450454712\n",
      ". . . batch: 123, batch_loss: 0.8362905979156494\n",
      "EPOCH: 6, train_loss: 0.9300267806053163, val_loss: 1.5048526618629694, val_score: 0.6123650637880275\n",
      ">>>>>>  EPOCH 6: validation score 0.6123650637880275\n",
      "7 / 17\n",
      ". . . batch: 0, batch_loss: 0.6457184553146362\n",
      ". . . batch: 41, batch_loss: 0.9839873313903809\n",
      ". . . batch: 82, batch_loss: 0.9939841032028198\n",
      ". . . batch: 123, batch_loss: 0.5053749680519104\n",
      "EPOCH: 7, train_loss: 0.7820317120552064, val_loss: 1.4287744518369436, val_score: 0.6241413150147204\n",
      ">>>>>>  EPOCH 7: validation score 0.6241413150147204\n",
      "8 / 17\n",
      ". . . batch: 0, batch_loss: 0.6070690751075745\n",
      ". . . batch: 41, batch_loss: 0.9376927614212036\n",
      ". . . batch: 82, batch_loss: 0.6880982518196106\n",
      ". . . batch: 123, batch_loss: 0.5926541090011597\n",
      "EPOCH: 8, train_loss: 0.6849175839424132, val_loss: 1.5490851942449808, val_score: 0.5902845927379784\n",
      "9 / 17\n",
      ". . . batch: 0, batch_loss: 0.5713584423065186\n",
      ". . . batch: 41, batch_loss: 0.819067120552063\n",
      ". . . batch: 82, batch_loss: 0.6663862466812134\n",
      ". . . batch: 123, batch_loss: 0.5052847266197205\n",
      "EPOCH: 9, train_loss: 0.5976659913063048, val_loss: 1.2470872960984707, val_score: 0.6751717369970559\n",
      ">>>>>>  EPOCH 9: validation score 0.6751717369970559\n",
      "10 / 17\n",
      ". . . batch: 0, batch_loss: 0.5742963552474976\n",
      ". . . batch: 41, batch_loss: 0.2654300630092621\n",
      ". . . batch: 82, batch_loss: 0.42477181553840637\n",
      ". . . batch: 123, batch_loss: 0.7614283561706543\n",
      "EPOCH: 10, train_loss: 0.5429161708354953, val_loss: 1.4047839250415564, val_score: 0.6334641805691855\n",
      "11 / 17\n",
      ". . . batch: 0, batch_loss: 0.5400798916816711\n",
      ". . . batch: 41, batch_loss: 0.37456268072128296\n",
      ". . . batch: 82, batch_loss: 0.5257990956306458\n",
      ". . . batch: 123, batch_loss: 0.4863225817680359\n",
      "EPOCH: 11, train_loss: 0.46512938368320467, val_loss: 1.2574143577367067, val_score: 0.6815505397448479\n",
      ">>>>>>  EPOCH 11: validation score 0.6815505397448479\n",
      "12 / 17\n",
      ". . . batch: 0, batch_loss: 0.3146509528160095\n",
      ". . . batch: 41, batch_loss: 0.3238937556743622\n",
      ". . . batch: 82, batch_loss: 0.26125484704971313\n",
      ". . . batch: 123, batch_loss: 0.44469332695007324\n",
      "EPOCH: 12, train_loss: 0.39637255799770366, val_loss: 1.2198522351682186, val_score: 0.6820412168792934\n",
      ">>>>>>  EPOCH 12: validation score 0.6820412168792934\n",
      "13 / 17\n",
      ". . . batch: 0, batch_loss: 0.2839764654636383\n",
      ". . . batch: 41, batch_loss: 0.4510001540184021\n",
      ". . . batch: 82, batch_loss: 0.4688321650028229\n",
      ". . . batch: 123, batch_loss: 0.635385274887085\n",
      "EPOCH: 13, train_loss: 0.37732431554794316, val_loss: 1.1971180699765682, val_score: 0.6908734052993131\n",
      ">>>>>>  EPOCH 13: validation score 0.6908734052993131\n",
      "14 / 17\n",
      ". . . batch: 0, batch_loss: 0.18444427847862244\n",
      ". . . batch: 41, batch_loss: 0.37645038962364197\n",
      ". . . batch: 82, batch_loss: 0.2743871808052063\n",
      ". . . batch: 123, batch_loss: 0.4333827495574951\n",
      "EPOCH: 14, train_loss: 0.33740710330009477, val_loss: 1.2744279373437166, val_score: 0.6894013738959764\n",
      "15 / 17\n",
      ". . . batch: 0, batch_loss: 0.4219340682029724\n",
      ". . . batch: 41, batch_loss: 0.27631875872612\n",
      ". . . batch: 82, batch_loss: 0.25847479701042175\n",
      ". . . batch: 123, batch_loss: 0.23362119495868683\n",
      "EPOCH: 15, train_loss: 0.2789961515665055, val_loss: 1.0677214711904526, val_score: 0.7384690873405301\n",
      ">>>>>>  EPOCH 15: validation score 0.7384690873405301\n",
      "16 / 17\n",
      ". . . batch: 0, batch_loss: 0.41402047872543335\n",
      ". . . batch: 41, batch_loss: 0.32331734895706177\n",
      ". . . batch: 82, batch_loss: 0.2817792296409607\n",
      ". . . batch: 123, batch_loss: 0.3000807762145996\n",
      "EPOCH: 16, train_loss: 0.27744803625345243, val_loss: 1.161314196884632, val_score: 0.7090284592737979\n",
      "17 / 17\n",
      ". . . batch: 0, batch_loss: 0.26870352029800415\n",
      ". . . batch: 41, batch_loss: 0.410366028547287\n",
      ". . . batch: 82, batch_loss: 0.14127683639526367\n",
      ". . . batch: 123, batch_loss: 0.21419161558151245\n",
      "EPOCH: 17, train_loss: 0.2622474649548532, val_loss: 1.143974494189024, val_score: 0.7154072620215898\n",
      "{'best_epoch': 15, 'best_score': 0.7384690873405301}\n"
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold1/rough/best_model_epoch_9_score_0.2787046123650638.pt'))\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 1\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 17, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.292495250701904\n",
      ". . . batch: 41, batch_loss: 5.307333469390869\n",
      ". . . batch: 82, batch_loss: 5.15076208114624\n",
      ". . . batch: 123, batch_loss: 5.093100070953369\n",
      "EPOCH: 1, train_loss: 5.276410400390626, val_loss: 5.135600745677948, val_score: 0.017456359102244388\n",
      ">>>>>>  EPOCH 1: validation score 0.017456359102244388\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.1176676750183105\n",
      ". . . batch: 41, batch_loss: 5.171294212341309\n",
      ". . . batch: 82, batch_loss: 5.177689075469971\n",
      ". . . batch: 123, batch_loss: 5.198026657104492\n",
      "EPOCH: 2, train_loss: 5.121323524475096, val_loss: 5.092849493026733, val_score: 0.016458852867830425\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 5.054117679595947\n",
      ". . . batch: 41, batch_loss: 4.913817405700684\n",
      ". . . batch: 82, batch_loss: 4.889196872711182\n",
      ". . . batch: 123, batch_loss: 4.927697658538818\n",
      "EPOCH: 3, train_loss: 4.962270847320557, val_loss: 4.954658076167107, val_score: 0.03391521197007481\n",
      ">>>>>>  EPOCH 3: validation score 0.03391521197007481\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 5.014168739318848\n",
      ". . . batch: 41, batch_loss: 4.7778167724609375\n",
      ". . . batch: 82, batch_loss: 4.581435680389404\n",
      ". . . batch: 123, batch_loss: 4.640652656555176\n",
      "EPOCH: 4, train_loss: 4.644921012878418, val_loss: 4.632788717746735, val_score: 0.0543640897755611\n",
      ">>>>>>  EPOCH 4: validation score 0.0543640897755611\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 4.328566551208496\n",
      ". . . batch: 41, batch_loss: 4.337775230407715\n",
      ". . . batch: 82, batch_loss: 4.242883682250977\n",
      ". . . batch: 123, batch_loss: 3.977182388305664\n",
      "EPOCH: 5, train_loss: 4.29762121772766, val_loss: 4.809225350618362, val_score: 0.05536159600997506\n",
      ">>>>>>  EPOCH 5: validation score 0.05536159600997506\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 4.081307411193848\n",
      ". . . batch: 41, batch_loss: 3.877300977706909\n",
      ". . . batch: 82, batch_loss: 3.7487196922302246\n",
      ". . . batch: 123, batch_loss: 3.4542489051818848\n",
      "EPOCH: 6, train_loss: 3.925948884963993, val_loss: 4.20292067527771, val_score: 0.08678304239401496\n",
      ">>>>>>  EPOCH 6: validation score 0.08678304239401496\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.755005359649658\n",
      ". . . batch: 41, batch_loss: 3.3742873668670654\n",
      ". . . batch: 82, batch_loss: 3.4813919067382812\n",
      ". . . batch: 123, batch_loss: 3.1683037281036377\n",
      "EPOCH: 7, train_loss: 3.5502946548461916, val_loss: 3.6005700081586838, val_score: 0.1486284289276808\n",
      ">>>>>>  EPOCH 7: validation score 0.1486284289276808\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 3.4023611545562744\n",
      ". . . batch: 41, batch_loss: 3.217398166656494\n",
      ". . . batch: 82, batch_loss: 3.116806745529175\n",
      ". . . batch: 123, batch_loss: 3.1279520988464355\n",
      "EPOCH: 8, train_loss: 3.1202896900177017, val_loss: 3.7301774695515633, val_score: 0.15511221945137157\n",
      ">>>>>>  EPOCH 8: validation score 0.15511221945137157\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.48183274269104\n",
      ". . . batch: 41, batch_loss: 2.8200490474700928\n",
      ". . . batch: 82, batch_loss: 2.7771501541137695\n",
      ". . . batch: 123, batch_loss: 2.1133251190185547\n",
      "EPOCH: 9, train_loss: 2.6360792045593255, val_loss: 2.57363148778677, val_score: 0.3197007481296758\n",
      ">>>>>>  EPOCH 9: validation score 0.3197007481296758\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 2.033456802368164\n",
      ". . . batch: 41, batch_loss: 2.322256088256836\n",
      ". . . batch: 82, batch_loss: 2.2574775218963623\n",
      ". . . batch: 123, batch_loss: 1.6275514364242554\n",
      "EPOCH: 10, train_loss: 2.1913798646926885, val_loss: 2.2288950830698013, val_score: 0.42693266832917703\n",
      ">>>>>>  EPOCH 10: validation score 0.42693266832917703\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.763359546661377\n",
      ". . . batch: 41, batch_loss: 2.0077531337738037\n",
      ". . . batch: 82, batch_loss: 1.2959781885147095\n",
      ". . . batch: 123, batch_loss: 1.8533282279968262\n",
      "EPOCH: 11, train_loss: 1.7893787326812733, val_loss: 1.9681777246296406, val_score: 0.4723192019950125\n",
      ">>>>>>  EPOCH 11: validation score 0.4723192019950125\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.3218953609466553\n",
      ". . . batch: 41, batch_loss: 1.9055757522583008\n",
      ". . . batch: 82, batch_loss: 1.5926073789596558\n",
      ". . . batch: 123, batch_loss: 1.467652678489685\n",
      "EPOCH: 12, train_loss: 1.4818875360488888, val_loss: 2.684720251709223, val_score: 0.35012468827930177\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.308409333229065\n",
      ". . . batch: 41, batch_loss: 1.1755539178848267\n",
      ". . . batch: 82, batch_loss: 1.4096753597259521\n",
      ". . . batch: 123, batch_loss: 1.1053401231765747\n",
      "EPOCH: 13, train_loss: 1.242403886318206, val_loss: 1.853622306138277, val_score: 0.5117206982543641\n",
      ">>>>>>  EPOCH 13: validation score 0.5117206982543641\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 1.055190086364746\n",
      ". . . batch: 41, batch_loss: 0.7187214493751526\n",
      ". . . batch: 82, batch_loss: 1.3466591835021973\n",
      ". . . batch: 123, batch_loss: 1.5793582201004028\n",
      "EPOCH: 14, train_loss: 1.01035686635971, val_loss: 1.581152755767107, val_score: 0.5780548628428928\n",
      ">>>>>>  EPOCH 14: validation score 0.5780548628428928\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.8346695303916931\n",
      ". . . batch: 41, batch_loss: 0.9314824938774109\n",
      ". . . batch: 82, batch_loss: 0.6605009436607361\n",
      ". . . batch: 123, batch_loss: 0.978154182434082\n",
      "EPOCH: 15, train_loss: 0.8486760387420655, val_loss: 1.3903560489416122, val_score: 0.6164588528678304\n",
      ">>>>>>  EPOCH 15: validation score 0.6164588528678304\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.5602161288261414\n",
      ". . . batch: 41, batch_loss: 0.7495927810668945\n",
      ". . . batch: 82, batch_loss: 0.8326491117477417\n",
      ". . . batch: 123, batch_loss: 0.6106997132301331\n",
      "EPOCH: 16, train_loss: 0.7437801125049596, val_loss: 1.3097454495728016, val_score: 0.6468827930174563\n",
      ">>>>>>  EPOCH 16: validation score 0.6468827930174563\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.5827696919441223\n",
      ". . . batch: 41, batch_loss: 0.4976133108139038\n",
      ". . . batch: 82, batch_loss: 0.9084897041320801\n",
      ". . . batch: 123, batch_loss: 0.5628044605255127\n",
      "EPOCH: 17, train_loss: 0.6275479085445401, val_loss: 1.242121621966362, val_score: 0.6723192019950125\n",
      ">>>>>>  EPOCH 17: validation score 0.6723192019950125\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.5272115468978882\n",
      ". . . batch: 41, batch_loss: 0.4947759509086609\n",
      ". . . batch: 82, batch_loss: 0.5244370102882385\n",
      ". . . batch: 123, batch_loss: 0.4175218343734741\n",
      "EPOCH: 18, train_loss: 0.5423674366474153, val_loss: 1.2307532597333193, val_score: 0.686284289276808\n",
      ">>>>>>  EPOCH 18: validation score 0.686284289276808\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.44112688302993774\n",
      ". . . batch: 41, batch_loss: 0.42575502395629883\n",
      ". . . batch: 82, batch_loss: 0.3859831392765045\n",
      ". . . batch: 123, batch_loss: 0.6201140284538269\n",
      "EPOCH: 19, train_loss: 0.45948816847801205, val_loss: 1.3208228703588247, val_score: 0.6608478802992519\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.5570939779281616\n",
      ". . . batch: 41, batch_loss: 0.232547327876091\n",
      ". . . batch: 82, batch_loss: 0.4063989818096161\n",
      ". . . batch: 123, batch_loss: 0.2652846872806549\n",
      "EPOCH: 20, train_loss: 0.39820337343215956, val_loss: 1.1353462282568216, val_score: 0.6997506234413965\n",
      ">>>>>>  EPOCH 20: validation score 0.6997506234413965\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.3887375593185425\n",
      ". . . batch: 41, batch_loss: 0.35864752531051636\n",
      ". . . batch: 82, batch_loss: 0.361627459526062\n",
      ". . . batch: 123, batch_loss: 0.46589139103889465\n",
      "EPOCH: 21, train_loss: 0.32688870155811306, val_loss: 1.0645248480141163, val_score: 0.7346633416458854\n",
      ">>>>>>  EPOCH 21: validation score 0.7346633416458854\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.28979241847991943\n",
      ". . . batch: 41, batch_loss: 0.377763569355011\n",
      ". . . batch: 82, batch_loss: 0.23221813142299652\n",
      ". . . batch: 123, batch_loss: 0.2747645676136017\n",
      "EPOCH: 22, train_loss: 0.30819140452146526, val_loss: 1.246492650359869, val_score: 0.6907730673316709\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.22400414943695068\n",
      ". . . batch: 41, batch_loss: 0.35289502143859863\n",
      ". . . batch: 82, batch_loss: 0.4786936342716217\n",
      ". . . batch: 123, batch_loss: 0.2144346833229065\n",
      "EPOCH: 23, train_loss: 0.2899316394329071, val_loss: 1.109217593446374, val_score: 0.7057356608478803\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.16701319813728333\n",
      ". . . batch: 41, batch_loss: 0.25180694460868835\n",
      ". . . batch: 82, batch_loss: 0.09168574213981628\n",
      ". . . batch: 123, batch_loss: 0.3328595459461212\n",
      "EPOCH: 24, train_loss: 0.26160897028446195, val_loss: 1.223020987585187, val_score: 0.6962593516209477\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.2994135320186615\n",
      ". . . batch: 41, batch_loss: 0.2915918231010437\n",
      ". . . batch: 82, batch_loss: 0.18124336004257202\n",
      ". . . batch: 123, batch_loss: 0.24625009298324585\n",
      "EPOCH: 25, train_loss: 0.2243001240491867, val_loss: 1.0744609218090773, val_score: 0.7456359102244389\n",
      ">>>>>>  EPOCH 25: validation score 0.7456359102244389\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.10826531052589417\n",
      ". . . batch: 41, batch_loss: 0.25520646572113037\n",
      ". . . batch: 82, batch_loss: 0.17313167452812195\n",
      ". . . batch: 123, batch_loss: 0.11815977096557617\n",
      "EPOCH: 26, train_loss: 0.20547938340902325, val_loss: 0.9750799350440502, val_score: 0.7675810473815461\n",
      ">>>>>>  EPOCH 26: validation score 0.7675810473815461\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.0455523282289505\n",
      ". . . batch: 41, batch_loss: 0.11689542233943939\n",
      ". . . batch: 82, batch_loss: 0.23053915798664093\n",
      ". . . batch: 123, batch_loss: 0.15320312976837158\n",
      "EPOCH: 27, train_loss: 0.179798708498478, val_loss: 1.0281360261142254, val_score: 0.7571072319201996\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.21988309919834137\n",
      ". . . batch: 41, batch_loss: 0.10562849789857864\n",
      ". . . batch: 82, batch_loss: 0.2195335030555725\n",
      ". . . batch: 123, batch_loss: 0.20698118209838867\n",
      "EPOCH: 28, train_loss: 0.16650171905755998, val_loss: 1.4121376294642687, val_score: 0.7022443890274315\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.09165624529123306\n",
      ". . . batch: 41, batch_loss: 0.20165590941905975\n",
      ". . . batch: 82, batch_loss: 0.09650635719299316\n",
      ". . . batch: 123, batch_loss: 0.1186119019985199\n",
      "EPOCH: 29, train_loss: 0.16181510743498814, val_loss: 1.1795205902308226, val_score: 0.7331670822942643\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.10535676032304764\n",
      ". . . batch: 41, batch_loss: 0.2014051079750061\n",
      ". . . batch: 82, batch_loss: 0.14926382899284363\n",
      ". . . batch: 123, batch_loss: 0.07199439406394958\n",
      "EPOCH: 30, train_loss: 0.1625627728104591, val_loss: 1.1030497960746288, val_score: 0.7381546134663342\n",
      "{'best_epoch': 26, 'best_score': 0.7675810473815461}\n"
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 2\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.306703090667725\n",
      ". . . batch: 42, batch_loss: 5.252557277679443\n",
      ". . . batch: 84, batch_loss: 5.26295804977417\n",
      "EPOCH: 1, train_loss: 5.305460506015354, val_loss: 5.159873300983061, val_score: 0.013272077590607452\n",
      ">>>>>>  EPOCH 1: validation score 0.013272077590607452\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.055030345916748\n",
      ". . . batch: 42, batch_loss: 5.198235988616943\n",
      ". . . batch: 84, batch_loss: 5.10764217376709\n",
      "EPOCH: 2, train_loss: 5.073299869658456, val_loss: 5.051805280870007, val_score: 0.02450229709035222\n",
      ">>>>>>  EPOCH 2: validation score 0.02450229709035222\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 4.942602634429932\n",
      ". . . batch: 42, batch_loss: 4.688323497772217\n",
      ". . . batch: 84, batch_loss: 4.750643730163574\n",
      "EPOCH: 3, train_loss: 4.892513312990702, val_loss: 4.857319678029706, val_score: 0.03522205206738132\n",
      ">>>>>>  EPOCH 3: validation score 0.03522205206738132\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.714207172393799\n",
      ". . . batch: 42, batch_loss: 4.659719944000244\n",
      ". . . batch: 84, batch_loss: 4.514183521270752\n",
      "EPOCH: 4, train_loss: 4.615775747904702, val_loss: 4.997865784552789, val_score: 0.04134762633996937\n",
      ">>>>>>  EPOCH 4: validation score 0.04134762633996937\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 4.240139007568359\n",
      ". . . batch: 42, batch_loss: 4.1761980056762695\n",
      ". . . batch: 84, batch_loss: 3.860159397125244\n",
      "EPOCH: 5, train_loss: 4.20761485326858, val_loss: 4.195309915850238, val_score: 0.07299642674834099\n",
      ">>>>>>  EPOCH 5: validation score 0.07299642674834099\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 4.001617431640625\n",
      ". . . batch: 42, batch_loss: 3.912468671798706\n",
      ". . . batch: 84, batch_loss: 3.8924977779388428\n",
      "EPOCH: 6, train_loss: 3.803704288270738, val_loss: 3.7940554618835454, val_score: 0.11944869831546708\n",
      ">>>>>>  EPOCH 6: validation score 0.11944869831546708\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.2688183784484863\n",
      ". . . batch: 42, batch_loss: 3.538572072982788\n",
      ". . . batch: 84, batch_loss: 3.4439425468444824\n",
      "EPOCH: 7, train_loss: 3.393247017784726, val_loss: 3.602232779225995, val_score: 0.1689637570188872\n",
      ">>>>>>  EPOCH 7: validation score 0.1689637570188872\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 2.971660614013672\n",
      ". . . batch: 42, batch_loss: 2.7383341789245605\n",
      ". . . batch: 84, batch_loss: 2.608372449874878\n",
      "EPOCH: 8, train_loss: 2.9544225552725414, val_loss: 4.521689930269795, val_score: 0.1082184788157223\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.845824956893921\n",
      ". . . batch: 42, batch_loss: 2.443880558013916\n",
      ". . . batch: 84, batch_loss: 2.5492827892303467\n",
      "EPOCH: 9, train_loss: 2.54437021792881, val_loss: 2.812385505245578, val_score: 0.2720775906074528\n",
      ">>>>>>  EPOCH 9: validation score 0.2720775906074528\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 1.7843108177185059\n",
      ". . . batch: 42, batch_loss: 2.249185800552368\n",
      ". . . batch: 84, batch_loss: 2.1590709686279297\n",
      "EPOCH: 10, train_loss: 2.1185169305120195, val_loss: 2.2509724978477723, val_score: 0.4134762633996938\n",
      ">>>>>>  EPOCH 10: validation score 0.4134762633996938\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.5477994680404663\n",
      ". . . batch: 42, batch_loss: 1.4773885011672974\n",
      ". . . batch: 84, batch_loss: 1.7202433347702026\n",
      "EPOCH: 11, train_loss: 1.810395035478803, val_loss: 2.726151854761186, val_score: 0.3282286881061766\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.466099500656128\n",
      ". . . batch: 42, batch_loss: 1.3734652996063232\n",
      ". . . batch: 84, batch_loss: 1.3427180051803589\n",
      "EPOCH: 12, train_loss: 1.527467843086, val_loss: 2.158757705842295, val_score: 0.4333843797856049\n",
      ">>>>>>  EPOCH 12: validation score 0.4333843797856049\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.1446233987808228\n",
      ". . . batch: 42, batch_loss: 1.177709937095642\n",
      ". . . batch: 84, batch_loss: 1.623713493347168\n",
      "EPOCH: 13, train_loss: 1.2607060008578839, val_loss: 1.64253173335906, val_score: 0.5604900459418071\n",
      ">>>>>>  EPOCH 13: validation score 0.5604900459418071\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 0.9308332204818726\n",
      ". . . batch: 42, batch_loss: 1.0193840265274048\n",
      ". . . batch: 84, batch_loss: 1.2002263069152832\n",
      "EPOCH: 14, train_loss: 1.064967214115082, val_loss: 1.6190986402573124, val_score: 0.5681470137825421\n",
      ">>>>>>  EPOCH 14: validation score 0.5681470137825421\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.9076053500175476\n",
      ". . . batch: 42, batch_loss: 0.9322801232337952\n",
      ". . . batch: 84, batch_loss: 0.7746056318283081\n",
      "EPOCH: 15, train_loss: 0.9131709881245142, val_loss: 1.4874462696813773, val_score: 0.6079632465543645\n",
      ">>>>>>  EPOCH 15: validation score 0.6079632465543645\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.5541864037513733\n",
      ". . . batch: 42, batch_loss: 0.961952805519104\n",
      ". . . batch: 84, batch_loss: 0.7277128100395203\n",
      "EPOCH: 16, train_loss: 0.7896234979705208, val_loss: 1.4220444906142449, val_score: 0.6151097498723839\n",
      ">>>>>>  EPOCH 16: validation score 0.6151097498723839\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.5774226188659668\n",
      ". . . batch: 42, batch_loss: 0.6715574264526367\n",
      ". . . batch: 84, batch_loss: 0.6891493201255798\n",
      "EPOCH: 17, train_loss: 0.6521446508547615, val_loss: 1.3293644401334948, val_score: 0.635017866258295\n",
      ">>>>>>  EPOCH 17: validation score 0.635017866258295\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.35399484634399414\n",
      ". . . batch: 42, batch_loss: 0.6459411978721619\n",
      ". . . batch: 84, batch_loss: 0.6866222620010376\n",
      "EPOCH: 18, train_loss: 0.5793705459625001, val_loss: 1.5138073198256958, val_score: 0.6018376722817764\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.34726670384407043\n",
      ". . . batch: 42, batch_loss: 0.3432404398918152\n",
      ". . . batch: 84, batch_loss: 0.37925222516059875\n",
      "EPOCH: 19, train_loss: 0.5106981323351932, val_loss: 1.3467827420080865, val_score: 0.6457376212353242\n",
      ">>>>>>  EPOCH 19: validation score 0.6457376212353242\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.5177192091941833\n",
      ". . . batch: 42, batch_loss: 0.47109270095825195\n",
      ". . . batch: 84, batch_loss: 0.5424900650978088\n",
      "EPOCH: 20, train_loss: 0.4822896423320921, val_loss: 1.370051908877588, val_score: 0.6569678407350689\n",
      ">>>>>>  EPOCH 20: validation score 0.6569678407350689\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.32546162605285645\n",
      ". . . batch: 42, batch_loss: 0.41319069266319275\n",
      ". . . batch: 84, batch_loss: 0.4644485116004944\n",
      "EPOCH: 21, train_loss: 0.38342603828225796, val_loss: 1.4040727403856097, val_score: 0.6447166921898928\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.2742292284965515\n",
      ". . . batch: 42, batch_loss: 0.4253712296485901\n",
      ". . . batch: 84, batch_loss: 0.36974209547042847\n",
      "EPOCH: 22, train_loss: 0.34364551897086815, val_loss: 1.3671183105437983, val_score: 0.6651352730985196\n",
      ">>>>>>  EPOCH 22: validation score 0.6651352730985196\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.36068904399871826\n",
      ". . . batch: 42, batch_loss: 0.2746874988079071\n",
      ". . . batch: 84, batch_loss: 0.2535579204559326\n",
      "EPOCH: 23, train_loss: 0.3073867548789298, val_loss: 1.0832049212148116, val_score: 0.7187340479836652\n",
      ">>>>>>  EPOCH 23: validation score 0.7187340479836652\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.2322194129228592\n",
      ". . . batch: 42, batch_loss: 0.09936778992414474\n",
      ". . . batch: 84, batch_loss: 0.28391656279563904\n",
      "EPOCH: 24, train_loss: 0.2785469485772035, val_loss: 1.2210778074879798, val_score: 0.6830015313935681\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.36751899123191833\n",
      ". . . batch: 42, batch_loss: 0.38221409916877747\n",
      ". . . batch: 84, batch_loss: 0.29493898153305054\n",
      "EPOCH: 25, train_loss: 0.2699561796136319, val_loss: 1.1281454063230945, val_score: 0.7151607963246555\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.18426106870174408\n",
      ". . . batch: 42, batch_loss: 0.14771439135074615\n",
      ". . . batch: 84, batch_loss: 0.2726268172264099\n",
      "EPOCH: 26, train_loss: 0.25063853143226533, val_loss: 1.1144617911308043, val_score: 0.7289433384379785\n",
      ">>>>>>  EPOCH 26: validation score 0.7289433384379785\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.23958814144134521\n",
      ". . . batch: 42, batch_loss: 0.24590104818344116\n",
      ". . . batch: 84, batch_loss: 0.0828983336687088\n",
      "EPOCH: 27, train_loss: 0.20609382427637526, val_loss: 1.126501963984582, val_score: 0.733027054619704\n",
      ">>>>>>  EPOCH 27: validation score 0.733027054619704\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.12283952534198761\n",
      ". . . batch: 42, batch_loss: 0.25407320261001587\n",
      ". . . batch: 84, batch_loss: 0.2244056761264801\n",
      "EPOCH: 28, train_loss: 0.20364580531087206, val_loss: 1.1313787871791472, val_score: 0.7258805513016844\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.12052886933088303\n",
      ". . . batch: 42, batch_loss: 0.20198115706443787\n",
      ". . . batch: 84, batch_loss: 0.3451491594314575\n",
      "EPOCH: 29, train_loss: 0.19182140989199523, val_loss: 1.1438036580239574, val_score: 0.7202654415518122\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.37083229422569275\n",
      ". . . batch: 42, batch_loss: 0.1215929388999939\n",
      ". . . batch: 84, batch_loss: 0.15244174003601074\n",
      "EPOCH: 30, train_loss: 0.1700387460490069, val_loss: 1.187866134028281, val_score: 0.7248596222562532\n",
      "{'best_epoch': 27, 'best_score': 0.733027054619704}\n"
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 3\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.31112813949585\n",
      ". . . batch: 42, batch_loss: 5.272105693817139\n",
      ". . . batch: 84, batch_loss: 5.215747356414795\n",
      ". . . batch: 126, batch_loss: 4.970615863800049\n",
      "EPOCH: 1, train_loss: 5.304517715934694, val_loss: 5.260423183441164, val_score: 0.015690376569037656\n",
      ">>>>>>  EPOCH 1: validation score 0.015690376569037656\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.127444744110107\n",
      ". . . batch: 42, batch_loss: 5.217661380767822\n",
      ". . . batch: 84, batch_loss: 5.090995788574219\n",
      ". . . batch: 126, batch_loss: 5.328627586364746\n",
      "EPOCH: 2, train_loss: 5.151388648926743, val_loss: 5.133008464177449, val_score: 0.016213389121338913\n",
      ">>>>>>  EPOCH 2: validation score 0.016213389121338913\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 5.046844959259033\n",
      ". . . batch: 42, batch_loss: 5.177473545074463\n",
      ". . . batch: 84, batch_loss: 4.997420310974121\n",
      ". . . batch: 126, batch_loss: 5.019209384918213\n",
      "EPOCH: 3, train_loss: 5.065052558117965, val_loss: 5.0455094178517665, val_score: 0.021966527196652718\n",
      ">>>>>>  EPOCH 3: validation score 0.021966527196652718\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.989376068115234\n",
      ". . . batch: 42, batch_loss: 4.907923221588135\n",
      ". . . batch: 84, batch_loss: 5.024835586547852\n",
      ". . . batch: 126, batch_loss: 4.818626403808594\n",
      "EPOCH: 4, train_loss: 4.949082960293989, val_loss: 4.918012746175129, val_score: 0.02981171548117155\n",
      ">>>>>>  EPOCH 4: validation score 0.02981171548117155\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 4.745466232299805\n",
      ". . . batch: 42, batch_loss: 4.820362091064453\n",
      ". . . batch: 84, batch_loss: 4.684454917907715\n",
      ". . . batch: 126, batch_loss: 4.1531500816345215\n",
      "EPOCH: 5, train_loss: 4.7590857227956205, val_loss: 5.159678697586059, val_score: 0.028765690376569036\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 4.687284469604492\n",
      ". . . batch: 42, batch_loss: 4.580353736877441\n",
      ". . . batch: 84, batch_loss: 4.106041431427002\n",
      ". . . batch: 126, batch_loss: 4.84557580947876\n",
      "EPOCH: 6, train_loss: 4.501911696486587, val_loss: 5.142596737543741, val_score: 0.043933054393305436\n",
      ">>>>>>  EPOCH 6: validation score 0.043933054393305436\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 4.575375556945801\n",
      ". . . batch: 42, batch_loss: 3.994457244873047\n",
      ". . . batch: 84, batch_loss: 3.9127719402313232\n",
      ". . . batch: 126, batch_loss: 3.879438877105713\n",
      "EPOCH: 7, train_loss: 4.172815200850721, val_loss: 4.3289413611094165, val_score: 0.06589958158995816\n",
      ">>>>>>  EPOCH 7: validation score 0.06589958158995816\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 4.0066986083984375\n",
      ". . . batch: 42, batch_loss: 3.9003729820251465\n",
      ". . . batch: 84, batch_loss: 3.582965612411499\n",
      ". . . batch: 126, batch_loss: 3.85876202583313\n",
      "EPOCH: 8, train_loss: 3.7667191328964806, val_loss: 3.931717777252198, val_score: 0.11401673640167365\n",
      ">>>>>>  EPOCH 8: validation score 0.11401673640167365\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 3.331784963607788\n",
      ". . . batch: 42, batch_loss: 3.538304567337036\n",
      ". . . batch: 84, batch_loss: 3.3117733001708984\n",
      ". . . batch: 126, batch_loss: 3.084000825881958\n",
      "EPOCH: 9, train_loss: 3.351160107635137, val_loss: 4.4390117088953644, val_score: 0.11192468619246862\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 3.053972005844116\n",
      ". . . batch: 42, batch_loss: 3.2506680488586426\n",
      ". . . batch: 84, batch_loss: 2.4927690029144287\n",
      ". . . batch: 126, batch_loss: 2.8534679412841797\n",
      "EPOCH: 10, train_loss: 2.926093030163621, val_loss: 3.191602039337158, val_score: 0.2170502092050209\n",
      ">>>>>>  EPOCH 10: validation score 0.2170502092050209\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 2.8355588912963867\n",
      ". . . batch: 42, batch_loss: 2.6827621459960938\n",
      ". . . batch: 84, batch_loss: 2.4241738319396973\n",
      ". . . batch: 126, batch_loss: 2.545764446258545\n",
      "EPOCH: 11, train_loss: 2.460869295390571, val_loss: 2.8271025339762375, val_score: 0.27876569037656906\n",
      ">>>>>>  EPOCH 11: validation score 0.27876569037656906\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 2.2463812828063965\n",
      ". . . batch: 42, batch_loss: 2.2562575340270996\n",
      ". . . batch: 84, batch_loss: 1.942612648010254\n",
      ". . . batch: 126, batch_loss: 1.8504632711410522\n",
      "EPOCH: 12, train_loss: 2.075541853904724, val_loss: 2.5980336666107178, val_score: 0.3389121338912134\n",
      ">>>>>>  EPOCH 12: validation score 0.3389121338912134\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.6436361074447632\n",
      ". . . batch: 42, batch_loss: 1.9287869930267334\n",
      ". . . batch: 84, batch_loss: 1.7469103336334229\n",
      ". . . batch: 126, batch_loss: 2.056934356689453\n",
      "EPOCH: 13, train_loss: 1.6973386627482607, val_loss: 2.444923142592112, val_score: 0.3723849372384937\n",
      ">>>>>>  EPOCH 13: validation score 0.3723849372384937\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 1.122275471687317\n",
      ". . . batch: 42, batch_loss: 1.3765199184417725\n",
      ". . . batch: 84, batch_loss: 1.3235993385314941\n",
      ". . . batch: 126, batch_loss: 1.3037526607513428\n",
      "EPOCH: 14, train_loss: 1.394102292267357, val_loss: 2.0071994781494134, val_score: 0.45292887029288703\n",
      ">>>>>>  EPOCH 14: validation score 0.45292887029288703\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 1.0914421081542969\n",
      ". . . batch: 42, batch_loss: 1.2710522413253784\n",
      ". . . batch: 84, batch_loss: 0.9123440980911255\n",
      ". . . batch: 126, batch_loss: 0.9664159417152405\n",
      "EPOCH: 15, train_loss: 1.1766802607558842, val_loss: 2.0896974881490076, val_score: 0.446652719665272\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 1.2400885820388794\n",
      ". . . batch: 42, batch_loss: 0.8305457830429077\n",
      ". . . batch: 84, batch_loss: 0.9104020595550537\n",
      ". . . batch: 126, batch_loss: 1.3429911136627197\n",
      "EPOCH: 16, train_loss: 0.9797853146951028, val_loss: 1.7003512899080913, val_score: 0.5428870292887029\n",
      ">>>>>>  EPOCH 16: validation score 0.5428870292887029\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 1.021306037902832\n",
      ". . . batch: 42, batch_loss: 0.7636938691139221\n",
      ". . . batch: 84, batch_loss: 0.889346718788147\n",
      ". . . batch: 126, batch_loss: 1.75655198097229\n",
      "EPOCH: 17, train_loss: 0.868668786184055, val_loss: 1.5076281825701394, val_score: 0.5957112970711297\n",
      ">>>>>>  EPOCH 17: validation score 0.5957112970711297\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.5978224277496338\n",
      ". . . batch: 42, batch_loss: 0.7927093505859375\n",
      ". . . batch: 84, batch_loss: 0.9984676241874695\n",
      ". . . batch: 126, batch_loss: 1.1874122619628906\n",
      "EPOCH: 18, train_loss: 0.7349663067051746, val_loss: 1.3574868480364484, val_score: 0.6297071129707112\n",
      ">>>>>>  EPOCH 18: validation score 0.6297071129707112\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.4065970778465271\n",
      ". . . batch: 42, batch_loss: 0.5532727241516113\n",
      ". . . batch: 84, batch_loss: 0.8205947875976562\n",
      ". . . batch: 126, batch_loss: 0.9511653780937195\n",
      "EPOCH: 19, train_loss: 0.6263974975413226, val_loss: 1.2236615737279255, val_score: 0.6668410041841004\n",
      ">>>>>>  EPOCH 19: validation score 0.6668410041841004\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.398635596036911\n",
      ". . . batch: 42, batch_loss: 0.3923530578613281\n",
      ". . . batch: 84, batch_loss: 0.5461609363555908\n",
      ". . . batch: 126, batch_loss: 0.8771846890449524\n",
      "EPOCH: 20, train_loss: 0.5370740078565642, val_loss: 1.41879966656367, val_score: 0.6344142259414226\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.6470144391059875\n",
      ". . . batch: 42, batch_loss: 0.5668746829032898\n",
      ". . . batch: 84, batch_loss: 0.49240514636039734\n",
      ". . . batch: 126, batch_loss: 1.162648320198059\n",
      "EPOCH: 21, train_loss: 0.4901996786434819, val_loss: 1.302632357676824, val_score: 0.6537656903765691\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.3178377151489258\n",
      ". . . batch: 42, batch_loss: 0.5436668992042542\n",
      ". . . batch: 84, batch_loss: 0.48616960644721985\n",
      ". . . batch: 126, batch_loss: 0.8769140243530273\n",
      "EPOCH: 22, train_loss: 0.4195341510096873, val_loss: 1.1880606452624, val_score: 0.6888075313807531\n",
      ">>>>>>  EPOCH 22: validation score 0.6888075313807531\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.3254328966140747\n",
      ". . . batch: 42, batch_loss: 0.25954991579055786\n",
      ". . . batch: 84, batch_loss: 0.4187767803668976\n",
      ". . . batch: 126, batch_loss: 0.6859063506126404\n",
      "EPOCH: 23, train_loss: 0.40030091508166976, val_loss: 1.4429426809151966, val_score: 0.6459205020920502\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.22045832872390747\n",
      ". . . batch: 42, batch_loss: 0.33809956908226013\n",
      ". . . batch: 84, batch_loss: 0.3208064138889313\n",
      ". . . batch: 126, batch_loss: 0.5541233420372009\n",
      "EPOCH: 24, train_loss: 0.3332763859840828, val_loss: 1.2287581404050192, val_score: 0.6872384937238494\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.27499282360076904\n",
      ". . . batch: 42, batch_loss: 0.37429189682006836\n",
      ". . . batch: 84, batch_loss: 0.1833002120256424\n",
      ". . . batch: 126, batch_loss: 0.5199460983276367\n",
      "EPOCH: 25, train_loss: 0.2644054323552162, val_loss: 1.3315160910288495, val_score: 0.674163179916318\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.3370189666748047\n",
      ". . . batch: 42, batch_loss: 0.2895922362804413\n",
      ". . . batch: 84, batch_loss: 0.17980727553367615\n",
      ". . . batch: 126, batch_loss: 0.42403820157051086\n",
      "EPOCH: 26, train_loss: 0.2694843480084826, val_loss: 1.2997955083847048, val_score: 0.6976987447698745\n",
      ">>>>>>  EPOCH 26: validation score 0.6976987447698745\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.22106754779815674\n",
      ". . . batch: 42, batch_loss: 0.24028795957565308\n",
      ". . . batch: 84, batch_loss: 0.16340509057044983\n",
      ". . . batch: 126, batch_loss: 0.3967561423778534\n",
      "EPOCH: 27, train_loss: 0.19823645292891293, val_loss: 1.167024258772532, val_score: 0.7186192468619247\n",
      ">>>>>>  EPOCH 27: validation score 0.7186192468619247\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.20506185293197632\n",
      ". . . batch: 42, batch_loss: 0.17448849976062775\n",
      ". . . batch: 84, batch_loss: 0.232558935880661\n",
      ". . . batch: 126, batch_loss: 0.20079681277275085\n",
      "EPOCH: 28, train_loss: 0.22229971232142032, val_loss: 1.57665827870369, val_score: 0.6558577405857741\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.2036460041999817\n",
      ". . . batch: 42, batch_loss: 0.10597353428602219\n",
      ". . . batch: 84, batch_loss: 0.20027364790439606\n",
      ". . . batch: 126, batch_loss: 0.28216731548309326\n",
      "EPOCH: 29, train_loss: 0.19712586909180554, val_loss: 1.322766665617625, val_score: 0.6997907949790795\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.1859784573316574\n",
      ". . . batch: 42, batch_loss: 0.13342857360839844\n",
      ". . . batch: 84, batch_loss: 0.16397613286972046\n",
      ". . . batch: 126, batch_loss: 0.10516870021820068\n",
      "EPOCH: 30, train_loss: 0.18985921698879069, val_loss: 1.1717539151509604, val_score: 0.7285564853556487\n",
      ">>>>>>  EPOCH 30: validation score 0.7285564853556487\n",
      "{'best_epoch': 30, 'best_score': 0.7285564853556487}\n"
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 4\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0 fold -----\n",
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.306539058685303\n",
      ". . . batch: 30, batch_loss: 5.304599285125732\n",
      ". . . batch: 60, batch_loss: 5.30805778503418\n",
      ". . . batch: 90, batch_loss: 5.3574538230896\n",
      ". . . batch: 120, batch_loss: 5.274111747741699\n",
      ". . . batch: 150, batch_loss: 5.165017127990723\n",
      ". . . batch: 180, batch_loss: 5.173110008239746\n",
      ". . . batch: 210, batch_loss: 5.233755111694336\n",
      ". . . batch: 240, batch_loss: 5.241053581237793\n",
      "EPOCH: 1, train_loss: 5.272678929747959, val_loss: 5.1790149075644365, val_score: 0.023603082851637765\n",
      ">>>>>>  EPOCH 1: validation score 0.023603082851637765\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.17225980758667\n",
      ". . . batch: 30, batch_loss: 5.246551513671875\n",
      ". . . batch: 60, batch_loss: 5.180649280548096\n",
      ". . . batch: 90, batch_loss: 5.047900199890137\n",
      ". . . batch: 120, batch_loss: 5.113183975219727\n",
      ". . . batch: 150, batch_loss: 5.078338623046875\n",
      ". . . batch: 180, batch_loss: 5.058002948760986\n",
      ". . . batch: 210, batch_loss: 4.926807880401611\n",
      ". . . batch: 240, batch_loss: 4.933359146118164\n",
      "EPOCH: 2, train_loss: 5.071676503528247, val_loss: 4.8729965686798105, val_score: 0.06021194605009634\n",
      ">>>>>>  EPOCH 2: validation score 0.06021194605009634\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 4.881667613983154\n",
      ". . . batch: 30, batch_loss: 4.88283634185791\n",
      ". . . batch: 60, batch_loss: 4.7613606452941895\n",
      ". . . batch: 90, batch_loss: 4.796080589294434\n",
      ". . . batch: 120, batch_loss: 4.698339462280273\n",
      ". . . batch: 150, batch_loss: 4.777329444885254\n",
      ". . . batch: 180, batch_loss: 4.612691879272461\n",
      ". . . batch: 210, batch_loss: 4.485635280609131\n",
      ". . . batch: 240, batch_loss: 4.355616092681885\n",
      "EPOCH: 3, train_loss: 4.678487685593692, val_loss: 4.420596848215376, val_score: 0.11705202312138728\n",
      ">>>>>>  EPOCH 3: validation score 0.11705202312138728\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.540595054626465\n",
      ". . . batch: 30, batch_loss: 4.2429022789001465\n",
      ". . . batch: 60, batch_loss: 4.3343939781188965\n",
      ". . . batch: 90, batch_loss: 4.645994663238525\n",
      ". . . batch: 120, batch_loss: 3.9156787395477295\n",
      ". . . batch: 150, batch_loss: 4.218480587005615\n",
      ". . . batch: 180, batch_loss: 3.9224133491516113\n",
      ". . . batch: 210, batch_loss: 4.006406784057617\n",
      ". . . batch: 240, batch_loss: 4.02776575088501\n",
      "EPOCH: 4, train_loss: 4.255297007885847, val_loss: 4.024938545908247, val_score: 0.1710019267822736\n",
      ">>>>>>  EPOCH 4: validation score 0.1710019267822736\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 3.948216676712036\n",
      ". . . batch: 30, batch_loss: 3.967377185821533\n",
      ". . . batch: 60, batch_loss: 4.270901203155518\n",
      ". . . batch: 90, batch_loss: 4.013476371765137\n",
      ". . . batch: 120, batch_loss: 3.9824066162109375\n",
      ". . . batch: 150, batch_loss: 3.9048221111297607\n",
      ". . . batch: 180, batch_loss: 3.651360511779785\n",
      ". . . batch: 210, batch_loss: 3.829716444015503\n",
      ". . . batch: 240, batch_loss: 3.757999897003174\n",
      "EPOCH: 5, train_loss: 3.84492747982343, val_loss: 3.6296664544514248, val_score: 0.22302504816955687\n",
      ">>>>>>  EPOCH 5: validation score 0.22302504816955687\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 3.6358230113983154\n",
      ". . . batch: 30, batch_loss: 3.678720235824585\n",
      ". . . batch: 60, batch_loss: 3.4046339988708496\n",
      ". . . batch: 90, batch_loss: 3.4119722843170166\n",
      ". . . batch: 120, batch_loss: 3.376479387283325\n",
      ". . . batch: 150, batch_loss: 3.480116605758667\n",
      ". . . batch: 180, batch_loss: 2.9752285480499268\n",
      ". . . batch: 210, batch_loss: 3.3258249759674072\n",
      ". . . batch: 240, batch_loss: 3.4167697429656982\n",
      "EPOCH: 6, train_loss: 3.4585423568884552, val_loss: 3.2519381523132327, val_score: 0.2832369942196532\n",
      ">>>>>>  EPOCH 6: validation score 0.2832369942196532\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.1802308559417725\n",
      ". . . batch: 30, batch_loss: 3.040349006652832\n",
      ". . . batch: 60, batch_loss: 3.2641656398773193\n",
      ". . . batch: 90, batch_loss: 3.273561716079712\n",
      ". . . batch: 120, batch_loss: 3.280194044113159\n",
      ". . . batch: 150, batch_loss: 2.7208313941955566\n",
      ". . . batch: 180, batch_loss: 3.000352382659912\n",
      ". . . batch: 210, batch_loss: 2.8027148246765137\n",
      ". . . batch: 240, batch_loss: 2.742377519607544\n",
      "EPOCH: 7, train_loss: 3.0857145289580035, val_loss: 2.938404628208704, val_score: 0.36175337186897877\n",
      ">>>>>>  EPOCH 7: validation score 0.36175337186897877\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 2.7285332679748535\n",
      ". . . batch: 30, batch_loss: 2.629702568054199\n",
      ". . . batch: 60, batch_loss: 2.656930446624756\n",
      ". . . batch: 90, batch_loss: 2.6168484687805176\n",
      ". . . batch: 120, batch_loss: 2.795553684234619\n",
      ". . . batch: 150, batch_loss: 2.897979497909546\n",
      ". . . batch: 180, batch_loss: 2.555246591567993\n",
      ". . . batch: 210, batch_loss: 2.719853639602661\n",
      ". . . batch: 240, batch_loss: 2.7152605056762695\n",
      "EPOCH: 8, train_loss: 2.7209265972628742, val_loss: 2.6061925309044986, val_score: 0.4489402697495183\n",
      ">>>>>>  EPOCH 8: validation score 0.4489402697495183\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.4297242164611816\n",
      ". . . batch: 30, batch_loss: 2.455289363861084\n",
      ". . . batch: 60, batch_loss: 2.361605405807495\n",
      ". . . batch: 90, batch_loss: 2.314997673034668\n",
      ". . . batch: 120, batch_loss: 2.0390498638153076\n",
      ". . . batch: 150, batch_loss: 2.5609054565429688\n",
      ". . . batch: 180, batch_loss: 2.4981489181518555\n",
      ". . . batch: 210, batch_loss: 2.524942636489868\n",
      ". . . batch: 240, batch_loss: 2.2440600395202637\n",
      "EPOCH: 9, train_loss: 2.3880241201682515, val_loss: 2.1763927715165274, val_score: 0.5207129094412332\n",
      ">>>>>>  EPOCH 9: validation score 0.5207129094412332\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 2.261306047439575\n",
      ". . . batch: 30, batch_loss: 2.110962390899658\n",
      ". . . batch: 60, batch_loss: 2.1833701133728027\n",
      ". . . batch: 90, batch_loss: 2.0838303565979004\n",
      ". . . batch: 120, batch_loss: 2.049069881439209\n",
      ". . . batch: 150, batch_loss: 2.155640125274658\n",
      ". . . batch: 180, batch_loss: 2.091665506362915\n",
      ". . . batch: 210, batch_loss: 1.8510030508041382\n",
      ". . . batch: 240, batch_loss: 2.094421148300171\n",
      "EPOCH: 10, train_loss: 2.0603571759931953, val_loss: 2.127007193224771, val_score: 0.5472061657032755\n",
      ">>>>>>  EPOCH 10: validation score 0.5472061657032755\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.808121919631958\n",
      ". . . batch: 30, batch_loss: 1.758905291557312\n",
      ". . . batch: 60, batch_loss: 1.922711968421936\n",
      ". . . batch: 90, batch_loss: 1.8046585321426392\n",
      ". . . batch: 120, batch_loss: 1.874758243560791\n",
      ". . . batch: 150, batch_loss: 1.6039097309112549\n",
      ". . . batch: 180, batch_loss: 1.461022138595581\n",
      ". . . batch: 210, batch_loss: 1.8009865283966064\n",
      ". . . batch: 240, batch_loss: 1.7677230834960938\n",
      "EPOCH: 11, train_loss: 1.767025700121216, val_loss: 1.7911008630480088, val_score: 0.6011560693641619\n",
      ">>>>>>  EPOCH 11: validation score 0.6011560693641619\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.4651325941085815\n",
      ". . . batch: 30, batch_loss: 1.4727628231048584\n",
      ". . . batch: 60, batch_loss: 1.6309285163879395\n",
      ". . . batch: 90, batch_loss: 1.131404161453247\n",
      ". . . batch: 120, batch_loss: 1.4607675075531006\n",
      ". . . batch: 150, batch_loss: 1.667357087135315\n",
      ". . . batch: 180, batch_loss: 1.3081852197647095\n",
      ". . . batch: 210, batch_loss: 1.3475285768508911\n",
      ". . . batch: 240, batch_loss: 1.5595462322235107\n",
      "EPOCH: 12, train_loss: 1.5068768019025984, val_loss: 1.663011521952492, val_score: 0.6146435452793835\n",
      ">>>>>>  EPOCH 12: validation score 0.6146435452793835\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.5459545850753784\n",
      ". . . batch: 30, batch_loss: 1.2635577917099\n",
      ". . . batch: 60, batch_loss: 1.0701820850372314\n",
      ". . . batch: 90, batch_loss: 1.1700189113616943\n",
      ". . . batch: 120, batch_loss: 1.735300064086914\n",
      ". . . batch: 150, batch_loss: 1.1766904592514038\n",
      ". . . batch: 180, batch_loss: 1.2197157144546509\n",
      ". . . batch: 210, batch_loss: 0.9550870656967163\n",
      ". . . batch: 240, batch_loss: 1.261224389076233\n",
      "EPOCH: 13, train_loss: 1.2697939549883206, val_loss: 1.6577379865305757, val_score: 0.640655105973025\n",
      ">>>>>>  EPOCH 13: validation score 0.640655105973025\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 0.8627650141716003\n",
      ". . . batch: 30, batch_loss: 0.9139760136604309\n",
      ". . . batch: 60, batch_loss: 0.8920305967330933\n",
      ". . . batch: 90, batch_loss: 0.7710344195365906\n",
      ". . . batch: 120, batch_loss: 1.1381393671035767\n",
      ". . . batch: 150, batch_loss: 1.037206768989563\n",
      ". . . batch: 180, batch_loss: 1.1086145639419556\n",
      ". . . batch: 210, batch_loss: 1.0568909645080566\n",
      ". . . batch: 240, batch_loss: 1.080152153968811\n",
      "EPOCH: 14, train_loss: 1.0799451908378888, val_loss: 1.726134566749845, val_score: 0.6551059730250481\n",
      ">>>>>>  EPOCH 14: validation score 0.6551059730250481\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.9762994050979614\n",
      ". . . batch: 30, batch_loss: 1.1987870931625366\n",
      ". . . batch: 60, batch_loss: 1.003448486328125\n",
      ". . . batch: 90, batch_loss: 0.9014300107955933\n",
      ". . . batch: 120, batch_loss: 0.8652173280715942\n",
      ". . . batch: 150, batch_loss: 1.1436045169830322\n",
      ". . . batch: 180, batch_loss: 0.9487894773483276\n",
      ". . . batch: 210, batch_loss: 0.7764855623245239\n",
      ". . . batch: 240, batch_loss: 0.8354336023330688\n",
      "EPOCH: 15, train_loss: 0.915742546997287, val_loss: 1.2083236472947259, val_score: 0.7133911368015415\n",
      ">>>>>>  EPOCH 15: validation score 0.7133911368015415\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.6224636435508728\n",
      ". . . batch: 30, batch_loss: 0.6998708248138428\n",
      ". . . batch: 60, batch_loss: 0.8886123895645142\n",
      ". . . batch: 90, batch_loss: 0.70285964012146\n",
      ". . . batch: 120, batch_loss: 0.8708789944648743\n",
      ". . . batch: 150, batch_loss: 1.0032984018325806\n",
      ". . . batch: 180, batch_loss: 1.0264798402786255\n",
      ". . . batch: 210, batch_loss: 0.9028851985931396\n",
      ". . . batch: 240, batch_loss: 0.8469731211662292\n",
      "EPOCH: 16, train_loss: 0.7786228631933533, val_loss: 1.3672910749912266, val_score: 0.7018304431599229\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.9345588088035583\n",
      ". . . batch: 30, batch_loss: 0.8032302856445312\n",
      ". . . batch: 60, batch_loss: 0.5997170805931091\n",
      ". . . batch: 90, batch_loss: 0.6756283044815063\n",
      ". . . batch: 120, batch_loss: 0.9372636079788208\n",
      ". . . batch: 150, batch_loss: 0.7851861119270325\n",
      ". . . batch: 180, batch_loss: 0.5781005620956421\n",
      ". . . batch: 210, batch_loss: 1.1123420000076294\n",
      ". . . batch: 240, batch_loss: 0.7186329960823059\n",
      "EPOCH: 17, train_loss: 0.657004356158502, val_loss: 1.3193949358803887, val_score: 0.7172447013487476\n",
      ">>>>>>  EPOCH 17: validation score 0.7172447013487476\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.7923757433891296\n",
      ". . . batch: 30, batch_loss: 0.663765549659729\n",
      ". . . batch: 60, batch_loss: 0.4681510627269745\n",
      ". . . batch: 90, batch_loss: 0.5065003037452698\n",
      ". . . batch: 120, batch_loss: 0.5728667974472046\n",
      ". . . batch: 150, batch_loss: 0.533920168876648\n",
      ". . . batch: 180, batch_loss: 0.4941954016685486\n",
      ". . . batch: 210, batch_loss: 0.4721391797065735\n",
      ". . . batch: 240, batch_loss: 0.5589134097099304\n",
      "EPOCH: 18, train_loss: 0.5609701751082232, val_loss: 1.2837108565228328, val_score: 0.720616570327553\n",
      ">>>>>>  EPOCH 18: validation score 0.720616570327553\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.4210468828678131\n",
      ". . . batch: 30, batch_loss: 0.5183618664741516\n",
      ". . . batch: 60, batch_loss: 0.5466137528419495\n",
      ". . . batch: 90, batch_loss: 0.5676313042640686\n",
      ". . . batch: 120, batch_loss: 0.42656782269477844\n",
      ". . . batch: 150, batch_loss: 0.46312764286994934\n",
      ". . . batch: 180, batch_loss: 0.6870504021644592\n",
      ". . . batch: 210, batch_loss: 0.4386374056339264\n",
      ". . . batch: 240, batch_loss: 0.7112189531326294\n",
      "EPOCH: 19, train_loss: 0.4925993417925908, val_loss: 1.1225235355751855, val_score: 0.7543352601156068\n",
      ">>>>>>  EPOCH 19: validation score 0.7543352601156068\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.41170549392700195\n",
      ". . . batch: 30, batch_loss: 0.43249720335006714\n",
      ". . . batch: 60, batch_loss: 0.2988678216934204\n",
      ". . . batch: 90, batch_loss: 0.35064172744750977\n",
      ". . . batch: 120, batch_loss: 0.5019639134407043\n",
      ". . . batch: 150, batch_loss: 0.6247819066047668\n",
      ". . . batch: 180, batch_loss: 0.37109506130218506\n",
      ". . . batch: 210, batch_loss: 0.5635581612586975\n",
      ". . . batch: 240, batch_loss: 0.31242281198501587\n",
      "EPOCH: 20, train_loss: 0.4227045269287896, val_loss: 0.8786270810025081, val_score: 0.773121387283237\n",
      ">>>>>>  EPOCH 20: validation score 0.773121387283237\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.3442442715167999\n",
      ". . . batch: 30, batch_loss: 0.3996707499027252\n",
      ". . . batch: 60, batch_loss: 0.2428724616765976\n",
      ". . . batch: 90, batch_loss: 0.3835030198097229\n",
      ". . . batch: 120, batch_loss: 0.312972754240036\n",
      ". . . batch: 150, batch_loss: 0.3144310414791107\n",
      ". . . batch: 180, batch_loss: 0.3309141993522644\n",
      ". . . batch: 210, batch_loss: 0.5018463730812073\n",
      ". . . batch: 240, batch_loss: 0.48766136169433594\n",
      "EPOCH: 21, train_loss: 0.3767135124089139, val_loss: 0.9157034320490701, val_score: 0.7851637764932563\n",
      ">>>>>>  EPOCH 21: validation score 0.7851637764932563\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.3033135235309601\n",
      ". . . batch: 30, batch_loss: 0.23053230345249176\n",
      ". . . batch: 60, batch_loss: 0.2868717908859253\n",
      ". . . batch: 90, batch_loss: 0.4300132691860199\n",
      ". . . batch: 120, batch_loss: 0.38080283999443054\n",
      ". . . batch: 150, batch_loss: 0.35007044672966003\n",
      ". . . batch: 180, batch_loss: 0.5606114864349365\n",
      ". . . batch: 210, batch_loss: 0.27742916345596313\n",
      ". . . batch: 240, batch_loss: 0.3138488531112671\n",
      "EPOCH: 22, train_loss: 0.3241137433232683, val_loss: 0.8225364363619257, val_score: 0.8000963391136802\n",
      ">>>>>>  EPOCH 22: validation score 0.8000963391136802\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.255946546792984\n",
      ". . . batch: 30, batch_loss: 0.42938241362571716\n",
      ". . . batch: 60, batch_loss: 0.27759936451911926\n",
      ". . . batch: 90, batch_loss: 0.316485196352005\n",
      ". . . batch: 120, batch_loss: 0.6142539381980896\n",
      ". . . batch: 150, batch_loss: 0.2126556783914566\n",
      ". . . batch: 180, batch_loss: 0.22498394548892975\n",
      ". . . batch: 210, batch_loss: 0.3329713046550751\n",
      ". . . batch: 240, batch_loss: 0.5046683549880981\n",
      "EPOCH: 23, train_loss: 0.2892540545964782, val_loss: 0.8906194584710254, val_score: 0.7976878612716763\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.3112592101097107\n",
      ". . . batch: 30, batch_loss: 0.24266797304153442\n",
      ". . . batch: 60, batch_loss: 0.23964381217956543\n",
      ". . . batch: 90, batch_loss: 0.19366998970508575\n",
      ". . . batch: 120, batch_loss: 0.21788932383060455\n",
      ". . . batch: 150, batch_loss: 0.34391313791275024\n",
      ". . . batch: 180, batch_loss: 0.20596720278263092\n",
      ". . . batch: 210, batch_loss: 0.34508001804351807\n",
      ". . . batch: 240, batch_loss: 0.19004376232624054\n",
      "EPOCH: 24, train_loss: 0.25263574078791956, val_loss: 0.7429600646453243, val_score: 0.8241811175337187\n",
      ">>>>>>  EPOCH 24: validation score 0.8241811175337187\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.23663975298404694\n",
      ". . . batch: 30, batch_loss: 0.13256601989269257\n",
      ". . . batch: 60, batch_loss: 0.21796177327632904\n",
      ". . . batch: 90, batch_loss: 0.3090304136276245\n",
      ". . . batch: 120, batch_loss: 0.14566154778003693\n",
      ". . . batch: 150, batch_loss: 0.22681376338005066\n",
      ". . . batch: 180, batch_loss: 0.20200549066066742\n",
      ". . . batch: 210, batch_loss: 0.21884670853614807\n",
      ". . . batch: 240, batch_loss: 0.22354990243911743\n",
      "EPOCH: 25, train_loss: 0.22760678782607574, val_loss: 0.9982175582221577, val_score: 0.7822736030828517\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.16447588801383972\n",
      ". . . batch: 30, batch_loss: 0.11856282502412796\n",
      ". . . batch: 60, batch_loss: 0.23572559654712677\n",
      ". . . batch: 90, batch_loss: 0.3302884101867676\n",
      ". . . batch: 120, batch_loss: 0.14122101664543152\n",
      ". . . batch: 150, batch_loss: 0.22350560128688812\n",
      ". . . batch: 180, batch_loss: 0.232410728931427\n",
      ". . . batch: 210, batch_loss: 0.1743166744709015\n",
      ". . . batch: 240, batch_loss: 0.16552066802978516\n",
      "EPOCH: 26, train_loss: 0.20551327407134304, val_loss: 0.859859309239047, val_score: 0.7928709055876686\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.12965825200080872\n",
      ". . . batch: 30, batch_loss: 0.24721042811870575\n",
      ". . . batch: 60, batch_loss: 0.22022028267383575\n",
      ". . . batch: 90, batch_loss: 0.18226686120033264\n",
      ". . . batch: 120, batch_loss: 0.1954624503850937\n",
      ". . . batch: 150, batch_loss: 0.1331622451543808\n",
      ". . . batch: 180, batch_loss: 0.17441192269325256\n",
      ". . . batch: 210, batch_loss: 0.12223288416862488\n",
      ". . . batch: 240, batch_loss: 0.1481524407863617\n",
      "EPOCH: 27, train_loss: 0.18225041091103433, val_loss: 0.8617530470447881, val_score: 0.7972061657032755\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.11248232424259186\n",
      ". . . batch: 30, batch_loss: 0.21355853974819183\n",
      ". . . batch: 60, batch_loss: 0.1201702132821083\n",
      ". . . batch: 90, batch_loss: 0.09735557436943054\n",
      ". . . batch: 120, batch_loss: 0.18166916072368622\n",
      ". . . batch: 150, batch_loss: 0.22444649040699005\n",
      ". . . batch: 180, batch_loss: 0.19829565286636353\n",
      ". . . batch: 210, batch_loss: 0.22687087953090668\n",
      ". . . batch: 240, batch_loss: 0.1527244597673416\n",
      "EPOCH: 28, train_loss: 0.16485363988657353, val_loss: 0.7850850978600127, val_score: 0.8145472061657033\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.17319132387638092\n",
      ". . . batch: 30, batch_loss: 0.1517035812139511\n",
      ". . . batch: 60, batch_loss: 0.09480079263448715\n",
      ". . . batch: 90, batch_loss: 0.09856805950403214\n",
      ". . . batch: 120, batch_loss: 0.07944685965776443\n",
      ". . . batch: 150, batch_loss: 0.08416949957609177\n",
      ". . . batch: 180, batch_loss: 0.11536023020744324\n",
      ". . . batch: 210, batch_loss: 0.2471519410610199\n",
      ". . . batch: 240, batch_loss: 0.1616474837064743\n",
      "EPOCH: 29, train_loss: 0.14175843458735585, val_loss: 1.0143698514572206, val_score: 0.7909441233140655\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.2111552208662033\n",
      ". . . batch: 30, batch_loss: 0.20871645212173462\n",
      ". . . batch: 60, batch_loss: 0.08956146240234375\n",
      ". . . batch: 90, batch_loss: 0.071384496986866\n",
      ". . . batch: 120, batch_loss: 0.11199983209371567\n",
      ". . . batch: 150, batch_loss: 0.11570759117603302\n",
      ". . . batch: 180, batch_loss: 0.1871120184659958\n",
      ". . . batch: 210, batch_loss: 0.15689922869205475\n",
      ". . . batch: 240, batch_loss: 0.06420306861400604\n",
      "EPOCH: 30, train_loss: 0.14060666649179024, val_loss: 0.6992353532995497, val_score: 0.8314065510597303\n",
      ">>>>>>  EPOCH 30: validation score 0.8314065510597303\n",
      "{'best_epoch': 30, 'best_score': 0.8314065510597303}\n",
      "----------\n",
      "----- 1 fold -----\n",
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.376272678375244\n",
      ". . . batch: 30, batch_loss: 5.300760269165039\n",
      ". . . batch: 60, batch_loss: 5.366354942321777\n",
      ". . . batch: 90, batch_loss: 5.25880241394043\n",
      ". . . batch: 120, batch_loss: 5.290124893188477\n",
      ". . . batch: 150, batch_loss: 5.284196853637695\n",
      ". . . batch: 180, batch_loss: 5.222611427307129\n",
      ". . . batch: 210, batch_loss: 5.288328647613525\n",
      ". . . batch: 240, batch_loss: 5.219677925109863\n",
      "EPOCH: 1, train_loss: 5.2730950502524685, val_loss: 5.207308600930607, val_score: 0.03140333660451423\n",
      ">>>>>>  EPOCH 1: validation score 0.03140333660451423\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.125453472137451\n",
      ". . . batch: 30, batch_loss: 5.150038242340088\n",
      ". . . batch: 60, batch_loss: 5.249124526977539\n",
      ". . . batch: 90, batch_loss: 5.208604335784912\n",
      ". . . batch: 120, batch_loss: 5.16512393951416\n",
      ". . . batch: 150, batch_loss: 5.1150031089782715\n",
      ". . . batch: 180, batch_loss: 5.0170722007751465\n",
      ". . . batch: 210, batch_loss: 4.990822792053223\n",
      ". . . batch: 240, batch_loss: 5.033548355102539\n",
      "EPOCH: 2, train_loss: 5.072206534837424, val_loss: 5.023109239690446, val_score: 0.061334641805691856\n",
      ">>>>>>  EPOCH 2: validation score 0.061334641805691856\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 4.791748523712158\n",
      ". . . batch: 30, batch_loss: 4.891601085662842\n",
      ". . . batch: 60, batch_loss: 4.857421398162842\n",
      ". . . batch: 90, batch_loss: 4.835235595703125\n",
      ". . . batch: 120, batch_loss: 4.790029525756836\n",
      ". . . batch: 150, batch_loss: 4.4871344566345215\n",
      ". . . batch: 180, batch_loss: 4.6837477684021\n",
      ". . . batch: 210, batch_loss: 4.658608913421631\n",
      ". . . batch: 240, batch_loss: 4.579249858856201\n",
      "EPOCH: 3, train_loss: 4.669804976398786, val_loss: 4.565863216624539, val_score: 0.11383709519136408\n",
      ">>>>>>  EPOCH 3: validation score 0.11383709519136408\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.4411187171936035\n",
      ". . . batch: 30, batch_loss: 4.399930477142334\n",
      ". . . batch: 60, batch_loss: 4.287139892578125\n",
      ". . . batch: 90, batch_loss: 4.499307155609131\n",
      ". . . batch: 120, batch_loss: 4.14240026473999\n",
      ". . . batch: 150, batch_loss: 4.108409881591797\n",
      ". . . batch: 180, batch_loss: 4.063665390014648\n",
      ". . . batch: 210, batch_loss: 4.037992000579834\n",
      ". . . batch: 240, batch_loss: 4.146149635314941\n",
      "EPOCH: 4, train_loss: 4.253113269805907, val_loss: 4.312085986137389, val_score: 0.133954857703631\n",
      ">>>>>>  EPOCH 4: validation score 0.133954857703631\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 4.0163373947143555\n",
      ". . . batch: 30, batch_loss: 3.727625846862793\n",
      ". . . batch: 60, batch_loss: 3.6597039699554443\n",
      ". . . batch: 90, batch_loss: 3.927377939224243\n",
      ". . . batch: 120, batch_loss: 4.168481826782227\n",
      ". . . batch: 150, batch_loss: 3.8803651332855225\n",
      ". . . batch: 180, batch_loss: 4.091020584106445\n",
      ". . . batch: 210, batch_loss: 3.69415020942688\n",
      ". . . batch: 240, batch_loss: 3.496691942214966\n",
      "EPOCH: 5, train_loss: 3.8562379179144277, val_loss: 3.923698285046747, val_score: 0.20412168792934246\n",
      ">>>>>>  EPOCH 5: validation score 0.20412168792934246\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 3.556931495666504\n",
      ". . . batch: 30, batch_loss: 3.4606430530548096\n",
      ". . . batch: 60, batch_loss: 3.2734668254852295\n",
      ". . . batch: 90, batch_loss: 3.5714194774627686\n",
      ". . . batch: 120, batch_loss: 3.3585188388824463\n",
      ". . . batch: 150, batch_loss: 3.4813241958618164\n",
      ". . . batch: 180, batch_loss: 3.7340822219848633\n",
      ". . . batch: 210, batch_loss: 3.3139235973358154\n",
      ". . . batch: 240, batch_loss: 3.3741695880889893\n",
      "EPOCH: 6, train_loss: 3.4447801570247014, val_loss: 3.711525243871354, val_score: 0.2517173699705594\n",
      ">>>>>>  EPOCH 6: validation score 0.2517173699705594\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.332409620285034\n",
      ". . . batch: 30, batch_loss: 2.9943275451660156\n",
      ". . . batch: 60, batch_loss: 3.041538715362549\n",
      ". . . batch: 90, batch_loss: 2.8839833736419678\n",
      ". . . batch: 120, batch_loss: 3.00927734375\n",
      ". . . batch: 150, batch_loss: 2.7699105739593506\n",
      ". . . batch: 180, batch_loss: 2.9311442375183105\n",
      ". . . batch: 210, batch_loss: 3.129495143890381\n",
      ". . . batch: 240, batch_loss: 2.7229533195495605\n",
      "EPOCH: 7, train_loss: 3.057728815795782, val_loss: 3.4595255641376275, val_score: 0.32188420019627084\n",
      ">>>>>>  EPOCH 7: validation score 0.32188420019627084\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 2.761199951171875\n",
      ". . . batch: 30, batch_loss: 2.9464924335479736\n",
      ". . . batch: 60, batch_loss: 2.7292912006378174\n",
      ". . . batch: 90, batch_loss: 2.6141159534454346\n",
      ". . . batch: 120, batch_loss: 2.5528557300567627\n",
      ". . . batch: 150, batch_loss: 2.5922324657440186\n",
      ". . . batch: 180, batch_loss: 2.900174379348755\n",
      ". . . batch: 210, batch_loss: 2.336596965789795\n",
      ". . . batch: 240, batch_loss: 2.820641279220581\n",
      "EPOCH: 8, train_loss: 2.694935709910285, val_loss: 2.770199547795688, val_score: 0.4052993130520117\n",
      ">>>>>>  EPOCH 8: validation score 0.4052993130520117\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.6532599925994873\n",
      ". . . batch: 30, batch_loss: 2.537013530731201\n",
      ". . . batch: 60, batch_loss: 2.447500705718994\n",
      ". . . batch: 90, batch_loss: 2.1094064712524414\n",
      ". . . batch: 120, batch_loss: 2.2166965007781982\n",
      ". . . batch: 150, batch_loss: 2.042262554168701\n",
      ". . . batch: 180, batch_loss: 2.1288368701934814\n",
      ". . . batch: 210, batch_loss: 2.545950174331665\n",
      ". . . batch: 240, batch_loss: 2.0553510189056396\n",
      "EPOCH: 9, train_loss: 2.356909930706021, val_loss: 2.7085273704108066, val_score: 0.4421000981354269\n",
      ">>>>>>  EPOCH 9: validation score 0.4421000981354269\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 1.825424075126648\n",
      ". . . batch: 30, batch_loss: 2.223426342010498\n",
      ". . . batch: 60, batch_loss: 1.9296656847000122\n",
      ". . . batch: 90, batch_loss: 2.0878489017486572\n",
      ". . . batch: 120, batch_loss: 2.3071281909942627\n",
      ". . . batch: 150, batch_loss: 2.241089105606079\n",
      ". . . batch: 180, batch_loss: 1.793455958366394\n",
      ". . . batch: 210, batch_loss: 1.9891090393066406\n",
      ". . . batch: 240, batch_loss: 1.6575467586517334\n",
      "EPOCH: 10, train_loss: 2.0412355455240823, val_loss: 2.8221018805223355, val_score: 0.49116781157998035\n",
      ">>>>>>  EPOCH 10: validation score 0.49116781157998035\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.877184510231018\n",
      ". . . batch: 30, batch_loss: 1.7468353509902954\n",
      ". . . batch: 60, batch_loss: 1.6463221311569214\n",
      ". . . batch: 90, batch_loss: 1.806592345237732\n",
      ". . . batch: 120, batch_loss: 1.931494116783142\n",
      ". . . batch: 150, batch_loss: 1.8094197511672974\n",
      ". . . batch: 180, batch_loss: 1.5190109014511108\n",
      ". . . batch: 210, batch_loss: 1.4628199338912964\n",
      ". . . batch: 240, batch_loss: 1.4478716850280762\n",
      "EPOCH: 11, train_loss: 1.7501962144572036, val_loss: 2.558845651500364, val_score: 0.5225711481844946\n",
      ">>>>>>  EPOCH 11: validation score 0.5225711481844946\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.6264692544937134\n",
      ". . . batch: 30, batch_loss: 1.4773679971694946\n",
      ". . . batch: 60, batch_loss: 1.4979392290115356\n",
      ". . . batch: 90, batch_loss: 1.4215470552444458\n",
      ". . . batch: 120, batch_loss: 1.778306245803833\n",
      ". . . batch: 150, batch_loss: 1.5152724981307983\n",
      ". . . batch: 180, batch_loss: 1.0977778434753418\n",
      ". . . batch: 210, batch_loss: 1.4481738805770874\n",
      ". . . batch: 240, batch_loss: 1.1684147119522095\n",
      "EPOCH: 12, train_loss: 1.506256216450741, val_loss: 1.966103613376618, val_score: 0.5907752698724239\n",
      ">>>>>>  EPOCH 12: validation score 0.5907752698724239\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.1722809076309204\n",
      ". . . batch: 30, batch_loss: 1.381245493888855\n",
      ". . . batch: 60, batch_loss: 1.4122962951660156\n",
      ". . . batch: 90, batch_loss: 1.3134682178497314\n",
      ". . . batch: 120, batch_loss: 1.0950523614883423\n",
      ". . . batch: 150, batch_loss: 1.2622601985931396\n",
      ". . . batch: 180, batch_loss: 1.1575779914855957\n",
      ". . . batch: 210, batch_loss: 1.2578259706497192\n",
      ". . . batch: 240, batch_loss: 1.5800570249557495\n",
      "EPOCH: 13, train_loss: 1.288213012137807, val_loss: 1.8708501510760362, val_score: 0.6216879293424926\n",
      ">>>>>>  EPOCH 13: validation score 0.6216879293424926\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 1.33201265335083\n",
      ". . . batch: 30, batch_loss: 1.2097193002700806\n",
      ". . . batch: 60, batch_loss: 1.1200050115585327\n",
      ". . . batch: 90, batch_loss: 1.2828959226608276\n",
      ". . . batch: 120, batch_loss: 1.3402961492538452\n",
      ". . . batch: 150, batch_loss: 1.025516152381897\n",
      ". . . batch: 180, batch_loss: 0.8022904992103577\n",
      ". . . batch: 210, batch_loss: 1.062972068786621\n",
      ". . . batch: 240, batch_loss: 1.083763599395752\n",
      "EPOCH: 14, train_loss: 1.1025968928982437, val_loss: 1.2533478202188717, val_score: 0.7055937193326791\n",
      ">>>>>>  EPOCH 14: validation score 0.7055937193326791\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.9590452909469604\n",
      ". . . batch: 30, batch_loss: 1.0841413736343384\n",
      ". . . batch: 60, batch_loss: 1.0796122550964355\n",
      ". . . batch: 90, batch_loss: 1.2822535037994385\n",
      ". . . batch: 120, batch_loss: 0.7171383500099182\n",
      ". . . batch: 150, batch_loss: 0.6471211910247803\n",
      ". . . batch: 180, batch_loss: 1.0625560283660889\n",
      ". . . batch: 210, batch_loss: 0.7684326767921448\n",
      ". . . batch: 240, batch_loss: 0.5062971711158752\n",
      "EPOCH: 15, train_loss: 0.9322052757094682, val_loss: 1.3402765051406973, val_score: 0.6982335623159961\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.7438156008720398\n",
      ". . . batch: 30, batch_loss: 0.6967933773994446\n",
      ". . . batch: 60, batch_loss: 0.8064945936203003\n",
      ". . . batch: 90, batch_loss: 0.7107555270195007\n",
      ". . . batch: 120, batch_loss: 0.6579446196556091\n",
      ". . . batch: 150, batch_loss: 0.6990052461624146\n",
      ". . . batch: 180, batch_loss: 0.6547448635101318\n",
      ". . . batch: 210, batch_loss: 0.6525490283966064\n",
      ". . . batch: 240, batch_loss: 0.8342045545578003\n",
      "EPOCH: 16, train_loss: 0.7988284757935012, val_loss: 1.4914897268309315, val_score: 0.6805691854759568\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.5811059474945068\n",
      ". . . batch: 30, batch_loss: 0.6078833937644958\n",
      ". . . batch: 60, batch_loss: 0.8504906892776489\n",
      ". . . batch: 90, batch_loss: 0.8161141276359558\n",
      ". . . batch: 120, batch_loss: 0.6846158504486084\n",
      ". . . batch: 150, batch_loss: 0.48233750462532043\n",
      ". . . batch: 180, batch_loss: 0.6930302381515503\n",
      ". . . batch: 210, batch_loss: 0.7186862826347351\n",
      ". . . batch: 240, batch_loss: 0.6975998282432556\n",
      "EPOCH: 17, train_loss: 0.6859947550565676, val_loss: 1.2564166459967105, val_score: 0.7266928361138371\n",
      ">>>>>>  EPOCH 17: validation score 0.7266928361138371\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.6198007464408875\n",
      ". . . batch: 30, batch_loss: 0.39909934997558594\n",
      ". . . batch: 60, batch_loss: 0.44737353920936584\n",
      ". . . batch: 90, batch_loss: 0.49056345224380493\n",
      ". . . batch: 120, batch_loss: 0.570590615272522\n",
      ". . . batch: 150, batch_loss: 0.4556732177734375\n",
      ". . . batch: 180, batch_loss: 0.4552083909511566\n",
      ". . . batch: 210, batch_loss: 0.5251166224479675\n",
      ". . . batch: 240, batch_loss: 0.49034038186073303\n",
      "EPOCH: 18, train_loss: 0.5938616536165537, val_loss: 0.9264104287413988, val_score: 0.7796859666339548\n",
      ">>>>>>  EPOCH 18: validation score 0.7796859666339548\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.5282706022262573\n",
      ". . . batch: 30, batch_loss: 0.5857738256454468\n",
      ". . . batch: 60, batch_loss: 0.4070115387439728\n",
      ". . . batch: 90, batch_loss: 0.3621147871017456\n",
      ". . . batch: 120, batch_loss: 0.8169249892234802\n",
      ". . . batch: 150, batch_loss: 0.37980085611343384\n",
      ". . . batch: 180, batch_loss: 0.6449629664421082\n",
      ". . . batch: 210, batch_loss: 0.4024319350719452\n",
      ". . . batch: 240, batch_loss: 0.42053741216659546\n",
      "EPOCH: 19, train_loss: 0.5025746462712611, val_loss: 1.2258445155971192, val_score: 0.7306182531894013\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.37504032254219055\n",
      ". . . batch: 30, batch_loss: 0.43904048204421997\n",
      ". . . batch: 60, batch_loss: 0.2858206033706665\n",
      ". . . batch: 90, batch_loss: 0.3837984502315521\n",
      ". . . batch: 120, batch_loss: 0.3347625136375427\n",
      ". . . batch: 150, batch_loss: 0.504239022731781\n",
      ". . . batch: 180, batch_loss: 0.454751580953598\n",
      ". . . batch: 210, batch_loss: 0.36899879574775696\n",
      ". . . batch: 240, batch_loss: 0.470269113779068\n",
      "EPOCH: 20, train_loss: 0.4416267493725717, val_loss: 0.9958070354426607, val_score: 0.7590775269872424\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.3133775293827057\n",
      ". . . batch: 30, batch_loss: 0.3888188898563385\n",
      ". . . batch: 60, batch_loss: 0.47940510511398315\n",
      ". . . batch: 90, batch_loss: 0.37649422883987427\n",
      ". . . batch: 120, batch_loss: 0.3335264325141907\n",
      ". . . batch: 150, batch_loss: 0.3383887708187103\n",
      ". . . batch: 180, batch_loss: 0.5423877239227295\n",
      ". . . batch: 210, batch_loss: 0.28208550810813904\n",
      ". . . batch: 240, batch_loss: 0.34472858905792236\n",
      "EPOCH: 21, train_loss: 0.3921744023498734, val_loss: 0.6634355428464273, val_score: 0.8228655544651619\n",
      ">>>>>>  EPOCH 21: validation score 0.8228655544651619\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.31474971771240234\n",
      ". . . batch: 30, batch_loss: 0.3738287687301636\n",
      ". . . batch: 60, batch_loss: 0.248334601521492\n",
      ". . . batch: 90, batch_loss: 0.3650262653827667\n",
      ". . . batch: 120, batch_loss: 0.2566053867340088\n",
      ". . . batch: 150, batch_loss: 0.3372081518173218\n",
      ". . . batch: 180, batch_loss: 0.5006248354911804\n",
      ". . . batch: 210, batch_loss: 0.33132219314575195\n",
      ". . . batch: 240, batch_loss: 0.38336673378944397\n",
      "EPOCH: 22, train_loss: 0.35193532240345937, val_loss: 0.6895680449464744, val_score: 0.8164867517173698\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.3943742513656616\n",
      ". . . batch: 30, batch_loss: 0.3208194375038147\n",
      ". . . batch: 60, batch_loss: 0.20970675349235535\n",
      ". . . batch: 90, batch_loss: 0.34911099076271057\n",
      ". . . batch: 120, batch_loss: 0.32949182391166687\n",
      ". . . batch: 150, batch_loss: 0.17367984354496002\n",
      ". . . batch: 180, batch_loss: 0.3258257210254669\n",
      ". . . batch: 210, batch_loss: 0.1028813049197197\n",
      ". . . batch: 240, batch_loss: 0.27822941541671753\n",
      "EPOCH: 23, train_loss: 0.3111109192154012, val_loss: 0.7870868091635845, val_score: 0.8091265947006869\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.22157475352287292\n",
      ". . . batch: 30, batch_loss: 0.20731407403945923\n",
      ". . . batch: 60, batch_loss: 0.13744255900382996\n",
      ". . . batch: 90, batch_loss: 0.23777362704277039\n",
      ". . . batch: 120, batch_loss: 0.2210424393415451\n",
      ". . . batch: 150, batch_loss: 0.14977623522281647\n",
      ". . . batch: 180, batch_loss: 0.2971603572368622\n",
      ". . . batch: 210, batch_loss: 0.19990567862987518\n",
      ". . . batch: 240, batch_loss: 0.17070770263671875\n",
      "EPOCH: 24, train_loss: 0.2623247945947308, val_loss: 0.7170853715609103, val_score: 0.830225711481845\n",
      ">>>>>>  EPOCH 24: validation score 0.830225711481845\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.11435441672801971\n",
      ". . . batch: 30, batch_loss: 0.1465492844581604\n",
      ". . . batch: 60, batch_loss: 0.3094058632850647\n",
      ". . . batch: 90, batch_loss: 0.30133500695228577\n",
      ". . . batch: 120, batch_loss: 0.299711674451828\n",
      ". . . batch: 150, batch_loss: 0.1295720636844635\n",
      ". . . batch: 180, batch_loss: 0.23162555694580078\n",
      ". . . batch: 210, batch_loss: 0.3409314751625061\n",
      ". . . batch: 240, batch_loss: 0.29565858840942383\n",
      "EPOCH: 25, train_loss: 0.24836437751476012, val_loss: 0.80195897971006, val_score: 0.8081452404317959\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.21626588702201843\n",
      ". . . batch: 30, batch_loss: 0.14360663294792175\n",
      ". . . batch: 60, batch_loss: 0.2893611192703247\n",
      ". . . batch: 90, batch_loss: 0.1891840249300003\n",
      ". . . batch: 120, batch_loss: 0.20256763696670532\n",
      ". . . batch: 150, batch_loss: 0.18290792405605316\n",
      ". . . batch: 180, batch_loss: 0.3381320834159851\n",
      ". . . batch: 210, batch_loss: 0.2064560502767563\n",
      ". . . batch: 240, batch_loss: 0.1495598405599594\n",
      "EPOCH: 26, train_loss: 0.21832552616645515, val_loss: 0.6170311997480252, val_score: 0.8410206084396468\n",
      ">>>>>>  EPOCH 26: validation score 0.8410206084396468\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.16968923807144165\n",
      ". . . batch: 30, batch_loss: 0.15381412208080292\n",
      ". . . batch: 60, batch_loss: 0.170840322971344\n",
      ". . . batch: 90, batch_loss: 0.14114250242710114\n",
      ". . . batch: 120, batch_loss: 0.14027200639247894\n",
      ". . . batch: 150, batch_loss: 0.15086421370506287\n",
      ". . . batch: 180, batch_loss: 0.21205949783325195\n",
      ". . . batch: 210, batch_loss: 0.10805775225162506\n",
      ". . . batch: 240, batch_loss: 0.10440397262573242\n",
      "EPOCH: 27, train_loss: 0.19702882636198416, val_loss: 0.8183465915567734, val_score: 0.802747791952895\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.1316489577293396\n",
      ". . . batch: 30, batch_loss: 0.18425899744033813\n",
      ". . . batch: 60, batch_loss: 0.18582333624362946\n",
      ". . . batch: 90, batch_loss: 0.24733217060565948\n",
      ". . . batch: 120, batch_loss: 0.11582116782665253\n",
      ". . . batch: 150, batch_loss: 0.1592143028974533\n",
      ". . . batch: 180, batch_loss: 0.17827996611595154\n",
      ". . . batch: 210, batch_loss: 0.17107407748699188\n",
      ". . . batch: 240, batch_loss: 0.16533832252025604\n",
      "EPOCH: 28, train_loss: 0.18129428789803856, val_loss: 0.851058797801242, val_score: 0.7934249263984299\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.16580186784267426\n",
      ". . . batch: 30, batch_loss: 0.14487510919570923\n",
      ". . . batch: 60, batch_loss: 0.19131235778331757\n",
      ". . . batch: 90, batch_loss: 0.20170074701309204\n",
      ". . . batch: 120, batch_loss: 0.20625807344913483\n",
      ". . . batch: 150, batch_loss: 0.2793973684310913\n",
      ". . . batch: 180, batch_loss: 0.17108017206192017\n",
      ". . . batch: 210, batch_loss: 0.14695723354816437\n",
      ". . . batch: 240, batch_loss: 0.07774098962545395\n",
      "EPOCH: 29, train_loss: 0.16721342798126376, val_loss: 0.9520564868169674, val_score: 0.7772325809617272\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.0699220672249794\n",
      ". . . batch: 30, batch_loss: 0.0715070441365242\n",
      ". . . batch: 60, batch_loss: 0.13697437942028046\n",
      ". . . batch: 90, batch_loss: 0.12353479117155075\n",
      ". . . batch: 120, batch_loss: 0.09861666709184647\n",
      ". . . batch: 150, batch_loss: 0.5411299467086792\n",
      ". . . batch: 180, batch_loss: 0.13835205137729645\n",
      ". . . batch: 210, batch_loss: 0.17425447702407837\n",
      ". . . batch: 240, batch_loss: 0.09081386029720306\n",
      "EPOCH: 30, train_loss: 0.1505499355691044, val_loss: 0.7111427376375475, val_score: 0.8326790971540726\n",
      "{'best_epoch': 26, 'best_score': 0.8410206084396468}\n",
      "----------\n",
      "----- 2 fold -----\n",
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.326461315155029\n",
      ". . . batch: 30, batch_loss: 5.335395336151123\n",
      ". . . batch: 60, batch_loss: 5.248205661773682\n",
      ". . . batch: 90, batch_loss: 5.2751240730285645\n",
      ". . . batch: 120, batch_loss: 5.198886394500732\n",
      ". . . batch: 150, batch_loss: 5.275660514831543\n",
      ". . . batch: 180, batch_loss: 5.230427265167236\n",
      ". . . batch: 210, batch_loss: 5.265221118927002\n",
      ". . . batch: 240, batch_loss: 5.272038459777832\n",
      "EPOCH: 1, train_loss: 5.269594526469481, val_loss: 5.196269818206333, val_score: 0.024438902743142147\n",
      ">>>>>>  EPOCH 1: validation score 0.024438902743142147\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.1531572341918945\n",
      ". . . batch: 30, batch_loss: 5.2420477867126465\n",
      ". . . batch: 60, batch_loss: 5.242234706878662\n",
      ". . . batch: 90, batch_loss: 5.1083598136901855\n",
      ". . . batch: 120, batch_loss: 5.125463485717773\n",
      ". . . batch: 150, batch_loss: 5.113110065460205\n",
      ". . . batch: 180, batch_loss: 5.0761847496032715\n",
      ". . . batch: 210, batch_loss: 4.989839553833008\n",
      ". . . batch: 240, batch_loss: 5.169903755187988\n",
      "EPOCH: 2, train_loss: 5.080100814947919, val_loss: 4.928717869431226, val_score: 0.06733167082294264\n",
      ">>>>>>  EPOCH 2: validation score 0.06733167082294264\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 4.938765048980713\n",
      ". . . batch: 30, batch_loss: 4.817750930786133\n",
      ". . . batch: 60, batch_loss: 4.863308429718018\n",
      ". . . batch: 90, batch_loss: 4.569733619689941\n",
      ". . . batch: 120, batch_loss: 4.8170061111450195\n",
      ". . . batch: 150, batch_loss: 4.693643569946289\n",
      ". . . batch: 180, batch_loss: 4.565369606018066\n",
      ". . . batch: 210, batch_loss: 4.569969177246094\n",
      ". . . batch: 240, batch_loss: 4.372769355773926\n",
      "EPOCH: 3, train_loss: 4.69527197062746, val_loss: 4.444573452223593, val_score: 0.09825436408977556\n",
      ">>>>>>  EPOCH 3: validation score 0.09825436408977556\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.438142776489258\n",
      ". . . batch: 30, batch_loss: 4.529106140136719\n",
      ". . . batch: 60, batch_loss: 4.180613040924072\n",
      ". . . batch: 90, batch_loss: 4.4198150634765625\n",
      ". . . batch: 120, batch_loss: 4.315618515014648\n",
      ". . . batch: 150, batch_loss: 4.086888790130615\n",
      ". . . batch: 180, batch_loss: 4.133755207061768\n",
      ". . . batch: 210, batch_loss: 4.339134216308594\n",
      ". . . batch: 240, batch_loss: 4.152922630310059\n",
      "EPOCH: 4, train_loss: 4.251026048195944, val_loss: 4.1029234039249705, val_score: 0.14463840399002495\n",
      ">>>>>>  EPOCH 4: validation score 0.14463840399002495\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 3.853228807449341\n",
      ". . . batch: 30, batch_loss: 3.9522018432617188\n",
      ". . . batch: 60, batch_loss: 3.706925630569458\n",
      ". . . batch: 90, batch_loss: 3.823784351348877\n",
      ". . . batch: 120, batch_loss: 3.6466572284698486\n",
      ". . . batch: 150, batch_loss: 3.8675308227539062\n",
      ". . . batch: 180, batch_loss: 3.894205331802368\n",
      ". . . batch: 210, batch_loss: 3.7736849784851074\n",
      ". . . batch: 240, batch_loss: 3.786396026611328\n",
      "EPOCH: 5, train_loss: 3.833771572577369, val_loss: 3.8649614213117918, val_score: 0.21496259351620947\n",
      ">>>>>>  EPOCH 5: validation score 0.21496259351620947\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 3.723111152648926\n",
      ". . . batch: 30, batch_loss: 3.5489704608917236\n",
      ". . . batch: 60, batch_loss: 3.374868631362915\n",
      ". . . batch: 90, batch_loss: 3.5748860836029053\n",
      ". . . batch: 120, batch_loss: 3.4263532161712646\n",
      ". . . batch: 150, batch_loss: 3.4050376415252686\n",
      ". . . batch: 180, batch_loss: 3.3718903064727783\n",
      ". . . batch: 210, batch_loss: 3.3275792598724365\n",
      ". . . batch: 240, batch_loss: 3.933546781539917\n",
      "EPOCH: 6, train_loss: 3.445279757181803, val_loss: 3.0908392827902267, val_score: 0.31371571072319204\n",
      ">>>>>>  EPOCH 6: validation score 0.31371571072319204\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.4344353675842285\n",
      ". . . batch: 30, batch_loss: 2.91219425201416\n",
      ". . . batch: 60, batch_loss: 3.0720202922821045\n",
      ". . . batch: 90, batch_loss: 3.237741231918335\n",
      ". . . batch: 120, batch_loss: 3.0653116703033447\n",
      ". . . batch: 150, batch_loss: 2.9663565158843994\n",
      ". . . batch: 180, batch_loss: 2.6834816932678223\n",
      ". . . batch: 210, batch_loss: 2.933666944503784\n",
      ". . . batch: 240, batch_loss: 2.8436014652252197\n",
      "EPOCH: 7, train_loss: 3.0504217888978524, val_loss: 2.739523734619368, val_score: 0.398004987531172\n",
      ">>>>>>  EPOCH 7: validation score 0.398004987531172\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 2.8117973804473877\n",
      ". . . batch: 30, batch_loss: 2.6940648555755615\n",
      ". . . batch: 60, batch_loss: 2.98014497756958\n",
      ". . . batch: 90, batch_loss: 2.932060718536377\n",
      ". . . batch: 120, batch_loss: 2.607872247695923\n",
      ". . . batch: 150, batch_loss: 2.6356306076049805\n",
      ". . . batch: 180, batch_loss: 2.770158052444458\n",
      ". . . batch: 210, batch_loss: 2.281290292739868\n",
      ". . . batch: 240, batch_loss: 2.797409772872925\n",
      "EPOCH: 8, train_loss: 2.688289164603873, val_loss: 2.3901780612433146, val_score: 0.4773067331670823\n",
      ">>>>>>  EPOCH 8: validation score 0.4773067331670823\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.212761878967285\n",
      ". . . batch: 30, batch_loss: 2.5118565559387207\n",
      ". . . batch: 60, batch_loss: 2.533266305923462\n",
      ". . . batch: 90, batch_loss: 2.188354730606079\n",
      ". . . batch: 120, batch_loss: 2.1622812747955322\n",
      ". . . batch: 150, batch_loss: 2.328481912612915\n",
      ". . . batch: 180, batch_loss: 2.224843740463257\n",
      ". . . batch: 210, batch_loss: 2.3406076431274414\n",
      ". . . batch: 240, batch_loss: 2.42000675201416\n",
      "EPOCH: 9, train_loss: 2.35215136263701, val_loss: 2.0687792265593115, val_score: 0.5441396508728179\n",
      ">>>>>>  EPOCH 9: validation score 0.5441396508728179\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 1.756500244140625\n",
      ". . . batch: 30, batch_loss: 2.1532530784606934\n",
      ". . . batch: 60, batch_loss: 1.9845643043518066\n",
      ". . . batch: 90, batch_loss: 2.0370466709136963\n",
      ". . . batch: 120, batch_loss: 1.800437331199646\n",
      ". . . batch: 150, batch_loss: 1.9972975254058838\n",
      ". . . batch: 180, batch_loss: 2.0186703205108643\n",
      ". . . batch: 210, batch_loss: 2.0246920585632324\n",
      ". . . batch: 240, batch_loss: 1.6785576343536377\n",
      "EPOCH: 10, train_loss: 2.0157209974103223, val_loss: 1.8318088730769368, val_score: 0.601496259351621\n",
      ">>>>>>  EPOCH 10: validation score 0.601496259351621\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.7435067892074585\n",
      ". . . batch: 30, batch_loss: 1.8207511901855469\n",
      ". . . batch: 60, batch_loss: 1.777641773223877\n",
      ". . . batch: 90, batch_loss: 1.9971644878387451\n",
      ". . . batch: 120, batch_loss: 1.6522343158721924\n",
      ". . . batch: 150, batch_loss: 1.8195468187332153\n",
      ". . . batch: 180, batch_loss: 1.77004075050354\n",
      ". . . batch: 210, batch_loss: 1.5732805728912354\n",
      ". . . batch: 240, batch_loss: 1.5249171257019043\n",
      "EPOCH: 11, train_loss: 1.7376899732632594, val_loss: 1.7189810667464984, val_score: 0.6244389027431422\n",
      ">>>>>>  EPOCH 11: validation score 0.6244389027431422\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.6074976921081543\n",
      ". . . batch: 30, batch_loss: 1.2671165466308594\n",
      ". . . batch: 60, batch_loss: 1.5930103063583374\n",
      ". . . batch: 90, batch_loss: 1.4847297668457031\n",
      ". . . batch: 120, batch_loss: 1.3519989252090454\n",
      ". . . batch: 150, batch_loss: 1.4299900531768799\n",
      ". . . batch: 180, batch_loss: 1.11049485206604\n",
      ". . . batch: 210, batch_loss: 1.3236877918243408\n",
      ". . . batch: 240, batch_loss: 1.488821268081665\n",
      "EPOCH: 12, train_loss: 1.4965353458561708, val_loss: 1.478203296661377, val_score: 0.6698254364089775\n",
      ">>>>>>  EPOCH 12: validation score 0.6698254364089775\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.1728618144989014\n",
      ". . . batch: 30, batch_loss: 1.6207067966461182\n",
      ". . . batch: 60, batch_loss: 1.2569636106491089\n",
      ". . . batch: 90, batch_loss: 1.3946555852890015\n",
      ". . . batch: 120, batch_loss: 1.351358413696289\n",
      ". . . batch: 150, batch_loss: 1.2150002717971802\n",
      ". . . batch: 180, batch_loss: 1.0588291883468628\n",
      ". . . batch: 210, batch_loss: 1.217231035232544\n",
      ". . . batch: 240, batch_loss: 1.1406394243240356\n",
      "EPOCH: 13, train_loss: 1.2704347128725235, val_loss: 1.2262056354266493, val_score: 0.7251870324189527\n",
      ">>>>>>  EPOCH 13: validation score 0.7251870324189527\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 1.0744537115097046\n",
      ". . . batch: 30, batch_loss: 1.2420060634613037\n",
      ". . . batch: 60, batch_loss: 1.0524388551712036\n",
      ". . . batch: 90, batch_loss: 1.1369141340255737\n",
      ". . . batch: 120, batch_loss: 1.3844428062438965\n",
      ". . . batch: 150, batch_loss: 0.7086367011070251\n",
      ". . . batch: 180, batch_loss: 1.4107463359832764\n",
      ". . . batch: 210, batch_loss: 1.58347749710083\n",
      ". . . batch: 240, batch_loss: 0.978598415851593\n",
      "EPOCH: 14, train_loss: 1.0692637256915205, val_loss: 1.3170146844280304, val_score: 0.6982543640897756\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.7596059441566467\n",
      ". . . batch: 30, batch_loss: 1.000635027885437\n",
      ". . . batch: 60, batch_loss: 1.013960361480713\n",
      ". . . batch: 90, batch_loss: 0.743217408657074\n",
      ". . . batch: 120, batch_loss: 0.9051010012626648\n",
      ". . . batch: 150, batch_loss: 0.8472550511360168\n",
      ". . . batch: 180, batch_loss: 0.6050513386726379\n",
      ". . . batch: 210, batch_loss: 0.7786079049110413\n",
      ". . . batch: 240, batch_loss: 0.852356493473053\n",
      "EPOCH: 15, train_loss: 0.8967227183477718, val_loss: 1.2145522743908328, val_score: 0.7316708229426435\n",
      ">>>>>>  EPOCH 15: validation score 0.7316708229426435\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.9282745122909546\n",
      ". . . batch: 30, batch_loss: 0.6935424208641052\n",
      ". . . batch: 60, batch_loss: 0.9096181988716125\n",
      ". . . batch: 90, batch_loss: 0.6441510319709778\n",
      ". . . batch: 120, batch_loss: 1.0174764394760132\n",
      ". . . batch: 150, batch_loss: 0.8073738217353821\n",
      ". . . batch: 180, batch_loss: 0.9353925585746765\n",
      ". . . batch: 210, batch_loss: 0.6102112531661987\n",
      ". . . batch: 240, batch_loss: 0.6402925252914429\n",
      "EPOCH: 16, train_loss: 0.7752389595303194, val_loss: 0.8385744846578855, val_score: 0.7935162094763092\n",
      ">>>>>>  EPOCH 16: validation score 0.7935162094763092\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.6830179691314697\n",
      ". . . batch: 30, batch_loss: 0.7404599785804749\n",
      ". . . batch: 60, batch_loss: 0.7475209832191467\n",
      ". . . batch: 90, batch_loss: 0.5522380471229553\n",
      ". . . batch: 120, batch_loss: 0.5845692753791809\n",
      ". . . batch: 150, batch_loss: 0.5725505948066711\n",
      ". . . batch: 180, batch_loss: 0.583908200263977\n",
      ". . . batch: 210, batch_loss: 0.6097177267074585\n",
      ". . . batch: 240, batch_loss: 0.4754008650779724\n",
      "EPOCH: 17, train_loss: 0.6719018651751543, val_loss: 0.7783688716034393, val_score: 0.8084788029925187\n",
      ">>>>>>  EPOCH 17: validation score 0.8084788029925187\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.6540623903274536\n",
      ". . . batch: 30, batch_loss: 0.43780437111854553\n",
      ". . . batch: 60, batch_loss: 0.43671032786369324\n",
      ". . . batch: 90, batch_loss: 0.5997488498687744\n",
      ". . . batch: 120, batch_loss: 0.4829469323158264\n",
      ". . . batch: 150, batch_loss: 0.5462443828582764\n",
      ". . . batch: 180, batch_loss: 0.47088947892189026\n",
      ". . . batch: 210, batch_loss: 0.4864081144332886\n",
      ". . . batch: 240, batch_loss: 0.5516318082809448\n",
      "EPOCH: 18, train_loss: 0.5650460014629002, val_loss: 0.6943611996387369, val_score: 0.8209476309226933\n",
      ">>>>>>  EPOCH 18: validation score 0.8209476309226933\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.3520169258117676\n",
      ". . . batch: 30, batch_loss: 0.49338656663894653\n",
      ". . . batch: 60, batch_loss: 0.507752001285553\n",
      ". . . batch: 90, batch_loss: 0.49678555130958557\n",
      ". . . batch: 120, batch_loss: 0.6777292490005493\n",
      ". . . batch: 150, batch_loss: 0.4375937879085541\n",
      ". . . batch: 180, batch_loss: 0.45722532272338867\n",
      ". . . batch: 210, batch_loss: 0.691473126411438\n",
      ". . . batch: 240, batch_loss: 0.47326260805130005\n",
      "EPOCH: 19, train_loss: 0.5108054678761556, val_loss: 0.6286862221226768, val_score: 0.8468827930174564\n",
      ">>>>>>  EPOCH 19: validation score 0.8468827930174564\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.39992135763168335\n",
      ". . . batch: 30, batch_loss: 0.46634307503700256\n",
      ". . . batch: 60, batch_loss: 0.5055612325668335\n",
      ". . . batch: 90, batch_loss: 0.5585727691650391\n",
      ". . . batch: 120, batch_loss: 0.6174764037132263\n",
      ". . . batch: 150, batch_loss: 0.34132274985313416\n",
      ". . . batch: 180, batch_loss: 0.5985833406448364\n",
      ". . . batch: 210, batch_loss: 0.5169501304626465\n",
      ". . . batch: 240, batch_loss: 0.5200839638710022\n",
      "EPOCH: 20, train_loss: 0.437648603420579, val_loss: 0.7399124805607011, val_score: 0.8164588528678304\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.45071402192115784\n",
      ". . . batch: 30, batch_loss: 0.5562988519668579\n",
      ". . . batch: 60, batch_loss: 0.24900132417678833\n",
      ". . . batch: 90, batch_loss: 0.3687080442905426\n",
      ". . . batch: 120, batch_loss: 0.41583603620529175\n",
      ". . . batch: 150, batch_loss: 0.3168444335460663\n",
      ". . . batch: 180, batch_loss: 0.3792293965816498\n",
      ". . . batch: 210, batch_loss: 0.3384493291378021\n",
      ". . . batch: 240, batch_loss: 0.4969586730003357\n",
      "EPOCH: 21, train_loss: 0.3799610260162459, val_loss: 0.5419393628835678, val_score: 0.8633416458852867\n",
      ">>>>>>  EPOCH 21: validation score 0.8633416458852867\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.405714213848114\n",
      ". . . batch: 30, batch_loss: 0.20040209591388702\n",
      ". . . batch: 60, batch_loss: 0.336003839969635\n",
      ". . . batch: 90, batch_loss: 0.2866283357143402\n",
      ". . . batch: 120, batch_loss: 0.30240827798843384\n",
      ". . . batch: 150, batch_loss: 0.26878610253334045\n",
      ". . . batch: 180, batch_loss: 0.3637279272079468\n",
      ". . . batch: 210, batch_loss: 0.4959629476070404\n",
      ". . . batch: 240, batch_loss: 0.350103497505188\n",
      "EPOCH: 22, train_loss: 0.32253509324588164, val_loss: 0.7341973890564335, val_score: 0.8264339152119702\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.23186953365802765\n",
      ". . . batch: 30, batch_loss: 0.2036871314048767\n",
      ". . . batch: 60, batch_loss: 0.24930797517299652\n",
      ". . . batch: 90, batch_loss: 0.18008841574192047\n",
      ". . . batch: 120, batch_loss: 0.563055694103241\n",
      ". . . batch: 150, batch_loss: 0.31282559037208557\n",
      ". . . batch: 180, batch_loss: 0.3797806203365326\n",
      ". . . batch: 210, batch_loss: 0.30256617069244385\n",
      ". . . batch: 240, batch_loss: 0.27005869150161743\n",
      "EPOCH: 23, train_loss: 0.2976794177561664, val_loss: 0.8972195377990381, val_score: 0.7975062344139651\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.23413453996181488\n",
      ". . . batch: 30, batch_loss: 0.23937863111495972\n",
      ". . . batch: 60, batch_loss: 0.26938357949256897\n",
      ". . . batch: 90, batch_loss: 0.304481565952301\n",
      ". . . batch: 120, batch_loss: 0.3030894994735718\n",
      ". . . batch: 150, batch_loss: 0.18636031448841095\n",
      ". . . batch: 180, batch_loss: 0.22839784622192383\n",
      ". . . batch: 210, batch_loss: 0.25733286142349243\n",
      ". . . batch: 240, batch_loss: 0.24008671939373016\n",
      "EPOCH: 24, train_loss: 0.2592105061820384, val_loss: 0.4899541722304786, val_score: 0.8668329177057357\n",
      ">>>>>>  EPOCH 24: validation score 0.8668329177057357\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.13394835591316223\n",
      ". . . batch: 30, batch_loss: 0.24325618147850037\n",
      ". . . batch: 60, batch_loss: 0.18399888277053833\n",
      ". . . batch: 90, batch_loss: 0.20137135684490204\n",
      ". . . batch: 120, batch_loss: 0.1919558197259903\n",
      ". . . batch: 150, batch_loss: 0.23450933396816254\n",
      ". . . batch: 180, batch_loss: 0.15796899795532227\n",
      ". . . batch: 210, batch_loss: 0.17637532949447632\n",
      ". . . batch: 240, batch_loss: 0.46080857515335083\n",
      "EPOCH: 25, train_loss: 0.23243787999121893, val_loss: 0.52950535825829, val_score: 0.8603491271820449\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.16455848515033722\n",
      ". . . batch: 30, batch_loss: 0.11407654732465744\n",
      ". . . batch: 60, batch_loss: 0.24083277583122253\n",
      ". . . batch: 90, batch_loss: 0.29621607065200806\n",
      ". . . batch: 120, batch_loss: 0.28914517164230347\n",
      ". . . batch: 150, batch_loss: 0.18130744993686676\n",
      ". . . batch: 180, batch_loss: 0.12905384600162506\n",
      ". . . batch: 210, batch_loss: 0.15248923003673553\n",
      ". . . batch: 240, batch_loss: 0.31222447752952576\n",
      "EPOCH: 26, train_loss: 0.21441260510392857, val_loss: 0.46965751029662234, val_score: 0.8713216957605985\n",
      ">>>>>>  EPOCH 26: validation score 0.8713216957605985\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.24023912847042084\n",
      ". . . batch: 30, batch_loss: 0.25695478916168213\n",
      ". . . batch: 60, batch_loss: 0.26831626892089844\n",
      ". . . batch: 90, batch_loss: 0.13805490732192993\n",
      ". . . batch: 120, batch_loss: 0.17537778615951538\n",
      ". . . batch: 150, batch_loss: 0.15612277388572693\n",
      ". . . batch: 180, batch_loss: 0.22303253412246704\n",
      ". . . batch: 210, batch_loss: 0.1420310139656067\n",
      ". . . batch: 240, batch_loss: 0.1135566383600235\n",
      "EPOCH: 27, train_loss: 0.19118191116255764, val_loss: 0.5570887687490946, val_score: 0.854862842892768\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.20275327563285828\n",
      ". . . batch: 30, batch_loss: 0.19065584242343903\n",
      ". . . batch: 60, batch_loss: 0.1506848931312561\n",
      ". . . batch: 90, batch_loss: 0.18214520812034607\n",
      ". . . batch: 120, batch_loss: 0.12892046570777893\n",
      ". . . batch: 150, batch_loss: 0.14106935262680054\n",
      ". . . batch: 180, batch_loss: 0.07965414971113205\n",
      ". . . batch: 210, batch_loss: 0.055992286652326584\n",
      ". . . batch: 240, batch_loss: 0.13596203923225403\n",
      "EPOCH: 28, train_loss: 0.16723367955521704, val_loss: 0.6335194424461962, val_score: 0.8488778054862843\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.10681174695491791\n",
      ". . . batch: 30, batch_loss: 0.17329005897045135\n",
      ". . . batch: 60, batch_loss: 0.10798700898885727\n",
      ". . . batch: 90, batch_loss: 0.1452922224998474\n",
      ". . . batch: 120, batch_loss: 0.09578800201416016\n",
      ". . . batch: 150, batch_loss: 0.2641318440437317\n",
      ". . . batch: 180, batch_loss: 0.10623124241828918\n",
      ". . . batch: 210, batch_loss: 0.17295800149440765\n",
      ". . . batch: 240, batch_loss: 0.19668716192245483\n",
      "EPOCH: 29, train_loss: 0.1521363446440144, val_loss: 0.6015889473370652, val_score: 0.8458852867830424\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.10781337320804596\n",
      ". . . batch: 30, batch_loss: 0.33950790762901306\n",
      ". . . batch: 60, batch_loss: 0.12190430611371994\n",
      ". . . batch: 90, batch_loss: 0.09237327426671982\n",
      ". . . batch: 120, batch_loss: 0.19290691614151\n",
      ". . . batch: 150, batch_loss: 0.16185824573040009\n",
      ". . . batch: 180, batch_loss: 0.15742164850234985\n",
      ". . . batch: 210, batch_loss: 0.11101023107767105\n",
      ". . . batch: 240, batch_loss: 0.13425128161907196\n",
      "EPOCH: 30, train_loss: 0.14501820810222898, val_loss: 0.6081371257331833, val_score: 0.8503740648379052\n",
      "{'best_epoch': 26, 'best_score': 0.8713216957605985}\n",
      "----------\n",
      "----- 3 fold -----\n",
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.324446678161621\n",
      ". . . batch: 30, batch_loss: 5.285412788391113\n",
      ". . . batch: 60, batch_loss: 5.302755832672119\n",
      ". . . batch: 90, batch_loss: 5.330637454986572\n",
      ". . . batch: 120, batch_loss: 5.2701544761657715\n",
      ". . . batch: 150, batch_loss: 5.283243656158447\n",
      ". . . batch: 180, batch_loss: 5.254149436950684\n",
      ". . . batch: 210, batch_loss: 5.249516487121582\n",
      ". . . batch: 240, batch_loss: 5.320801258087158\n",
      "EPOCH: 1, train_loss: 5.268489138403939, val_loss: 5.1720650340571535, val_score: 0.030627871362940276\n",
      ">>>>>>  EPOCH 1: validation score 0.030627871362940276\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.249511241912842\n",
      ". . . batch: 30, batch_loss: 5.14323616027832\n",
      ". . . batch: 60, batch_loss: 5.07567834854126\n",
      ". . . batch: 90, batch_loss: 5.180559158325195\n",
      ". . . batch: 120, batch_loss: 5.11505126953125\n",
      ". . . batch: 150, batch_loss: 5.039322853088379\n",
      ". . . batch: 180, batch_loss: 4.995221138000488\n",
      ". . . batch: 210, batch_loss: 5.020044803619385\n",
      ". . . batch: 240, batch_loss: 4.888932704925537\n",
      "EPOCH: 2, train_loss: 5.055570885316649, val_loss: 4.868989330349549, val_score: 0.06431852986217458\n",
      ">>>>>>  EPOCH 2: validation score 0.06431852986217458\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 4.877171993255615\n",
      ". . . batch: 30, batch_loss: 4.762109756469727\n",
      ". . . batch: 60, batch_loss: 4.752311706542969\n",
      ". . . batch: 90, batch_loss: 4.650574207305908\n",
      ". . . batch: 120, batch_loss: 4.689611434936523\n",
      ". . . batch: 150, batch_loss: 4.543094158172607\n",
      ". . . batch: 180, batch_loss: 4.5533294677734375\n",
      ". . . batch: 210, batch_loss: 4.422863483428955\n",
      ". . . batch: 240, batch_loss: 4.591340065002441\n",
      "EPOCH: 3, train_loss: 4.6490662008968755, val_loss: 4.375516869805075, val_score: 0.12302194997447677\n",
      ">>>>>>  EPOCH 3: validation score 0.12302194997447677\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.46277379989624\n",
      ". . . batch: 30, batch_loss: 4.202486515045166\n",
      ". . . batch: 60, batch_loss: 4.228302478790283\n",
      ". . . batch: 90, batch_loss: 4.3669867515563965\n",
      ". . . batch: 120, batch_loss: 3.8893120288848877\n",
      ". . . batch: 150, batch_loss: 3.99603271484375\n",
      ". . . batch: 180, batch_loss: 4.396912097930908\n",
      ". . . batch: 210, batch_loss: 4.302479267120361\n",
      ". . . batch: 240, batch_loss: 4.180881023406982\n",
      "EPOCH: 4, train_loss: 4.226779097941384, val_loss: 4.082319722031102, val_score: 0.16488004083716182\n",
      ">>>>>>  EPOCH 4: validation score 0.16488004083716182\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 3.9262728691101074\n",
      ". . . batch: 30, batch_loss: 3.9526095390319824\n",
      ". . . batch: 60, batch_loss: 3.7925727367401123\n",
      ". . . batch: 90, batch_loss: 3.526284694671631\n",
      ". . . batch: 120, batch_loss: 3.762167453765869\n",
      ". . . batch: 150, batch_loss: 3.871162176132202\n",
      ". . . batch: 180, batch_loss: 3.620654344558716\n",
      ". . . batch: 210, batch_loss: 3.9112894535064697\n",
      ". . . batch: 240, batch_loss: 4.022366523742676\n",
      "EPOCH: 5, train_loss: 3.830618813856323, val_loss: 3.642895207260595, val_score: 0.22358346094946402\n",
      ">>>>>>  EPOCH 5: validation score 0.22358346094946402\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 3.6722543239593506\n",
      ". . . batch: 30, batch_loss: 3.4433770179748535\n",
      ". . . batch: 60, batch_loss: 3.569530963897705\n",
      ". . . batch: 90, batch_loss: 3.621659517288208\n",
      ". . . batch: 120, batch_loss: 3.6688787937164307\n",
      ". . . batch: 150, batch_loss: 3.3129115104675293\n",
      ". . . batch: 180, batch_loss: 3.270733594894409\n",
      ". . . batch: 210, batch_loss: 3.1278412342071533\n",
      ". . . batch: 240, batch_loss: 3.1031382083892822\n",
      "EPOCH: 6, train_loss: 3.432588648440234, val_loss: 3.3030299165032124, val_score: 0.29249617151607965\n",
      ">>>>>>  EPOCH 6: validation score 0.29249617151607965\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.3102798461914062\n",
      ". . . batch: 30, batch_loss: 2.6957147121429443\n",
      ". . . batch: 60, batch_loss: 3.0614287853240967\n",
      ". . . batch: 90, batch_loss: 3.376148223876953\n",
      ". . . batch: 120, batch_loss: 3.2145302295684814\n",
      ". . . batch: 150, batch_loss: 3.1297671794891357\n",
      ". . . batch: 180, batch_loss: 2.930676221847534\n",
      ". . . batch: 210, batch_loss: 3.237539052963257\n",
      ". . . batch: 240, batch_loss: 2.8202855587005615\n",
      "EPOCH: 7, train_loss: 3.0509828453633325, val_loss: 2.875357689279497, val_score: 0.3614088820826952\n",
      ">>>>>>  EPOCH 7: validation score 0.3614088820826952\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 3.0341567993164062\n",
      ". . . batch: 30, batch_loss: 2.605260133743286\n",
      ". . . batch: 60, batch_loss: 2.7925188541412354\n",
      ". . . batch: 90, batch_loss: 2.701043128967285\n",
      ". . . batch: 120, batch_loss: 2.732783794403076\n",
      ". . . batch: 150, batch_loss: 2.7275214195251465\n",
      ". . . batch: 180, batch_loss: 2.8459296226501465\n",
      ". . . batch: 210, batch_loss: 2.270582914352417\n",
      ". . . batch: 240, batch_loss: 2.961229085922241\n",
      "EPOCH: 8, train_loss: 2.6821792881880255, val_loss: 2.6624261935551963, val_score: 0.4282797345584482\n",
      ">>>>>>  EPOCH 8: validation score 0.4282797345584482\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.342412233352661\n",
      ". . . batch: 30, batch_loss: 2.154353141784668\n",
      ". . . batch: 60, batch_loss: 2.5737626552581787\n",
      ". . . batch: 90, batch_loss: 2.3141989707946777\n",
      ". . . batch: 120, batch_loss: 2.3253257274627686\n",
      ". . . batch: 150, batch_loss: 2.4224257469177246\n",
      ". . . batch: 180, batch_loss: 1.9566214084625244\n",
      ". . . batch: 210, batch_loss: 2.383527994155884\n",
      ". . . batch: 240, batch_loss: 2.3322415351867676\n",
      "EPOCH: 9, train_loss: 2.3156750882739456, val_loss: 2.4957612481984235, val_score: 0.4920877998979071\n",
      ">>>>>>  EPOCH 9: validation score 0.4920877998979071\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 2.3560791015625\n",
      ". . . batch: 30, batch_loss: 1.8656069040298462\n",
      ". . . batch: 60, batch_loss: 1.9210131168365479\n",
      ". . . batch: 90, batch_loss: 1.9326740503311157\n",
      ". . . batch: 120, batch_loss: 2.1229820251464844\n",
      ". . . batch: 150, batch_loss: 1.9226056337356567\n",
      ". . . batch: 180, batch_loss: 1.8191965818405151\n",
      ". . . batch: 210, batch_loss: 1.9173678159713745\n",
      ". . . batch: 240, batch_loss: 2.0144147872924805\n",
      "EPOCH: 10, train_loss: 2.022091863315497, val_loss: 1.9796049649065188, val_score: 0.5487493619193466\n",
      ">>>>>>  EPOCH 10: validation score 0.5487493619193466\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.9510482549667358\n",
      ". . . batch: 30, batch_loss: 1.6782872676849365\n",
      ". . . batch: 60, batch_loss: 1.7061060667037964\n",
      ". . . batch: 90, batch_loss: 1.7351129055023193\n",
      ". . . batch: 120, batch_loss: 1.480601191520691\n",
      ". . . batch: 150, batch_loss: 1.8553272485733032\n",
      ". . . batch: 180, batch_loss: 1.4300302267074585\n",
      ". . . batch: 210, batch_loss: 1.6314270496368408\n",
      ". . . batch: 240, batch_loss: 1.306405782699585\n",
      "EPOCH: 11, train_loss: 1.718239386135073, val_loss: 1.8356835751822502, val_score: 0.5839714139867279\n",
      ">>>>>>  EPOCH 11: validation score 0.5839714139867279\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.607080340385437\n",
      ". . . batch: 30, batch_loss: 1.7757182121276855\n",
      ". . . batch: 60, batch_loss: 1.6770957708358765\n",
      ". . . batch: 90, batch_loss: 1.4667832851409912\n",
      ". . . batch: 120, batch_loss: 1.5960564613342285\n",
      ". . . batch: 150, batch_loss: 1.5007615089416504\n",
      ". . . batch: 180, batch_loss: 1.1919747591018677\n",
      ". . . batch: 210, batch_loss: 1.0021235942840576\n",
      ". . . batch: 240, batch_loss: 1.235339641571045\n",
      "EPOCH: 12, train_loss: 1.4673840434693572, val_loss: 1.672824282537807, val_score: 0.631955079122001\n",
      ">>>>>>  EPOCH 12: validation score 0.631955079122001\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.039086103439331\n",
      ". . . batch: 30, batch_loss: 1.2589462995529175\n",
      ". . . batch: 60, batch_loss: 1.1925495862960815\n",
      ". . . batch: 90, batch_loss: 1.1925517320632935\n",
      ". . . batch: 120, batch_loss: 1.4568883180618286\n",
      ". . . batch: 150, batch_loss: 1.319326400756836\n",
      ". . . batch: 180, batch_loss: 1.080774188041687\n",
      ". . . batch: 210, batch_loss: 1.1223413944244385\n",
      ". . . batch: 240, batch_loss: 1.0291845798492432\n",
      "EPOCH: 13, train_loss: 1.2414565795837935, val_loss: 1.6946914801091868, val_score: 0.6431852986217458\n",
      ">>>>>>  EPOCH 13: validation score 0.6431852986217458\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 0.7608779668807983\n",
      ". . . batch: 30, batch_loss: 0.991425096988678\n",
      ". . . batch: 60, batch_loss: 1.1344658136367798\n",
      ". . . batch: 90, batch_loss: 1.1800339221954346\n",
      ". . . batch: 120, batch_loss: 0.9850427508354187\n",
      ". . . batch: 150, batch_loss: 1.1429810523986816\n",
      ". . . batch: 180, batch_loss: 1.0403008460998535\n",
      ". . . batch: 210, batch_loss: 1.164695382118225\n",
      ". . . batch: 240, batch_loss: 0.8537136316299438\n",
      "EPOCH: 14, train_loss: 1.0402750750975827, val_loss: 1.401257943023335, val_score: 0.6845329249617151\n",
      ">>>>>>  EPOCH 14: validation score 0.6845329249617151\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.8560143113136292\n",
      ". . . batch: 30, batch_loss: 1.233446717262268\n",
      ". . . batch: 60, batch_loss: 0.746666669845581\n",
      ". . . batch: 90, batch_loss: 0.785098671913147\n",
      ". . . batch: 120, batch_loss: 0.6295793056488037\n",
      ". . . batch: 150, batch_loss: 0.7500461935997009\n",
      ". . . batch: 180, batch_loss: 0.7813817858695984\n",
      ". . . batch: 210, batch_loss: 0.9009057283401489\n",
      ". . . batch: 240, batch_loss: 0.849507212638855\n",
      "EPOCH: 15, train_loss: 0.8870084436971751, val_loss: 1.447807907155066, val_score: 0.703420112302195\n",
      ">>>>>>  EPOCH 15: validation score 0.703420112302195\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.6789305210113525\n",
      ". . . batch: 30, batch_loss: 0.7823745012283325\n",
      ". . . batch: 60, batch_loss: 0.7339174151420593\n",
      ". . . batch: 90, batch_loss: 0.8874735236167908\n",
      ". . . batch: 120, batch_loss: 0.7947493195533752\n",
      ". . . batch: 150, batch_loss: 0.5952416658401489\n",
      ". . . batch: 180, batch_loss: 0.6903759241104126\n",
      ". . . batch: 210, batch_loss: 0.844925045967102\n",
      ". . . batch: 240, batch_loss: 0.9505865573883057\n",
      "EPOCH: 16, train_loss: 0.7657189142348163, val_loss: 1.4265224734942117, val_score: 0.7090352220520674\n",
      ">>>>>>  EPOCH 16: validation score 0.7090352220520674\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.6483153700828552\n",
      ". . . batch: 30, batch_loss: 0.9123059511184692\n",
      ". . . batch: 60, batch_loss: 0.6242077946662903\n",
      ". . . batch: 90, batch_loss: 0.5390424728393555\n",
      ". . . batch: 120, batch_loss: 0.5789579749107361\n",
      ". . . batch: 150, batch_loss: 0.5321117043495178\n",
      ". . . batch: 180, batch_loss: 0.7071408033370972\n",
      ". . . batch: 210, batch_loss: 0.3769974112510681\n",
      ". . . batch: 240, batch_loss: 0.5094465613365173\n",
      "EPOCH: 17, train_loss: 0.6476785834155865, val_loss: 1.2000584792007103, val_score: 0.7238386932108218\n",
      ">>>>>>  EPOCH 17: validation score 0.7238386932108218\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.6773064732551575\n",
      ". . . batch: 30, batch_loss: 0.5880081057548523\n",
      ". . . batch: 60, batch_loss: 0.5731204152107239\n",
      ". . . batch: 90, batch_loss: 0.8669244050979614\n",
      ". . . batch: 120, batch_loss: 0.76784348487854\n",
      ". . . batch: 150, batch_loss: 0.38509729504585266\n",
      ". . . batch: 180, batch_loss: 0.5636367201805115\n",
      ". . . batch: 210, batch_loss: 0.5212922692298889\n",
      ". . . batch: 240, batch_loss: 0.41960397362709045\n",
      "EPOCH: 18, train_loss: 0.5688552754138829, val_loss: 1.312901217829097, val_score: 0.7253700867789689\n",
      ">>>>>>  EPOCH 18: validation score 0.7253700867789689\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.46814337372779846\n",
      ". . . batch: 30, batch_loss: 0.41158467531204224\n",
      ". . . batch: 60, batch_loss: 0.4574844539165497\n",
      ". . . batch: 90, batch_loss: 0.38922929763793945\n",
      ". . . batch: 120, batch_loss: 0.6337774395942688\n",
      ". . . batch: 150, batch_loss: 0.34583795070648193\n",
      ". . . batch: 180, batch_loss: 0.7569991946220398\n",
      ". . . batch: 210, batch_loss: 0.43275535106658936\n",
      ". . . batch: 240, batch_loss: 0.3737369179725647\n",
      "EPOCH: 19, train_loss: 0.47422022878456505, val_loss: 1.2523105690876646, val_score: 0.731495661051557\n",
      ">>>>>>  EPOCH 19: validation score 0.731495661051557\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.3530706763267517\n",
      ". . . batch: 30, batch_loss: 0.28326690196990967\n",
      ". . . batch: 60, batch_loss: 0.4587222635746002\n",
      ". . . batch: 90, batch_loss: 0.40006452798843384\n",
      ". . . batch: 120, batch_loss: 0.4909842908382416\n",
      ". . . batch: 150, batch_loss: 0.4559735357761383\n",
      ". . . batch: 180, batch_loss: 0.4369255602359772\n",
      ". . . batch: 210, batch_loss: 0.4377232491970062\n",
      ". . . batch: 240, batch_loss: 0.4594472050666809\n",
      "EPOCH: 20, train_loss: 0.4217099262151255, val_loss: 1.080810089002956, val_score: 0.7549770290964779\n",
      ">>>>>>  EPOCH 20: validation score 0.7549770290964779\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.3863633871078491\n",
      ". . . batch: 30, batch_loss: 0.37173429131507874\n",
      ". . . batch: 60, batch_loss: 0.5496764779090881\n",
      ". . . batch: 90, batch_loss: 0.39518266916275024\n",
      ". . . batch: 120, batch_loss: 0.3408365845680237\n",
      ". . . batch: 150, batch_loss: 0.35467979311943054\n",
      ". . . batch: 180, batch_loss: 0.45983627438545227\n",
      ". . . batch: 210, batch_loss: 0.3167118728160858\n",
      ". . . batch: 240, batch_loss: 0.25676649808883667\n",
      "EPOCH: 21, train_loss: 0.3688102148806871, val_loss: 0.933758322713953, val_score: 0.77947932618683\n",
      ">>>>>>  EPOCH 21: validation score 0.77947932618683\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.5311765074729919\n",
      ". . . batch: 30, batch_loss: 0.31534120440483093\n",
      ". . . batch: 60, batch_loss: 0.27195075154304504\n",
      ". . . batch: 90, batch_loss: 0.3413142263889313\n",
      ". . . batch: 120, batch_loss: 0.4012959897518158\n",
      ". . . batch: 150, batch_loss: 0.2508490979671478\n",
      ". . . batch: 180, batch_loss: 0.3184184730052948\n",
      ". . . batch: 210, batch_loss: 0.3675372004508972\n",
      ". . . batch: 240, batch_loss: 0.19866885244846344\n",
      "EPOCH: 22, train_loss: 0.32316100105309675, val_loss: 1.2637771304809688, val_score: 0.7478305257784584\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.3503720164299011\n",
      ". . . batch: 30, batch_loss: 0.2989197373390198\n",
      ". . . batch: 60, batch_loss: 0.38637369871139526\n",
      ". . . batch: 90, batch_loss: 0.3247087895870209\n",
      ". . . batch: 120, batch_loss: 0.30803823471069336\n",
      ". . . batch: 150, batch_loss: 0.2683354616165161\n",
      ". . . batch: 180, batch_loss: 0.24735046923160553\n",
      ". . . batch: 210, batch_loss: 0.20898102223873138\n",
      ". . . batch: 240, batch_loss: 0.29224684834480286\n",
      "EPOCH: 23, train_loss: 0.272451600727083, val_loss: 0.7659570297056981, val_score: 0.8106176620724859\n",
      ">>>>>>  EPOCH 23: validation score 0.8106176620724859\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.24514064192771912\n",
      ". . . batch: 30, batch_loss: 0.3848111033439636\n",
      ". . . batch: 60, batch_loss: 0.26708662509918213\n",
      ". . . batch: 90, batch_loss: 0.23484092950820923\n",
      ". . . batch: 120, batch_loss: 0.3495597243309021\n",
      ". . . batch: 150, batch_loss: 0.21361078321933746\n",
      ". . . batch: 180, batch_loss: 0.2745763659477234\n",
      ". . . batch: 210, batch_loss: 0.13402652740478516\n",
      ". . . batch: 240, batch_loss: 0.21021559834480286\n",
      "EPOCH: 24, train_loss: 0.24476163253299352, val_loss: 1.2973382802623687, val_score: 0.749872383869321\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.229319766163826\n",
      ". . . batch: 30, batch_loss: 0.2028617560863495\n",
      ". . . batch: 60, batch_loss: 0.18691180646419525\n",
      ". . . batch: 90, batch_loss: 0.2588265538215637\n",
      ". . . batch: 120, batch_loss: 0.2772201895713806\n",
      ". . . batch: 150, batch_loss: 0.23580874502658844\n",
      ". . . batch: 180, batch_loss: 0.14418064057826996\n",
      ". . . batch: 210, batch_loss: 0.20034419000148773\n",
      ". . . batch: 240, batch_loss: 0.2707124650478363\n",
      "EPOCH: 25, train_loss: 0.21924721769321334, val_loss: 0.7154017138210208, val_score: 0.8259315977539561\n",
      ">>>>>>  EPOCH 25: validation score 0.8259315977539561\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.2924633026123047\n",
      ". . . batch: 30, batch_loss: 0.08691217005252838\n",
      ". . . batch: 60, batch_loss: 0.21144512295722961\n",
      ". . . batch: 90, batch_loss: 0.18369919061660767\n",
      ". . . batch: 120, batch_loss: 0.10662747919559479\n",
      ". . . batch: 150, batch_loss: 0.2714633345603943\n",
      ". . . batch: 180, batch_loss: 0.326045960187912\n",
      ". . . batch: 210, batch_loss: 0.13370510935783386\n",
      ". . . batch: 240, batch_loss: 0.20373228192329407\n",
      "EPOCH: 26, train_loss: 0.19713111216230184, val_loss: 1.0233882834965535, val_score: 0.7805002552322614\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.10231844335794449\n",
      ". . . batch: 30, batch_loss: 0.1474921852350235\n",
      ". . . batch: 60, batch_loss: 0.31409645080566406\n",
      ". . . batch: 90, batch_loss: 0.24852977693080902\n",
      ". . . batch: 120, batch_loss: 0.146549254655838\n",
      ". . . batch: 150, batch_loss: 0.1540141999721527\n",
      ". . . batch: 180, batch_loss: 0.09509630501270294\n",
      ". . . batch: 210, batch_loss: 0.12671226263046265\n",
      ". . . batch: 240, batch_loss: 0.2730625867843628\n",
      "EPOCH: 27, train_loss: 0.1746842783889663, val_loss: 0.8883421362349478, val_score: 0.8044920877998979\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.11744915693998337\n",
      ". . . batch: 30, batch_loss: 0.12455295026302338\n",
      ". . . batch: 60, batch_loss: 0.20390905439853668\n",
      ". . . batch: 90, batch_loss: 0.11231829226016998\n",
      ". . . batch: 120, batch_loss: 0.08148737251758575\n",
      ". . . batch: 150, batch_loss: 0.1219341903924942\n",
      ". . . batch: 180, batch_loss: 0.10969632118940353\n",
      ". . . batch: 210, batch_loss: 0.25083157420158386\n",
      ". . . batch: 240, batch_loss: 0.2804033160209656\n",
      "EPOCH: 28, train_loss: 0.1634097917061021, val_loss: 0.8198217309334064, val_score: 0.8162327718223582\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.23248745501041412\n",
      ". . . batch: 30, batch_loss: 0.12700936198234558\n",
      ". . . batch: 60, batch_loss: 0.174645334482193\n",
      ". . . batch: 90, batch_loss: 0.23392607271671295\n",
      ". . . batch: 120, batch_loss: 0.1399984359741211\n",
      ". . . batch: 150, batch_loss: 0.2185216248035431\n",
      ". . . batch: 180, batch_loss: 0.13172553479671478\n",
      ". . . batch: 210, batch_loss: 0.1648585945367813\n",
      ". . . batch: 240, batch_loss: 0.1289849877357483\n",
      "EPOCH: 29, train_loss: 0.1481965418432409, val_loss: 0.8098775268052567, val_score: 0.8055130168453293\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.06406774371862411\n",
      ". . . batch: 30, batch_loss: 0.08431792259216309\n",
      ". . . batch: 60, batch_loss: 0.10373274236917496\n",
      ". . . batch: 90, batch_loss: 0.12874583899974823\n",
      ". . . batch: 120, batch_loss: 0.045580897480249405\n",
      ". . . batch: 150, batch_loss: 0.11462052911520004\n",
      ". . . batch: 180, batch_loss: 0.04473158344626427\n",
      ". . . batch: 210, batch_loss: 0.07895810157060623\n",
      ". . . batch: 240, batch_loss: 0.12278963625431061\n",
      "EPOCH: 30, train_loss: 0.13755736231748297, val_loss: 0.9453241131973987, val_score: 0.7901990811638591\n",
      "{'best_epoch': 25, 'best_score': 0.8259315977539561}\n",
      "----------\n",
      "----- 4 fold -----\n",
      "1 / 30\n",
      ". . . batch: 0, batch_loss: 5.375960350036621\n",
      ". . . batch: 30, batch_loss: 5.298272609710693\n",
      ". . . batch: 60, batch_loss: 5.293790817260742\n",
      ". . . batch: 90, batch_loss: 5.335606098175049\n",
      ". . . batch: 120, batch_loss: 5.33499002456665\n",
      ". . . batch: 150, batch_loss: 5.2702717781066895\n",
      ". . . batch: 180, batch_loss: 5.249760150909424\n",
      ". . . batch: 210, batch_loss: 5.190081596374512\n",
      ". . . batch: 240, batch_loss: 5.251443386077881\n",
      "EPOCH: 1, train_loss: 5.269891904901576, val_loss: 5.179859131574631, val_score: 0.016213389121338913\n",
      ">>>>>>  EPOCH 1: validation score 0.016213389121338913\n",
      "2 / 30\n",
      ". . . batch: 0, batch_loss: 5.229425430297852\n",
      ". . . batch: 30, batch_loss: 5.278030872344971\n",
      ". . . batch: 60, batch_loss: 5.04066801071167\n",
      ". . . batch: 90, batch_loss: 5.162640571594238\n",
      ". . . batch: 120, batch_loss: 5.005850791931152\n",
      ". . . batch: 150, batch_loss: 5.009695053100586\n",
      ". . . batch: 180, batch_loss: 5.049544811248779\n",
      ". . . batch: 210, batch_loss: 4.968888759613037\n",
      ". . . batch: 240, batch_loss: 4.9316911697387695\n",
      "EPOCH: 2, train_loss: 5.069007202431006, val_loss: 4.853900231420994, val_score: 0.07635983263598327\n",
      ">>>>>>  EPOCH 2: validation score 0.07635983263598327\n",
      "3 / 30\n",
      ". . . batch: 0, batch_loss: 4.91977596282959\n",
      ". . . batch: 30, batch_loss: 4.832688808441162\n",
      ". . . batch: 60, batch_loss: 4.649248123168945\n",
      ". . . batch: 90, batch_loss: 4.77420711517334\n",
      ". . . batch: 120, batch_loss: 4.713987350463867\n",
      ". . . batch: 150, batch_loss: 4.6928534507751465\n",
      ". . . batch: 180, batch_loss: 4.532944202423096\n",
      ". . . batch: 210, batch_loss: 4.407074451446533\n",
      ". . . batch: 240, batch_loss: 4.676094055175781\n",
      "EPOCH: 3, train_loss: 4.666519048478866, val_loss: 4.451936051249504, val_score: 0.125\n",
      ">>>>>>  EPOCH 3: validation score 0.125\n",
      "4 / 30\n",
      ". . . batch: 0, batch_loss: 4.448751449584961\n",
      ". . . batch: 30, batch_loss: 4.261253356933594\n",
      ". . . batch: 60, batch_loss: 4.282288074493408\n",
      ". . . batch: 90, batch_loss: 4.317010402679443\n",
      ". . . batch: 120, batch_loss: 4.5255632400512695\n",
      ". . . batch: 150, batch_loss: 4.125495910644531\n",
      ". . . batch: 180, batch_loss: 3.794621229171753\n",
      ". . . batch: 210, batch_loss: 4.001654148101807\n",
      ". . . batch: 240, batch_loss: 3.810281276702881\n",
      "EPOCH: 4, train_loss: 4.2194790478105935, val_loss: 4.071558136492968, val_score: 0.1506276150627615\n",
      ">>>>>>  EPOCH 4: validation score 0.1506276150627615\n",
      "5 / 30\n",
      ". . . batch: 0, batch_loss: 4.115530014038086\n",
      ". . . batch: 30, batch_loss: 4.345672130584717\n",
      ". . . batch: 60, batch_loss: 3.819689989089966\n",
      ". . . batch: 90, batch_loss: 3.8371684551239014\n",
      ". . . batch: 120, batch_loss: 3.589566230773926\n",
      ". . . batch: 150, batch_loss: 3.9650352001190186\n",
      ". . . batch: 180, batch_loss: 3.9026031494140625\n",
      ". . . batch: 210, batch_loss: 3.436222791671753\n",
      ". . . batch: 240, batch_loss: 3.7661056518554688\n",
      "EPOCH: 5, train_loss: 3.81056156599963, val_loss: 3.545131418853998, val_score: 0.2196652719665272\n",
      ">>>>>>  EPOCH 5: validation score 0.2196652719665272\n",
      "6 / 30\n",
      ". . . batch: 0, batch_loss: 3.718907356262207\n",
      ". . . batch: 30, batch_loss: 3.707772731781006\n",
      ". . . batch: 60, batch_loss: 3.6646971702575684\n",
      ". . . batch: 90, batch_loss: 3.2631735801696777\n",
      ". . . batch: 120, batch_loss: 3.953148603439331\n",
      ". . . batch: 150, batch_loss: 3.150813102722168\n",
      ". . . batch: 180, batch_loss: 3.2774672508239746\n",
      ". . . batch: 210, batch_loss: 3.320046901702881\n",
      ". . . batch: 240, batch_loss: 3.3481454849243164\n",
      "EPOCH: 6, train_loss: 3.391341268574749, val_loss: 3.453656744211912, val_score: 0.26202928870292885\n",
      ">>>>>>  EPOCH 6: validation score 0.26202928870292885\n",
      "7 / 30\n",
      ". . . batch: 0, batch_loss: 3.0739126205444336\n",
      ". . . batch: 30, batch_loss: 3.1787476539611816\n",
      ". . . batch: 60, batch_loss: 3.263129711151123\n",
      ". . . batch: 90, batch_loss: 3.0994515419006348\n",
      ". . . batch: 120, batch_loss: 3.152495861053467\n",
      ". . . batch: 150, batch_loss: 2.967313051223755\n",
      ". . . batch: 180, batch_loss: 2.9768126010894775\n",
      ". . . batch: 210, batch_loss: 2.9256629943847656\n",
      ". . . batch: 240, batch_loss: 2.381695032119751\n",
      "EPOCH: 7, train_loss: 3.014181563589311, val_loss: 2.8909329436719418, val_score: 0.3624476987447699\n",
      ">>>>>>  EPOCH 7: validation score 0.3624476987447699\n",
      "8 / 30\n",
      ". . . batch: 0, batch_loss: 2.953362464904785\n",
      ". . . batch: 30, batch_loss: 2.8494086265563965\n",
      ". . . batch: 60, batch_loss: 2.7663331031799316\n",
      ". . . batch: 90, batch_loss: 2.6289007663726807\n",
      ". . . batch: 120, batch_loss: 2.608229160308838\n",
      ". . . batch: 150, batch_loss: 2.6849617958068848\n",
      ". . . batch: 180, batch_loss: 2.6430346965789795\n",
      ". . . batch: 210, batch_loss: 2.275564670562744\n",
      ". . . batch: 240, batch_loss: 2.4705615043640137\n",
      "EPOCH: 8, train_loss: 2.649885972340902, val_loss: 2.542866140604019, val_score: 0.448744769874477\n",
      ">>>>>>  EPOCH 8: validation score 0.448744769874477\n",
      "9 / 30\n",
      ". . . batch: 0, batch_loss: 2.435631513595581\n",
      ". . . batch: 30, batch_loss: 2.1473660469055176\n",
      ". . . batch: 60, batch_loss: 2.4460136890411377\n",
      ". . . batch: 90, batch_loss: 2.338630199432373\n",
      ". . . batch: 120, batch_loss: 2.6025261878967285\n",
      ". . . batch: 150, batch_loss: 2.1179990768432617\n",
      ". . . batch: 180, batch_loss: 2.174579381942749\n",
      ". . . batch: 210, batch_loss: 2.370068073272705\n",
      ". . . batch: 240, batch_loss: 2.533574104309082\n",
      "EPOCH: 9, train_loss: 2.29428705683461, val_loss: 2.435509741306305, val_score: 0.49215481171548114\n",
      ">>>>>>  EPOCH 9: validation score 0.49215481171548114\n",
      "10 / 30\n",
      ". . . batch: 0, batch_loss: 2.0167183876037598\n",
      ". . . batch: 30, batch_loss: 1.9749987125396729\n",
      ". . . batch: 60, batch_loss: 2.3116564750671387\n",
      ". . . batch: 90, batch_loss: 2.572628974914551\n",
      ". . . batch: 120, batch_loss: 1.8947372436523438\n",
      ". . . batch: 150, batch_loss: 2.007565498352051\n",
      ". . . batch: 180, batch_loss: 2.1928868293762207\n",
      ". . . batch: 210, batch_loss: 1.847880244255066\n",
      ". . . batch: 240, batch_loss: 1.7253135442733765\n",
      "EPOCH: 10, train_loss: 2.0016518844498514, val_loss: 2.1415765080600977, val_score: 0.5350418410041841\n",
      ">>>>>>  EPOCH 10: validation score 0.5350418410041841\n",
      "11 / 30\n",
      ". . . batch: 0, batch_loss: 1.6469502449035645\n",
      ". . . batch: 30, batch_loss: 1.4773826599121094\n",
      ". . . batch: 60, batch_loss: 2.0185227394104004\n",
      ". . . batch: 90, batch_loss: 1.7249951362609863\n",
      ". . . batch: 120, batch_loss: 1.6639078855514526\n",
      ". . . batch: 150, batch_loss: 1.7542346715927124\n",
      ". . . batch: 180, batch_loss: 1.6773464679718018\n",
      ". . . batch: 210, batch_loss: 1.6032240390777588\n",
      ". . . batch: 240, batch_loss: 1.31544029712677\n",
      "EPOCH: 11, train_loss: 1.705970464370869, val_loss: 2.0053684134036303, val_score: 0.571652719665272\n",
      ">>>>>>  EPOCH 11: validation score 0.571652719665272\n",
      "12 / 30\n",
      ". . . batch: 0, batch_loss: 1.3994816541671753\n",
      ". . . batch: 30, batch_loss: 1.737007975578308\n",
      ". . . batch: 60, batch_loss: 1.520174503326416\n",
      ". . . batch: 90, batch_loss: 1.593629240989685\n",
      ". . . batch: 120, batch_loss: 1.4167016744613647\n",
      ". . . batch: 150, batch_loss: 1.7412492036819458\n",
      ". . . batch: 180, batch_loss: 1.46300208568573\n",
      ". . . batch: 210, batch_loss: 1.3913294076919556\n",
      ". . . batch: 240, batch_loss: 1.64588463306427\n",
      "EPOCH: 12, train_loss: 1.4603271020783313, val_loss: 1.8186512179672718, val_score: 0.6187238493723849\n",
      ">>>>>>  EPOCH 12: validation score 0.6187238493723849\n",
      "13 / 30\n",
      ". . . batch: 0, batch_loss: 1.1854361295700073\n",
      ". . . batch: 30, batch_loss: 1.3844733238220215\n",
      ". . . batch: 60, batch_loss: 1.207726001739502\n",
      ". . . batch: 90, batch_loss: 1.1562362909317017\n",
      ". . . batch: 120, batch_loss: 1.056896686553955\n",
      ". . . batch: 150, batch_loss: 1.2238670587539673\n",
      ". . . batch: 180, batch_loss: 1.2821704149246216\n",
      ". . . batch: 210, batch_loss: 1.1662739515304565\n",
      ". . . batch: 240, batch_loss: 1.4636482000350952\n",
      "EPOCH: 13, train_loss: 1.239054939261189, val_loss: 1.8332755211740732, val_score: 0.6286610878661087\n",
      ">>>>>>  EPOCH 13: validation score 0.6286610878661087\n",
      "14 / 30\n",
      ". . . batch: 0, batch_loss: 0.8779346346855164\n",
      ". . . batch: 30, batch_loss: 1.0528029203414917\n",
      ". . . batch: 60, batch_loss: 0.9342750310897827\n",
      ". . . batch: 90, batch_loss: 1.1881245374679565\n",
      ". . . batch: 120, batch_loss: 1.0253138542175293\n",
      ". . . batch: 150, batch_loss: 0.8758799433708191\n",
      ". . . batch: 180, batch_loss: 1.1040247678756714\n",
      ". . . batch: 210, batch_loss: 1.0017517805099487\n",
      ". . . batch: 240, batch_loss: 0.9847227931022644\n",
      "EPOCH: 14, train_loss: 1.0447220996574118, val_loss: 1.2965299747884274, val_score: 0.7201882845188285\n",
      ">>>>>>  EPOCH 14: validation score 0.7201882845188285\n",
      "15 / 30\n",
      ". . . batch: 0, batch_loss: 0.7731432318687439\n",
      ". . . batch: 30, batch_loss: 0.8574849963188171\n",
      ". . . batch: 60, batch_loss: 0.8240405321121216\n",
      ". . . batch: 90, batch_loss: 0.6604862213134766\n",
      ". . . batch: 120, batch_loss: 0.7062389254570007\n",
      ". . . batch: 150, batch_loss: 0.7469848990440369\n",
      ". . . batch: 180, batch_loss: 0.7283029556274414\n",
      ". . . batch: 210, batch_loss: 0.7047168016433716\n",
      ". . . batch: 240, batch_loss: 0.6466935276985168\n",
      "EPOCH: 15, train_loss: 0.8955921857445323, val_loss: 1.1186923515051603, val_score: 0.7447698744769874\n",
      ">>>>>>  EPOCH 15: validation score 0.7447698744769874\n",
      "16 / 30\n",
      ". . . batch: 0, batch_loss: 0.9224371314048767\n",
      ". . . batch: 30, batch_loss: 0.8426944613456726\n",
      ". . . batch: 60, batch_loss: 0.8644635677337646\n",
      ". . . batch: 90, batch_loss: 0.6425586938858032\n",
      ". . . batch: 120, batch_loss: 0.7311636805534363\n",
      ". . . batch: 150, batch_loss: 0.6520057320594788\n",
      ". . . batch: 180, batch_loss: 0.8531476855278015\n",
      ". . . batch: 210, batch_loss: 0.8280554413795471\n",
      ". . . batch: 240, batch_loss: 0.7713161706924438\n",
      "EPOCH: 16, train_loss: 0.7571629378530715, val_loss: 1.4828045992180705, val_score: 0.6971757322175732\n",
      "17 / 30\n",
      ". . . batch: 0, batch_loss: 0.6503194570541382\n",
      ". . . batch: 30, batch_loss: 0.8263322114944458\n",
      ". . . batch: 60, batch_loss: 0.7270005345344543\n",
      ". . . batch: 90, batch_loss: 0.6121860146522522\n",
      ". . . batch: 120, batch_loss: 0.6147176027297974\n",
      ". . . batch: 150, batch_loss: 0.44790059328079224\n",
      ". . . batch: 180, batch_loss: 0.6000775694847107\n",
      ". . . batch: 210, batch_loss: 0.7131439447402954\n",
      ". . . batch: 240, batch_loss: 0.7377139925956726\n",
      "EPOCH: 17, train_loss: 0.6489557948377394, val_loss: 1.4253844656050205, val_score: 0.7144351464435146\n",
      "18 / 30\n",
      ". . . batch: 0, batch_loss: 0.6470499634742737\n",
      ". . . batch: 30, batch_loss: 0.5241743922233582\n",
      ". . . batch: 60, batch_loss: 0.48054900765419006\n",
      ". . . batch: 90, batch_loss: 0.6461789011955261\n",
      ". . . batch: 120, batch_loss: 0.6184324622154236\n",
      ". . . batch: 150, batch_loss: 0.40732812881469727\n",
      ". . . batch: 180, batch_loss: 0.3913800120353699\n",
      ". . . batch: 210, batch_loss: 0.33003145456314087\n",
      ". . . batch: 240, batch_loss: 0.4181562662124634\n",
      "EPOCH: 18, train_loss: 0.5549330508267436, val_loss: 1.1680992702022195, val_score: 0.7426778242677824\n",
      "19 / 30\n",
      ". . . batch: 0, batch_loss: 0.5154033303260803\n",
      ". . . batch: 30, batch_loss: 0.4892056882381439\n",
      ". . . batch: 60, batch_loss: 0.3836786448955536\n",
      ". . . batch: 90, batch_loss: 0.45843204855918884\n",
      ". . . batch: 120, batch_loss: 0.41663631796836853\n",
      ". . . batch: 150, batch_loss: 0.6276676058769226\n",
      ". . . batch: 180, batch_loss: 0.5726240277290344\n",
      ". . . batch: 210, batch_loss: 0.28712743520736694\n",
      ". . . batch: 240, batch_loss: 0.4662121832370758\n",
      "EPOCH: 19, train_loss: 0.4744530980233793, val_loss: 1.2721551759168506, val_score: 0.7322175732217574\n",
      "20 / 30\n",
      ". . . batch: 0, batch_loss: 0.47208473086357117\n",
      ". . . batch: 30, batch_loss: 0.44846999645233154\n",
      ". . . batch: 60, batch_loss: 0.42639288306236267\n",
      ". . . batch: 90, batch_loss: 0.41405755281448364\n",
      ". . . batch: 120, batch_loss: 0.4787527322769165\n",
      ". . . batch: 150, batch_loss: 0.4548206329345703\n",
      ". . . batch: 180, batch_loss: 0.41791486740112305\n",
      ". . . batch: 210, batch_loss: 0.30117493867874146\n",
      ". . . batch: 240, batch_loss: 0.29860323667526245\n",
      "EPOCH: 20, train_loss: 0.4123681860941429, val_loss: 1.1818241439759731, val_score: 0.7447698744769874\n",
      "21 / 30\n",
      ". . . batch: 0, batch_loss: 0.31009432673454285\n",
      ". . . batch: 30, batch_loss: 0.45357710123062134\n",
      ". . . batch: 60, batch_loss: 0.4137318432331085\n",
      ". . . batch: 90, batch_loss: 0.5406271815299988\n",
      ". . . batch: 120, batch_loss: 0.6019284725189209\n",
      ". . . batch: 150, batch_loss: 0.3773365020751953\n",
      ". . . batch: 180, batch_loss: 0.35178905725479126\n",
      ". . . batch: 210, batch_loss: 0.2672868072986603\n",
      ". . . batch: 240, batch_loss: 0.2013661414384842\n",
      "EPOCH: 21, train_loss: 0.3741768913136589, val_loss: 0.7022263794206083, val_score: 0.8185146443514645\n",
      ">>>>>>  EPOCH 21: validation score 0.8185146443514645\n",
      "22 / 30\n",
      ". . . batch: 0, batch_loss: 0.5549719333648682\n",
      ". . . batch: 30, batch_loss: 0.27042388916015625\n",
      ". . . batch: 60, batch_loss: 0.30014699697494507\n",
      ". . . batch: 90, batch_loss: 0.23107023537158966\n",
      ". . . batch: 120, batch_loss: 0.3507835268974304\n",
      ". . . batch: 150, batch_loss: 0.23957429826259613\n",
      ". . . batch: 180, batch_loss: 0.5497376918792725\n",
      ". . . batch: 210, batch_loss: 0.2799978256225586\n",
      ". . . batch: 240, batch_loss: 0.4215889275074005\n",
      "EPOCH: 22, train_loss: 0.31622392800119187, val_loss: 0.8835485898889601, val_score: 0.7955020920502092\n",
      "23 / 30\n",
      ". . . batch: 0, batch_loss: 0.2482876181602478\n",
      ". . . batch: 30, batch_loss: 0.28361210227012634\n",
      ". . . batch: 60, batch_loss: 0.2919342815876007\n",
      ". . . batch: 90, batch_loss: 0.20127049088478088\n",
      ". . . batch: 120, batch_loss: 0.20993828773498535\n",
      ". . . batch: 150, batch_loss: 0.1849827617406845\n",
      ". . . batch: 180, batch_loss: 0.3763607144355774\n",
      ". . . batch: 210, batch_loss: 0.17291630804538727\n",
      ". . . batch: 240, batch_loss: 0.23825214803218842\n",
      "EPOCH: 23, train_loss: 0.27447815258745795, val_loss: 0.784008976072073, val_score: 0.8122384937238494\n",
      "24 / 30\n",
      ". . . batch: 0, batch_loss: 0.30256888270378113\n",
      ". . . batch: 30, batch_loss: 0.4692096412181854\n",
      ". . . batch: 60, batch_loss: 0.19922423362731934\n",
      ". . . batch: 90, batch_loss: 0.25197023153305054\n",
      ". . . batch: 120, batch_loss: 0.19288696348667145\n",
      ". . . batch: 150, batch_loss: 0.30893072485923767\n",
      ". . . batch: 180, batch_loss: 0.2771102488040924\n",
      ". . . batch: 210, batch_loss: 0.31989336013793945\n",
      ". . . batch: 240, batch_loss: 0.24181804060935974\n",
      "EPOCH: 24, train_loss: 0.24165089919611268, val_loss: 0.8571990057826042, val_score: 0.7981171548117155\n",
      "25 / 30\n",
      ". . . batch: 0, batch_loss: 0.31613877415657043\n",
      ". . . batch: 30, batch_loss: 0.29384440183639526\n",
      ". . . batch: 60, batch_loss: 0.2211393415927887\n",
      ". . . batch: 90, batch_loss: 0.34555062651634216\n",
      ". . . batch: 120, batch_loss: 0.20194314420223236\n",
      ". . . batch: 150, batch_loss: 0.1572679877281189\n",
      ". . . batch: 180, batch_loss: 0.32840123772621155\n",
      ". . . batch: 210, batch_loss: 0.31578221917152405\n",
      ". . . batch: 240, batch_loss: 0.1665334403514862\n",
      "EPOCH: 25, train_loss: 0.2095899301822539, val_loss: 0.7604755016509444, val_score: 0.8122384937238494\n",
      "26 / 30\n",
      ". . . batch: 0, batch_loss: 0.258662611246109\n",
      ". . . batch: 30, batch_loss: 0.1989174485206604\n",
      ". . . batch: 60, batch_loss: 0.15030059218406677\n",
      ". . . batch: 90, batch_loss: 0.17036867141723633\n",
      ". . . batch: 120, batch_loss: 0.08010081946849823\n",
      ". . . batch: 150, batch_loss: 0.1675674468278885\n",
      ". . . batch: 180, batch_loss: 0.13314072787761688\n",
      ". . . batch: 210, batch_loss: 0.2427849918603897\n",
      ". . . batch: 240, batch_loss: 0.13965155184268951\n",
      "EPOCH: 26, train_loss: 0.19096743154029053, val_loss: 0.6864464667160064, val_score: 0.8221757322175731\n",
      ">>>>>>  EPOCH 26: validation score 0.8221757322175731\n",
      "27 / 30\n",
      ". . . batch: 0, batch_loss: 0.271203875541687\n",
      ". . . batch: 30, batch_loss: 0.06292696297168732\n",
      ". . . batch: 60, batch_loss: 0.18209005892276764\n",
      ". . . batch: 90, batch_loss: 0.09997456520795822\n",
      ". . . batch: 120, batch_loss: 0.11269302666187286\n",
      ". . . batch: 150, batch_loss: 0.11032215505838394\n",
      ". . . batch: 180, batch_loss: 0.1327844262123108\n",
      ". . . batch: 210, batch_loss: 0.44252368807792664\n",
      ". . . batch: 240, batch_loss: 0.17735542356967926\n",
      "EPOCH: 27, train_loss: 0.18017027511916767, val_loss: 0.984436979983002, val_score: 0.7887029288702929\n",
      "28 / 30\n",
      ". . . batch: 0, batch_loss: 0.10260649025440216\n",
      ". . . batch: 30, batch_loss: 0.20235823094844818\n",
      ". . . batch: 60, batch_loss: 0.17183415591716766\n",
      ". . . batch: 90, batch_loss: 0.3148883879184723\n",
      ". . . batch: 120, batch_loss: 0.20102576911449432\n",
      ". . . batch: 150, batch_loss: 0.16898486018180847\n",
      ". . . batch: 180, batch_loss: 0.20142963528633118\n",
      ". . . batch: 210, batch_loss: 0.0646757110953331\n",
      ". . . batch: 240, batch_loss: 0.12623868882656097\n",
      "EPOCH: 28, train_loss: 0.15745050356619883, val_loss: 1.0499652000144124, val_score: 0.7897489539748953\n",
      "29 / 30\n",
      ". . . batch: 0, batch_loss: 0.14766134321689606\n",
      ". . . batch: 30, batch_loss: 0.15899282693862915\n",
      ". . . batch: 60, batch_loss: 0.10998131334781647\n",
      ". . . batch: 90, batch_loss: 0.3563804030418396\n",
      ". . . batch: 120, batch_loss: 0.07226521521806717\n",
      ". . . batch: 150, batch_loss: 0.10107135772705078\n",
      ". . . batch: 180, batch_loss: 0.14155928790569305\n",
      ". . . batch: 210, batch_loss: 0.25485795736312866\n",
      ". . . batch: 240, batch_loss: 0.17100222408771515\n",
      "EPOCH: 29, train_loss: 0.14156998107554739, val_loss: 0.9126538443379104, val_score: 0.7996861924686193\n",
      "30 / 30\n",
      ". . . batch: 0, batch_loss: 0.09018827974796295\n",
      ". . . batch: 30, batch_loss: 0.13723261654376984\n",
      ". . . batch: 60, batch_loss: 0.09087594598531723\n",
      ". . . batch: 90, batch_loss: 0.08930520713329315\n",
      ". . . batch: 120, batch_loss: 0.25236305594444275\n",
      ". . . batch: 150, batch_loss: 0.1664503663778305\n",
      ". . . batch: 180, batch_loss: 0.19674226641654968\n",
      ". . . batch: 210, batch_loss: 0.16305536031723022\n",
      ". . . batch: 240, batch_loss: 0.06968136131763458\n",
      "EPOCH: 30, train_loss: 0.12788592592157702, val_loss: 0.6484136693179607, val_score: 0.8399581589958159\n",
      ">>>>>>  EPOCH 30: validation score 0.8399581589958159\n",
      "{'best_epoch': 30, 'best_score': 0.8399581589958159}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Batch size\n",
    "batch_size = 30\n",
    "\n",
    "# Image resize\n",
    "image_size = (299, 299)\n",
    "\n",
    "# Datapath\n",
    "TRAIN_DATA_PATH = '../data/train_crop/'\n",
    "TEST_DATA_PATH = '../data/test_crop/'\n",
    "\n",
    "# torch dataset\n",
    "class TrainImages(Dataset):\n",
    "    def __init__(self, images, labels, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TRAIN_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "class TestImages(Dataset):\n",
    "    def __init__(self, images, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TEST_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "import pretrainedmodels\n",
    "\n",
    "for fold in range(5):\n",
    "    model_name = 'inceptionresnetv2'\n",
    "    model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "    num_features = model.last_linear.in_features\n",
    "    model.last_linear = nn.Linear(num_features, 196)\n",
    "\n",
    "    \n",
    "    print(\"-\"*5, fold, \"fold\",\"-\"*5)\n",
    "    X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "    dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    PATH = './xception/fold{}'.format(fold)\n",
    "    results = train_model(model, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "    print(results)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD4 fine tunning \n",
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.12030280381441116\n",
      ". . . batch: 30, batch_loss: 0.15838436782360077\n",
      ". . . batch: 60, batch_loss: 0.15239566564559937\n",
      ". . . batch: 90, batch_loss: 0.08967011421918869\n",
      ". . . batch: 120, batch_loss: 0.0583653450012207\n",
      ". . . batch: 150, batch_loss: 0.14996983110904694\n",
      ". . . batch: 180, batch_loss: 0.07520421594381332\n",
      ". . . batch: 210, batch_loss: 0.06687876582145691\n",
      ". . . batch: 240, batch_loss: 0.11562085151672363\n",
      "EPOCH: 1, train_loss: 0.11140351042979281, val_loss: 0.8221133472397923, val_score: 0.8122384937238494\n",
      ">>>>>>  EPOCH 1: validation score 0.8122384937238494\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.15421149134635925\n",
      ". . . batch: 30, batch_loss: 0.06723102182149887\n",
      ". . . batch: 60, batch_loss: 0.06572552025318146\n",
      ". . . batch: 90, batch_loss: 0.18448972702026367\n",
      ". . . batch: 120, batch_loss: 0.13882866501808167\n",
      ". . . batch: 150, batch_loss: 0.05588060989975929\n",
      ". . . batch: 180, batch_loss: 0.1730726808309555\n",
      ". . . batch: 210, batch_loss: 0.05740521848201752\n",
      ". . . batch: 240, batch_loss: 0.11820634454488754\n",
      "EPOCH: 2, train_loss: 0.10106643961259618, val_loss: 0.6795768283773214, val_score: 0.8347280334728033\n",
      ">>>>>>  EPOCH 2: validation score 0.8347280334728033\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.07843456417322159\n",
      ". . . batch: 30, batch_loss: 0.11176614463329315\n",
      ". . . batch: 60, batch_loss: 0.16269828379154205\n",
      ". . . batch: 90, batch_loss: 0.1471247673034668\n",
      ". . . batch: 120, batch_loss: 0.06256211549043655\n",
      ". . . batch: 150, batch_loss: 0.06870686262845993\n",
      ". . . batch: 180, batch_loss: 0.04651835933327675\n",
      ". . . batch: 210, batch_loss: 0.11407925188541412\n",
      ". . . batch: 240, batch_loss: 0.06877409666776657\n",
      "EPOCH: 3, train_loss: 0.09926579938166685, val_loss: 0.8847680296748877, val_score: 0.803347280334728\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.04803008958697319\n",
      ". . . batch: 30, batch_loss: 0.14641278982162476\n",
      ". . . batch: 60, batch_loss: 0.11702381819486618\n",
      ". . . batch: 90, batch_loss: 0.053363196551799774\n",
      ". . . batch: 120, batch_loss: 0.09283291548490524\n",
      ". . . batch: 150, batch_loss: 0.0602879524230957\n",
      ". . . batch: 180, batch_loss: 0.14191456139087677\n",
      ". . . batch: 210, batch_loss: 0.06393690407276154\n",
      ". . . batch: 240, batch_loss: 0.06930462270975113\n",
      "EPOCH: 4, train_loss: 0.09207490710196674, val_loss: 0.729226176859811, val_score: 0.8274058577405857\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.09902200847864151\n",
      ". . . batch: 30, batch_loss: 0.1372746080160141\n",
      ". . . batch: 60, batch_loss: 0.06681060791015625\n",
      ". . . batch: 90, batch_loss: 0.11291646957397461\n",
      ". . . batch: 120, batch_loss: 0.08770249783992767\n",
      ". . . batch: 150, batch_loss: 0.15324611961841583\n",
      ". . . batch: 180, batch_loss: 0.10264883190393448\n",
      ". . . batch: 210, batch_loss: 0.06497001647949219\n",
      ". . . batch: 240, batch_loss: 0.05541146546602249\n",
      "EPOCH: 5, train_loss: 0.09576266810849865, val_loss: 0.7409809699747711, val_score: 0.8289748953974896\n",
      "{'best_epoch': 2, 'best_score': 0.8347280334728033}\n"
     ]
    }
   ],
   "source": [
    "model_name = 'inceptionresnetv2'\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')\n",
    "num_features = model.last_linear.in_features\n",
    "model.last_linear = nn.Linear(num_features, 196)\n",
    "model.load_state_dict(torch.load('./xception/fold4/best_model_epoch_30_score_0.8399581589958159.pt'))\n",
    "\n",
    "fold = 4\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "PATH = './xception/fold{}/'.format(fold)\n",
    "results = train_model(model, dataloaders, 0.0001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
