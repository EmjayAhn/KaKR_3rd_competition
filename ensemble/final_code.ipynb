{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# fix seeds\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 2019\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.enabled = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFOLD\n",
    "- 5 folds for ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/preser9191/.local/lib/python3.6/site-packages/pandas/core/indexing.py:190: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_train.replace(196, 0, inplace=True)\n",
    "df_train['fold'] = 999\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=SEED, shuffle=False)\n",
    "for index, (_, val_index) in enumerate(skf.split(df_train['img_file'], df_train['class'])):\n",
    "    df_train['fold'].iloc[val_index] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_fold_dataset(df_train, fold):\n",
    "    X_train = df_train[df_train['fold']!=fold]['img_file']\n",
    "    X_val = df_train[df_train['fold']==fold]['img_file']\n",
    "    y_train = df_train[df_train['fold']!=fold]['class']\n",
    "    y_val = df_train[df_train['fold']==fold]['class']\n",
    "    \n",
    "    return X_train.values, X_val.values, y_train.values, y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n",
      "(7914,)\n",
      "(7914,)\n",
      "(2076,)\n",
      "(2076,)\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, 0)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_val.shape)\n",
    "    print(y_val.shape)\n",
    "    print(\"-\"*8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Image resize\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Datapath\n",
    "TRAIN_DATA_PATH = '../data/train_crop/'\n",
    "TEST_DATA_PATH = '../data/test_crop/'\n",
    "\n",
    "# torch dataset\n",
    "class TrainImages(Dataset):\n",
    "    def __init__(self, images, labels, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TRAIN_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "class TestImages(Dataset):\n",
    "    def __init__(self, images, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TEST_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    \n",
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(image_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406],\n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataloader(X_train, X_val, y_train, y_val):\n",
    "    train_dataset = TrainImages(images=X_train, labels=y_train, mode='train', transforms=transform)\n",
    "    val_dataset = TrainImages(images=X_val, labels=y_val, mode='val', transforms=transform)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    dataloaders = {\n",
    "        'train': train_dataloader,\n",
    "        'val': val_dataloader\n",
    "    }\n",
    "\n",
    "    dataset_sizes = {\n",
    "        'train': len(train_dataset),\n",
    "        'val': len(val_dataset)\n",
    "    }\n",
    "    return dataloaders, dataset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for batch_index, (batch_image, batch_target) in enumerate(dataloader):\n",
    "        batch_image, batch_target = batch_image.to(device), batch_target.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        optimizer.zero_grad()\n",
    "        batch_output = model(batch_image)\n",
    "        loss = criterion(batch_output, batch_target)\n",
    "        \n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() / len(dataloader)\n",
    "        if batch_index % (len(dataloader)//3) == 0:\n",
    "            print(\". . . batch: {}, batch_loss: {}\".format(batch_index, loss.item()))\n",
    "    return train_loss\n",
    "\n",
    "def validate(model, dataloader, criterion, dataset_sizes):\n",
    "    model.eval()\n",
    "    \n",
    "    val_preds = np.zeros((dataset_sizes['val'], 1))\n",
    "    val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_index, (batch_image, batch_target) in enumerate(dataloader):\n",
    "            batch_image, batch_target = batch_image.to(device), batch_target.to(device)\n",
    "            \n",
    "            batch_output = model(batch_image).detach()\n",
    "            _, batch_preds = torch.max(batch_output, 1)\n",
    "            \n",
    "            loss = criterion(batch_output, batch_target)\n",
    "            val_loss += loss.item() / len(dataloader)\n",
    "            \n",
    "            val_preds[batch_index * batch_size: (batch_index+1) * batch_size] = batch_preds.cpu().view(-1, 1).numpy()\n",
    "\n",
    "        val_score = f1_score(y_val, val_preds, average='micro')\n",
    "        \n",
    "    return val_loss, val_score\n",
    "\n",
    "def train_model(model, dataloaders, lr, dataset_sizes, num_epochs, PATH):\n",
    "    \n",
    "    best_score = 0.0\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    results = {\n",
    "        'best_epoch': 0,\n",
    "        'best_score': 0,\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"{} / {}\".format(epoch+1, num_epochs))\n",
    "        train_loss = train(model, dataloaders['train'], criterion, optimizer)\n",
    "        val_loss, val_score = validate(model, dataloaders['val'], criterion, dataset_sizes)\n",
    "        \n",
    "        print(\"EPOCH: {}, train_loss: {}, val_loss: {}, val_score: {}\".format(epoch+1, train_loss, val_loss, val_score))\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            torch.save(model.state_dict(), './{}/best_model_epoch_{}_score_{}.pt'.format(PATH, epoch+1, val_score))\n",
    "            results['best_epoch'] = epoch+1\n",
    "            results['best_score'] = best_score\n",
    "            print(\">>>>>>  EPOCH {}: validation score {}\".format(epoch+1, val_score))\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 5.383825302124023\n",
      ". . . batch: 41, batch_loss: 5.299849033355713\n",
      ". . . batch: 82, batch_loss: 5.233278751373291\n",
      ". . . batch: 123, batch_loss: 5.312289714813232\n",
      "EPOCH: 1, train_loss: 5.291198522813858, val_loss: 5.228442495519465, val_score: 0.01878612716763006\n",
      ">>>>>>  EPOCH 1: validation score 0.01878612716763006\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 5.282308101654053\n",
      ". . . batch: 41, batch_loss: 5.1560540199279785\n",
      ". . . batch: 82, batch_loss: 5.07704496383667\n",
      ". . . batch: 123, batch_loss: 5.177755355834961\n",
      "EPOCH: 2, train_loss: 5.137968890128598, val_loss: 5.100189252333208, val_score: 0.0197495183044316\n",
      ">>>>>>  EPOCH 2: validation score 0.0197495183044316\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 5.020870685577393\n",
      ". . . batch: 41, batch_loss: 4.926645755767822\n",
      ". . . batch: 82, batch_loss: 5.113419532775879\n",
      ". . . batch: 123, batch_loss: 4.968969345092773\n",
      "EPOCH: 3, train_loss: 5.035809605352338, val_loss: 5.145202521121862, val_score: 0.016377649325626204\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 4.953311920166016\n",
      ". . . batch: 41, batch_loss: 4.784001350402832\n",
      ". . . batch: 82, batch_loss: 4.673601150512695\n",
      ". . . batch: 123, batch_loss: 4.725433349609375\n",
      "EPOCH: 4, train_loss: 4.838701348150931, val_loss: 4.840043067932128, val_score: 0.03564547206165703\n",
      ">>>>>>  EPOCH 4: validation score 0.03564547206165703\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 4.690493106842041\n",
      ". . . batch: 41, batch_loss: 4.528688430786133\n",
      ". . . batch: 82, batch_loss: 4.520097255706787\n",
      ". . . batch: 123, batch_loss: 4.463616847991943\n",
      "EPOCH: 5, train_loss: 4.529774565850534, val_loss: 4.905718471064712, val_score: 0.03901734104046243\n",
      ">>>>>>  EPOCH 5: validation score 0.03901734104046243\n",
      "{'best_epoch': 5, 'best_score': 0.03901734104046243}\n"
     ]
    }
   ],
   "source": [
    "# 0번째 fold\n",
    "fold = 0\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 4.246837615966797\n",
      ". . . batch: 41, batch_loss: 4.343574523925781\n",
      ". . . batch: 82, batch_loss: 4.252584934234619\n",
      ". . . batch: 123, batch_loss: 4.106612205505371\n",
      "EPOCH: 1, train_loss: 4.250045176475279, val_loss: 4.246904828331687, val_score: 0.07996146435452794\n",
      ">>>>>>  EPOCH 1: validation score 0.07996146435452794\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 4.149881839752197\n",
      ". . . batch: 41, batch_loss: 3.9386115074157715\n",
      ". . . batch: 82, batch_loss: 3.77221417427063\n",
      ". . . batch: 123, batch_loss: 3.844247341156006\n",
      "EPOCH: 2, train_loss: 3.908779055841508, val_loss: 3.8655671784372045, val_score: 0.10886319845857419\n",
      ">>>>>>  EPOCH 2: validation score 0.10886319845857419\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 3.5502612590789795\n",
      ". . . batch: 41, batch_loss: 3.8402698040008545\n",
      ". . . batch: 82, batch_loss: 3.587817668914795\n",
      ". . . batch: 123, batch_loss: 3.235092878341675\n",
      "EPOCH: 3, train_loss: 3.611608159157541, val_loss: 3.884415417006521, val_score: 0.12379576107899808\n",
      ">>>>>>  EPOCH 3: validation score 0.12379576107899808\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 3.0473897457122803\n",
      ". . . batch: 41, batch_loss: 3.2178311347961426\n",
      ". . . batch: 82, batch_loss: 3.3181562423706055\n",
      ". . . batch: 123, batch_loss: 3.1219820976257324\n",
      "EPOCH: 4, train_loss: 3.248041241399703, val_loss: 3.416328285679673, val_score: 0.19219653179190754\n",
      ">>>>>>  EPOCH 4: validation score 0.19219653179190754\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 2.8582446575164795\n",
      ". . . batch: 41, batch_loss: 2.830639600753784\n",
      ". . . batch: 82, batch_loss: 2.931617259979248\n",
      ". . . batch: 123, batch_loss: 2.903578519821167\n",
      "EPOCH: 5, train_loss: 2.8939737350709978, val_loss: 3.3143193577275136, val_score: 0.19653179190751446\n",
      ">>>>>>  EPOCH 5: validation score 0.19653179190751446\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 2.460219621658325\n",
      ". . . batch: 41, batch_loss: 2.413177728652954\n",
      ". . . batch: 82, batch_loss: 2.7885491847991943\n",
      ". . . batch: 123, batch_loss: 2.430300235748291\n",
      "EPOCH: 6, train_loss: 2.5141041721067117, val_loss: 2.611470865480828, val_score: 0.342485549132948\n",
      ">>>>>>  EPOCH 6: validation score 0.342485549132948\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 2.136598825454712\n",
      ". . . batch: 41, batch_loss: 2.2568233013153076\n",
      ". . . batch: 82, batch_loss: 1.74003005027771\n",
      ". . . batch: 123, batch_loss: 2.08760142326355\n",
      "EPOCH: 7, train_loss: 2.1314251749746256, val_loss: 2.647846041303692, val_score: 0.33236994219653176\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 1.812044382095337\n",
      ". . . batch: 41, batch_loss: 1.8911529779434204\n",
      ". . . batch: 82, batch_loss: 2.0538134574890137\n",
      ". . . batch: 123, batch_loss: 1.5412712097167969\n",
      "EPOCH: 8, train_loss: 1.8107605288105637, val_loss: 2.368409077326457, val_score: 0.3752408477842004\n",
      ">>>>>>  EPOCH 8: validation score 0.3752408477842004\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 1.5071673393249512\n",
      ". . . batch: 41, batch_loss: 1.5958070755004883\n",
      ". . . batch: 82, batch_loss: 1.219062328338623\n",
      ". . . batch: 123, batch_loss: 1.6381218433380127\n",
      "EPOCH: 9, train_loss: 1.5479134369281025, val_loss: 1.9295076565309002, val_score: 0.47832369942196534\n",
      ">>>>>>  EPOCH 9: validation score 0.47832369942196534\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 1.5183156728744507\n",
      ". . . batch: 41, batch_loss: 1.4012386798858643\n",
      ". . . batch: 82, batch_loss: 1.262334942817688\n",
      ". . . batch: 123, batch_loss: 1.5234886407852173\n",
      "EPOCH: 10, train_loss: 1.30449401611282, val_loss: 2.188221682201732, val_score: 0.4508670520231214\n",
      "{'best_epoch': 9, 'best_score': 0.47832369942196534}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_5_score_0.03901734104046243.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 1.6552002429962158\n",
      ". . . batch: 41, batch_loss: 1.444204330444336\n",
      ". . . batch: 82, batch_loss: 0.9600077867507935\n",
      ". . . batch: 123, batch_loss: 1.1740903854370117\n",
      "EPOCH: 1, train_loss: 1.3083350216188747, val_loss: 1.9234032558672352, val_score: 0.5048169556840078\n",
      ">>>>>>  EPOCH 1: validation score 0.5048169556840078\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 1.0093985795974731\n",
      ". . . batch: 41, batch_loss: 0.9463107585906982\n",
      ". . . batch: 82, batch_loss: 1.211683988571167\n",
      ". . . batch: 123, batch_loss: 1.2292311191558838\n",
      "EPOCH: 2, train_loss: 1.0798399501269869, val_loss: 1.9095017332019228, val_score: 0.49614643545279385\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 1.0029034614562988\n",
      ". . . batch: 41, batch_loss: 1.1067020893096924\n",
      ". . . batch: 82, batch_loss: 0.8739738464355469\n",
      ". . . batch: 123, batch_loss: 1.1196417808532715\n",
      "EPOCH: 3, train_loss: 0.9829437910549103, val_loss: 1.5341745994307776, val_score: 0.5814065510597303\n",
      ">>>>>>  EPOCH 3: validation score 0.5814065510597303\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 1.157421588897705\n",
      ". . . batch: 41, batch_loss: 0.8023973703384399\n",
      ". . . batch: 82, batch_loss: 0.943950891494751\n",
      ". . . batch: 123, batch_loss: 1.2912423610687256\n",
      "EPOCH: 4, train_loss: 0.842440106455357, val_loss: 1.6118978659311933, val_score: 0.5915221579961464\n",
      ">>>>>>  EPOCH 4: validation score 0.5915221579961464\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 0.6595814824104309\n",
      ". . . batch: 41, batch_loss: 0.847517728805542\n",
      ". . . batch: 82, batch_loss: 0.7691802382469177\n",
      ". . . batch: 123, batch_loss: 0.658896803855896\n",
      "EPOCH: 5, train_loss: 0.753384583179028, val_loss: 1.554417570432027, val_score: 0.5973025048169557\n",
      ">>>>>>  EPOCH 5: validation score 0.5973025048169557\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 0.6718743443489075\n",
      ". . . batch: 41, batch_loss: 0.6136841773986816\n",
      ". . . batch: 82, batch_loss: 0.7794466018676758\n",
      ". . . batch: 123, batch_loss: 0.8669793009757996\n",
      "EPOCH: 6, train_loss: 0.6626722574714693, val_loss: 1.7090022925174595, val_score: 0.5751445086705202\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 0.43103456497192383\n",
      ". . . batch: 41, batch_loss: 0.511823832988739\n",
      ". . . batch: 82, batch_loss: 0.5790030360221863\n",
      ". . . batch: 123, batch_loss: 0.5938624143600464\n",
      "EPOCH: 7, train_loss: 0.6242400037665521, val_loss: 1.4402682672847402, val_score: 0.6127167630057804\n",
      ">>>>>>  EPOCH 7: validation score 0.6127167630057804\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 0.4517046809196472\n",
      ". . . batch: 41, batch_loss: 0.38463863730430603\n",
      ". . . batch: 82, batch_loss: 0.7506340146064758\n",
      ". . . batch: 123, batch_loss: 0.509239673614502\n",
      "EPOCH: 8, train_loss: 0.5280559091798719, val_loss: 1.5129623015721636, val_score: 0.6180154142581888\n",
      ">>>>>>  EPOCH 8: validation score 0.6180154142581888\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 0.48947593569755554\n",
      ". . . batch: 41, batch_loss: 0.5386035442352295\n",
      ". . . batch: 82, batch_loss: 0.4448235034942627\n",
      ". . . batch: 123, batch_loss: 0.4290955066680908\n",
      "EPOCH: 9, train_loss: 0.4577255550651781, val_loss: 1.4537493442044116, val_score: 0.6271676300578035\n",
      ">>>>>>  EPOCH 9: validation score 0.6271676300578035\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 0.46351537108421326\n",
      ". . . batch: 41, batch_loss: 0.753371000289917\n",
      ". . . batch: 82, batch_loss: 0.39037010073661804\n",
      ". . . batch: 123, batch_loss: 0.45858052372932434\n",
      "EPOCH: 10, train_loss: 0.4317118268339864, val_loss: 1.6258621504812527, val_score: 0.5934489402697495\n",
      "{'best_epoch': 9, 'best_score': 0.6271676300578035}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_9_score_0.47832369942196534.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.37338078022003174\n",
      ". . . batch: 41, batch_loss: 0.32476985454559326\n",
      ". . . batch: 82, batch_loss: 0.3499756455421448\n",
      ". . . batch: 123, batch_loss: 0.41411399841308594\n",
      "EPOCH: 1, train_loss: 0.5039797786983754, val_loss: 1.8053203134825735, val_score: 0.5948940269749519\n",
      ">>>>>>  EPOCH 1: validation score 0.5948940269749519\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.37293627858161926\n",
      ". . . batch: 41, batch_loss: 0.32039737701416016\n",
      ". . . batch: 82, batch_loss: 0.37813687324523926\n",
      ". . . batch: 123, batch_loss: 0.3415590524673462\n",
      "EPOCH: 2, train_loss: 0.4132883915257068, val_loss: 1.3744796911875405, val_score: 0.6551059730250481\n",
      ">>>>>>  EPOCH 2: validation score 0.6551059730250481\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.37042543292045593\n",
      ". . . batch: 41, batch_loss: 0.30435675382614136\n",
      ". . . batch: 82, batch_loss: 0.445711225271225\n",
      ". . . batch: 123, batch_loss: 0.5060069561004639\n",
      "EPOCH: 3, train_loss: 0.37092277083185426, val_loss: 1.4581100145975752, val_score: 0.6488439306358381\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.2237655371427536\n",
      ". . . batch: 41, batch_loss: 0.2576567530632019\n",
      ". . . batch: 82, batch_loss: 0.2429797351360321\n",
      ". . . batch: 123, batch_loss: 0.4393986761569977\n",
      "EPOCH: 4, train_loss: 0.33006408125642817, val_loss: 1.497027724078207, val_score: 0.6421001926782274\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.3941466510295868\n",
      ". . . batch: 41, batch_loss: 0.2602291405200958\n",
      ". . . batch: 82, batch_loss: 0.3448876738548279\n",
      ". . . batch: 123, batch_loss: 0.26735052466392517\n",
      "EPOCH: 5, train_loss: 0.2981158329714691, val_loss: 1.3118934197859324, val_score: 0.6685934489402697\n",
      ">>>>>>  EPOCH 5: validation score 0.6685934489402697\n",
      "{'best_epoch': 5, 'best_score': 0.6685934489402697}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_9_score_0.6271676300578035.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr changed to 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.26603302359580994\n",
      ". . . batch: 41, batch_loss: 0.11748883128166199\n",
      ". . . batch: 82, batch_loss: 0.10489501804113388\n",
      ". . . batch: 123, batch_loss: 0.20275545120239258\n",
      "EPOCH: 1, train_loss: 0.14286818845017302, val_loss: 0.8847493773156948, val_score: 0.779383429672447\n",
      ">>>>>>  EPOCH 1: validation score 0.779383429672447\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.13722552359104156\n",
      ". . . batch: 41, batch_loss: 0.07206806540489197\n",
      ". . . batch: 82, batch_loss: 0.15307839214801788\n",
      ". . . batch: 123, batch_loss: 0.09004052728414536\n",
      "EPOCH: 2, train_loss: 0.08164021179019924, val_loss: 0.8492354479703037, val_score: 0.785645472061657\n",
      ">>>>>>  EPOCH 2: validation score 0.785645472061657\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.038217902183532715\n",
      ". . . batch: 41, batch_loss: 0.09447608143091202\n",
      ". . . batch: 82, batch_loss: 0.08864694088697433\n",
      ". . . batch: 123, batch_loss: 0.1042739674448967\n",
      "EPOCH: 3, train_loss: 0.06729429539653563, val_loss: 0.927479602170713, val_score: 0.7827552986512524\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.04233287274837494\n",
      ". . . batch: 41, batch_loss: 0.0703224316239357\n",
      ". . . batch: 82, batch_loss: 0.0892648994922638\n",
      ". . . batch: 123, batch_loss: 0.07265786826610565\n",
      "EPOCH: 4, train_loss: 0.06202249793756392, val_loss: 1.1000714658787756, val_score: 0.7760115606936416\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.04759419709444046\n",
      ". . . batch: 41, batch_loss: 0.030626654624938965\n",
      ". . . batch: 82, batch_loss: 0.05312336981296539\n",
      ". . . batch: 123, batch_loss: 0.11420699208974838\n",
      "EPOCH: 5, train_loss: 0.05296175449245399, val_loss: 0.9563788252346442, val_score: 0.7813102119460502\n",
      "{'best_epoch': 2, 'best_score': 0.785645472061657}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_5_score_0.6685934489402697.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.0001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3\n",
      ". . . batch: 0, batch_loss: 0.10267733782529831\n",
      ". . . batch: 41, batch_loss: 0.051810793578624725\n",
      ". . . batch: 82, batch_loss: 0.06250932812690735\n",
      ". . . batch: 123, batch_loss: 0.11724892258644104\n",
      "EPOCH: 1, train_loss: 0.07666434596983658, val_loss: 0.8477138425364639, val_score: 0.7870905587668593\n",
      ">>>>>>  EPOCH 1: validation score 0.7870905587668593\n",
      "2 / 3\n",
      ". . . batch: 0, batch_loss: 0.10274454951286316\n",
      ". . . batch: 41, batch_loss: 0.05277039855718613\n",
      ". . . batch: 82, batch_loss: 0.06517122685909271\n",
      ". . . batch: 123, batch_loss: 0.12235032021999359\n",
      "EPOCH: 2, train_loss: 0.06382877607980082, val_loss: 0.9512522459933253, val_score: 0.7764932562620422\n",
      "3 / 3\n",
      ". . . batch: 0, batch_loss: 0.08058720827102661\n",
      ". . . batch: 41, batch_loss: 0.06236293166875839\n",
      ". . . batch: 82, batch_loss: 0.05246765911579132\n",
      ". . . batch: 123, batch_loss: 0.04324960708618164\n",
      "EPOCH: 3, train_loss: 0.05411495618341911, val_loss: 0.8722764127182238, val_score: 0.785645472061657\n",
      "{'best_epoch': 1, 'best_score': 0.7870905587668593}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_2_score_0.785645472061657.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.0001, dataset_sizes, 3, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr changed to 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 0.04467710852622986\n",
      ". . . batch: 41, batch_loss: 0.027035189792513847\n",
      ". . . batch: 82, batch_loss: 0.11692338436841965\n",
      ". . . batch: 123, batch_loss: 0.028341684490442276\n",
      "EPOCH: 1, train_loss: 0.05913375088224002, val_loss: 0.8829545604460166, val_score: 0.7914258188824663\n",
      ">>>>>>  EPOCH 1: validation score 0.7914258188824663\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 0.05197174474596977\n",
      ". . . batch: 41, batch_loss: 0.06104442477226257\n",
      ". . . batch: 82, batch_loss: 0.03625480830669403\n",
      ". . . batch: 123, batch_loss: 0.0462426133453846\n",
      "EPOCH: 2, train_loss: 0.05352216397201823, val_loss: 0.8743639619964542, val_score: 0.785645472061657\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 0.037354402244091034\n",
      ". . . batch: 41, batch_loss: 0.051488082855939865\n",
      ". . . batch: 82, batch_loss: 0.04191826656460762\n",
      ". . . batch: 123, batch_loss: 0.01837806962430477\n",
      "EPOCH: 3, train_loss: 0.053001852105221445, val_loss: 0.87860474848386, val_score: 0.791907514450867\n",
      ">>>>>>  EPOCH 3: validation score 0.791907514450867\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 0.0345434732735157\n",
      ". . . batch: 41, batch_loss: 0.057416513562202454\n",
      ". . . batch: 82, batch_loss: 0.08384521305561066\n",
      ". . . batch: 123, batch_loss: 0.020036909729242325\n",
      "EPOCH: 4, train_loss: 0.05243130541977383, val_loss: 0.8772105633309393, val_score: 0.7875722543352601\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 0.04210113361477852\n",
      ". . . batch: 41, batch_loss: 0.12569484114646912\n",
      ". . . batch: 82, batch_loss: 0.017913274466991425\n",
      ". . . batch: 123, batch_loss: 0.048036880791187286\n",
      "EPOCH: 5, train_loss: 0.05086861309715577, val_loss: 0.8812867570104022, val_score: 0.789980732177264\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 0.049345895648002625\n",
      ". . . batch: 41, batch_loss: 0.06963817030191422\n",
      ". . . batch: 82, batch_loss: 0.032964304089546204\n",
      ". . . batch: 123, batch_loss: 0.047105852514505386\n",
      "EPOCH: 6, train_loss: 0.048034182284027345, val_loss: 0.8900954655625606, val_score: 0.7904624277456648\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 0.03807713836431503\n",
      ". . . batch: 41, batch_loss: 0.062261104583740234\n",
      ". . . batch: 82, batch_loss: 0.0696101114153862\n",
      ". . . batch: 123, batch_loss: 0.03835670277476311\n",
      "EPOCH: 7, train_loss: 0.04650859612851375, val_loss: 0.8753344263091232, val_score: 0.7909441233140655\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 0.022748028859496117\n",
      ". . . batch: 41, batch_loss: 0.01956932060420513\n",
      ". . . batch: 82, batch_loss: 0.10802997648715973\n",
      ". . . batch: 123, batch_loss: 0.15286335349082947\n",
      "EPOCH: 8, train_loss: 0.04637923642181822, val_loss: 0.8950835728284087, val_score: 0.789980732177264\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 0.043077677488327026\n",
      ". . . batch: 41, batch_loss: 0.03525177761912346\n",
      ". . . batch: 82, batch_loss: 0.06529812514781952\n",
      ". . . batch: 123, batch_loss: 0.040857572108507156\n",
      "EPOCH: 9, train_loss: 0.045736794585301985, val_loss: 0.9287911414196998, val_score: 0.7880539499036608\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 0.04600878059864044\n",
      ". . . batch: 41, batch_loss: 0.07668454200029373\n",
      ". . . batch: 82, batch_loss: 0.03854244202375412\n",
      ". . . batch: 123, batch_loss: 0.04099080711603165\n",
      "EPOCH: 10, train_loss: 0.04531997663059061, val_loss: 0.8709051943186558, val_score: 0.7909441233140655\n",
      "{'best_epoch': 3, 'best_score': 0.791907514450867}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_1_score_0.7870905587668593.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.00001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      ". . . batch: 0, batch_loss: 0.11710284650325775\n",
      ". . . batch: 41, batch_loss: 0.03234390914440155\n",
      ". . . batch: 82, batch_loss: 0.08893438428640366\n",
      ". . . batch: 123, batch_loss: 0.04258214682340622\n",
      "EPOCH: 1, train_loss: 0.050638629769485806, val_loss: 0.9253194088285621, val_score: 0.7870905587668593\n",
      ">>>>>>  EPOCH 1: validation score 0.7870905587668593\n",
      "2 / 10\n",
      ". . . batch: 0, batch_loss: 0.06959838420152664\n",
      ". . . batch: 41, batch_loss: 0.0741816982626915\n",
      ". . . batch: 82, batch_loss: 0.0527956485748291\n",
      ". . . batch: 123, batch_loss: 0.08831766992807388\n",
      "EPOCH: 2, train_loss: 0.051807586749595014, val_loss: 0.9722666853305066, val_score: 0.7842003853564548\n",
      "3 / 10\n",
      ". . . batch: 0, batch_loss: 0.04893384873867035\n",
      ". . . batch: 41, batch_loss: 0.05226784199476242\n",
      ". . . batch: 82, batch_loss: 0.04128000885248184\n",
      ". . . batch: 123, batch_loss: 0.0834939256310463\n",
      "EPOCH: 3, train_loss: 0.05059158180149332, val_loss: 0.9425019495414965, val_score: 0.789980732177264\n",
      ">>>>>>  EPOCH 3: validation score 0.789980732177264\n",
      "4 / 10\n",
      ". . . batch: 0, batch_loss: 0.023958228528499603\n",
      ". . . batch: 41, batch_loss: 0.04184021055698395\n",
      ". . . batch: 82, batch_loss: 0.05338679626584053\n",
      ". . . batch: 123, batch_loss: 0.10429608076810837\n",
      "EPOCH: 4, train_loss: 0.04922089700196538, val_loss: 0.8570327998110742, val_score: 0.7904624277456648\n",
      ">>>>>>  EPOCH 4: validation score 0.7904624277456648\n",
      "5 / 10\n",
      ". . . batch: 0, batch_loss: 0.02719520963728428\n",
      ". . . batch: 41, batch_loss: 0.046402037143707275\n",
      ". . . batch: 82, batch_loss: 0.03236202523112297\n",
      ". . . batch: 123, batch_loss: 0.09552756696939468\n",
      "EPOCH: 5, train_loss: 0.05372763560303759, val_loss: 0.8653778876319075, val_score: 0.7885356454720617\n",
      "6 / 10\n",
      ". . . batch: 0, batch_loss: 0.03824109584093094\n",
      ". . . batch: 41, batch_loss: 0.0325571671128273\n",
      ". . . batch: 82, batch_loss: 0.0508679524064064\n",
      ". . . batch: 123, batch_loss: 0.03279593959450722\n",
      "EPOCH: 6, train_loss: 0.04669392409343871, val_loss: 0.870419733000524, val_score: 0.789980732177264\n",
      "7 / 10\n",
      ". . . batch: 0, batch_loss: 0.08185221254825592\n",
      ". . . batch: 41, batch_loss: 0.03459974005818367\n",
      ". . . batch: 82, batch_loss: 0.05380600690841675\n",
      ". . . batch: 123, batch_loss: 0.0392308309674263\n",
      "EPOCH: 7, train_loss: 0.04936917357507253, val_loss: 0.8563286102179327, val_score: 0.7875722543352601\n",
      "8 / 10\n",
      ". . . batch: 0, batch_loss: 0.032137881964445114\n",
      ". . . batch: 41, batch_loss: 0.0873379036784172\n",
      ". . . batch: 82, batch_loss: 0.09402362257242203\n",
      ". . . batch: 123, batch_loss: 0.07748664170503616\n",
      "EPOCH: 8, train_loss: 0.0517860690522338, val_loss: 0.9652134834816963, val_score: 0.7851637764932563\n",
      "9 / 10\n",
      ". . . batch: 0, batch_loss: 0.03428276255726814\n",
      ". . . batch: 41, batch_loss: 0.047557130455970764\n",
      ". . . batch: 82, batch_loss: 0.04348762705922127\n",
      ". . . batch: 123, batch_loss: 0.0744650587439537\n",
      "EPOCH: 9, train_loss: 0.04958169109698747, val_loss: 0.8451551655025195, val_score: 0.7880539499036608\n",
      "10 / 10\n",
      ". . . batch: 0, batch_loss: 0.10569979250431061\n",
      ". . . batch: 41, batch_loss: 0.0633280798792839\n",
      ". . . batch: 82, batch_loss: 0.04008481651544571\n",
      ". . . batch: 123, batch_loss: 0.1458704173564911\n",
      "EPOCH: 10, train_loss: 0.049793511891977914, val_loss: 0.870501151139086, val_score: 0.7890173410404624\n",
      "{'best_epoch': 4, 'best_score': 0.7904624277456648}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_3_score_0.791907514450867.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.000001, dataset_sizes, 10, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lr change to 0.0000001\n",
    "- with EPOCH: 3, train_loss: 0.053001852105221445, val_loss: 0.87860474848386, val_score: 0.791907514450867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 5\n",
      ". . . batch: 0, batch_loss: 0.05719216167926788\n",
      ". . . batch: 41, batch_loss: 0.04256844520568848\n",
      ". . . batch: 82, batch_loss: 0.05564809590578079\n",
      ". . . batch: 123, batch_loss: 0.03641868755221367\n",
      "EPOCH: 1, train_loss: 0.05317618748954228, val_loss: 0.8727182687231991, val_score: 0.7943159922928708\n",
      ">>>>>>  EPOCH 1: validation score 0.7943159922928708\n",
      "2 / 5\n",
      ". . . batch: 0, batch_loss: 0.058001965284347534\n",
      ". . . batch: 41, batch_loss: 0.0617021769285202\n",
      ". . . batch: 82, batch_loss: 0.02316904254257679\n",
      ". . . batch: 123, batch_loss: 0.06976498663425446\n",
      "EPOCH: 2, train_loss: 0.049729162211259496, val_loss: 0.8796036704020066, val_score: 0.7890173410404624\n",
      "3 / 5\n",
      ". . . batch: 0, batch_loss: 0.04677455499768257\n",
      ". . . batch: 41, batch_loss: 0.060270022600889206\n",
      ". . . batch: 82, batch_loss: 0.01879439502954483\n",
      ". . . batch: 123, batch_loss: 0.027426855638623238\n",
      "EPOCH: 3, train_loss: 0.05180054671701884, val_loss: 0.8766368586908686, val_score: 0.7904624277456648\n",
      "4 / 5\n",
      ". . . batch: 0, batch_loss: 0.07763092964887619\n",
      ". . . batch: 41, batch_loss: 0.021512489765882492\n",
      ". . . batch: 82, batch_loss: 0.05150999873876572\n",
      ". . . batch: 123, batch_loss: 0.0375295914709568\n",
      "EPOCH: 4, train_loss: 0.05035420175972247, val_loss: 0.8618030859665436, val_score: 0.7914258188824663\n",
      "5 / 5\n",
      ". . . batch: 0, batch_loss: 0.04613475874066353\n",
      ". . . batch: 41, batch_loss: 0.030328379943966866\n",
      ". . . batch: 82, batch_loss: 0.0568937323987484\n",
      ". . . batch: 123, batch_loss: 0.02057383395731449\n",
      "EPOCH: 5, train_loss: 0.051052083351439036, val_loss: 0.8554841925700505, val_score: 0.791907514450867\n",
      "{'best_epoch': 1, 'best_score': 0.7943159922928708}\n"
     ]
    }
   ],
   "source": [
    "fold = 0\n",
    "\n",
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold0/rough/best_model_epoch_3_score_0.791907514450867.pt'))\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.0000001, dataset_sizes, 5, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 17\n",
      ". . . batch: 0, batch_loss: 2.213510751724243\n",
      ". . . batch: 41, batch_loss: 2.493255853652954\n",
      ". . . batch: 82, batch_loss: 2.096853017807007\n"
     ]
    }
   ],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./fold1/rough/best_model_epoch_9_score_0.2787046123650638.pt'))\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 1\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 17, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 2\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 3\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FOLD4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet101(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "\n",
    "# 0번째 fold\n",
    "fold = 4\n",
    "\n",
    "X_train, X_val, y_train, y_val = prepare_fold_dataset(df_train, fold)\n",
    "dataloaders, dataset_sizes = prepare_dataloader(X_train, X_val, y_train, y_val)\n",
    "\n",
    "model_res.to(device)\n",
    "\n",
    "PATH = 'fold{}/'.format(fold) + 'rough'\n",
    "results = train_model(model_res, dataloaders, 0.001, dataset_sizes, 30, PATH)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
