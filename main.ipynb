{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "# fix seeds\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "SEED = 2019\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.enabled = False\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "- 196종의 차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AM General Hummer SUV 2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Acura RL Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Acura TL Sedan 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Acura TL Type-S 2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Acura TSX Sedan 2012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                        name\n",
       "0   1  AM General Hummer SUV 2000\n",
       "1   2         Acura RL Sedan 2012\n",
       "2   3         Acura TL Sedan 2012\n",
       "3   4        Acura TL Type-S 2008\n",
       "4   5        Acura TSX Sedan 2012"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class = pd.read_csv('./data/class.csv')\n",
    "df_class.head()\n",
    "# print(df_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_00001.jpg</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_00002.jpg</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_00003.jpg</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_00004.jpg</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_00005.jpg</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          img_file  class\n",
       "0  train_00001.jpg    108\n",
       "1  train_00002.jpg     71\n",
       "2  train_00003.jpg     76\n",
       "3  train_00004.jpg    188\n",
       "4  train_00005.jpg     44"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('./data/train.csv')\n",
    "df_train = df_train[['img_file', 'class']]\n",
    "df_train.replace(196, 0, inplace=True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_file</th>\n",
       "      <th>bbox_x1</th>\n",
       "      <th>bbox_y1</th>\n",
       "      <th>bbox_x2</th>\n",
       "      <th>bbox_y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_00001.jpg</td>\n",
       "      <td>199</td>\n",
       "      <td>184</td>\n",
       "      <td>1116</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_00002.jpg</td>\n",
       "      <td>55</td>\n",
       "      <td>61</td>\n",
       "      <td>480</td>\n",
       "      <td>257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_00003.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>123</td>\n",
       "      <td>602</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_00004.jpg</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>619</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_00005.jpg</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>209</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         img_file  bbox_x1  bbox_y1  bbox_x2  bbox_y2\n",
       "0  test_00001.jpg      199      184     1116      809\n",
       "1  test_00002.jpg       55       61      480      257\n",
       "2  test_00003.jpg       42      123      602      413\n",
       "3  test_00004.jpg       13        8      619      393\n",
       "4  test_00005.jpg        8        9      209       93"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('./data/test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train vs Validation Data split\n",
    "- 신경망의 validation 을 위해 dataset을 분리합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566     train_00567.jpg\n",
      "592     train_00593.jpg\n",
      "3074    train_03075.jpg\n",
      "210     train_00211.jpg\n",
      "7252    train_07253.jpg\n",
      "Name: img_file, dtype: object 566     118\n",
      "592     117\n",
      "3074    172\n",
      "210      79\n",
      "7252    154\n",
      "Name: class, dtype: int64\n",
      "9036    train_09037.jpg\n",
      "6581    train_06582.jpg\n",
      "6541    train_06542.jpg\n",
      "5061    train_05062.jpg\n",
      "3056    train_03057.jpg\n",
      "Name: img_file, dtype: object 9036    151\n",
      "6581     81\n",
      "6541    155\n",
      "5061     76\n",
      "3056    114\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train['img_file'], df_train['class'], stratify=df_train['class'], test_size=0.2, random_state=SEED)\n",
    "print(X_train.head(), y_train.head())\n",
    "print(X_val.head(), y_val.head())\n",
    "\n",
    "X_train = X_train.values\n",
    "X_val = X_val.values\n",
    "y_train = y_train.values\n",
    "y_val = y_val.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['train_00567.jpg', 'train_00593.jpg', 'train_03075.jpg', ...,\n",
       "       'train_02049.jpg', 'train_01605.jpg', 'train_04788.jpg'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7992,)\n",
      "(1998,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Torch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH = './data/train_crop/'\n",
    "TEST_DATA_PATH = './data/test_crop/'\n",
    "\n",
    "class TrainImages(Dataset):\n",
    "    def __init__(self, images, labels, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.images.shape[0]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TRAIN_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    \n",
    "class TestImages(Dataset):\n",
    "    def __init__(self, images, labels, mode=None, transforms=None):\n",
    "        self.images = images\n",
    "        self.laels = labels\n",
    "        self.mode = mode\n",
    "        self.transforms = transforms[self.mode]\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(TEST_DATA_PATH + self.images[idx]).convert(\"RGB\")\n",
    "        image = self.transforms(image)\n",
    "        labels = self.labels[idx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((250, 250)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], \n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((250, 250)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], \n",
    "            [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((250, 250)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            [0.485, 0.456, 0.406], \n",
    "            [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataset = TrainImages(images=X_train, labels=y_train, mode='train', transforms=transform)\n",
    "val_dataset = TrainImages(images=X_val, labels=y_val, mode='val', transforms=transform)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    'train': train_dataloader,\n",
    "    'val': val_dataloader\n",
    "}\n",
    "\n",
    "dataset_sizes = {\n",
    "    'train': len(train_dataset),\n",
    "    'val': len(val_dataset)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "- resnext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_res = models.resnet18(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model_res.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, dataset_sizes, criterion, optimizer, device, epochs=20):\n",
    "    start = time.time()\n",
    "    \n",
    "    num_classes = 196\n",
    "    \n",
    "    best_model_weights = copy.deepcopy(model.state_dict())\n",
    "    best_f1 = 0.0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        print(\"EPOCH {} / {}: \".format(epoch+1, epochs))\n",
    "        print(\"-\" * 10)\n",
    "        \n",
    "        epoch_loss = 0.0\n",
    "        phase = 'train'\n",
    "        \n",
    "        for batch_index, (batch_inputs, batch_labels) in enumerate(dataloaders[phase]):\n",
    "            batch_inputs = batch_inputs.cuda()\n",
    "            batch_labels = batch_labels.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_inputs)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            batch_loss = criterion(outputs, batch_labels)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += batch_loss.item() * batch_inputs.size(0)\n",
    "            if batch_index % 5 == 0:\n",
    "                print(\"EPOCH {} BATCH {}: training batch loss: {}\".format(epoch+1, batch_index+1, batch_loss.item()))\n",
    "            \n",
    "            if batch_index % 10 == 0:\n",
    "                phase = 'val'\n",
    "                val_preds = np.zeros((dataset_sizes['val'], 1))\n",
    "                val_loss = 0.0\n",
    "                with torch.no_grad():\n",
    "                    model.eval()\n",
    "                    for val_batch_index, (val_batch_inputs, val_batch_labels) in enumerate(dataloaders[phase]):\n",
    "                        \n",
    "                        val_batch_inputs = val_batch_inputs.cuda()\n",
    "                        val_batch_labels = val_batch_labels.cuda()\n",
    "                        \n",
    "                        val_outputs = model(val_batch_inputs).detach()\n",
    "                        _, val_batch_preds = torch.max(val_outputs, 1)\n",
    "                        val_batch_loss = criterion(val_outputs, val_batch_labels)\n",
    "                        val_preds[val_batch_index * batch_size: (val_batch_index+1) * batch_size] = val_batch_preds.cpu().view(-1, 1).numpy()\n",
    "                        val_loss += val_batch_loss.item() * val_batch_inputs.size(0)\n",
    "                            \n",
    "                    val_score = f1_score(y_val, val_preds, average='micro')\n",
    "                    print()\n",
    "                    print(\">>>>>>  EPOCH {} BATCH {}: validation score {}\".format(epoch+1, batch_index+1, val_score))\n",
    "                    print()\n",
    "                    if val_score > best_f1:\n",
    "                        best_f1 = val_score\n",
    "                        best_model_weights = copy.deepcopy(model.state_dict())\n",
    "#                         torch.save(model.state_dict(), './model/first_trial/fine_tune/best_model_{}_{}.pt'.format(epoch, batch_index))\n",
    "                        \n",
    "                phase = 'train'\n",
    "                model.train()\n",
    "                \n",
    "        epoch_loss = epoch_loss / dataset_sizes['train']\n",
    "        print(\"EPOCH {}: EPOCH_LOSS: {}\".format(epoch+1, epoch_loss))\n",
    "        \n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    print(\"Training COMPLETED: {:.0f}m {:.0f}s\".format(elapsed_time // 60, elapsed_time % 60))\n",
    "    print(\"BEST VALIDATION F1: {:4f}\".format(best_f1))\n",
    "    \n",
    "    model.load_state_dict(best_model_weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 / 20: \n",
      "----------\n",
      "EPOCH 1 BATCH 1: training batch loss: 5.556825637817383\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 1: validation score 0.011011011011011011\n",
      "\n",
      "EPOCH 1 BATCH 6: training batch loss: 5.04494047164917\n",
      "EPOCH 1 BATCH 11: training batch loss: 4.401520729064941\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 11: validation score 0.01701701701701702\n",
      "\n",
      "EPOCH 1 BATCH 16: training batch loss: 3.9667809009552\n",
      "EPOCH 1 BATCH 21: training batch loss: 3.5828843116760254\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 21: validation score 0.15515515515515516\n",
      "\n",
      "EPOCH 1 BATCH 26: training batch loss: 3.094449043273926\n",
      "EPOCH 1 BATCH 31: training batch loss: 2.7181689739227295\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 31: validation score 0.32682682682682684\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [03:35<1:08:16, 215.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: EPOCH_LOSS: 3.9904703535475172\n",
      "EPOCH 2 / 20: \n",
      "----------\n",
      "EPOCH 2 BATCH 1: training batch loss: 2.252932548522949\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 1: validation score 0.3148148148148148\n",
      "\n",
      "EPOCH 2 BATCH 6: training batch loss: 1.873906135559082\n",
      "EPOCH 2 BATCH 11: training batch loss: 1.6232776641845703\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 11: validation score 0.4744744744744745\n",
      "\n",
      "EPOCH 2 BATCH 16: training batch loss: 1.4923676252365112\n",
      "EPOCH 2 BATCH 21: training batch loss: 1.1947169303894043\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 21: validation score 0.5635635635635635\n",
      "\n",
      "EPOCH 2 BATCH 26: training batch loss: 1.2016472816467285\n",
      "EPOCH 2 BATCH 31: training batch loss: 0.9848882555961609\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 31: validation score 0.6316316316316316\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 2/20 [07:14<1:05:00, 216.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: EPOCH_LOSS: 1.535744501305772\n",
      "EPOCH 3 / 20: \n",
      "----------\n",
      "EPOCH 3 BATCH 1: training batch loss: 0.6440747380256653\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 1: validation score 0.6381381381381381\n",
      "\n",
      "EPOCH 3 BATCH 6: training batch loss: 0.5615177750587463\n",
      "EPOCH 3 BATCH 11: training batch loss: 0.5608423352241516\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 11: validation score 0.6446446446446447\n",
      "\n",
      "EPOCH 3 BATCH 16: training batch loss: 0.43849802017211914\n",
      "EPOCH 3 BATCH 21: training batch loss: 0.4044843018054962\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 21: validation score 0.6841841841841841\n",
      "\n",
      "EPOCH 3 BATCH 26: training batch loss: 0.34807059168815613\n",
      "EPOCH 3 BATCH 31: training batch loss: 0.37168559432029724\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 31: validation score 0.7172172172172172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [10:53<1:01:33, 217.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3: EPOCH_LOSS: 0.4895053960241236\n",
      "EPOCH 4 / 20: \n",
      "----------\n",
      "EPOCH 4 BATCH 1: training batch loss: 0.17194847762584686\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 1: validation score 0.6781781781781782\n",
      "\n",
      "EPOCH 4 BATCH 6: training batch loss: 0.21675606071949005\n",
      "EPOCH 4 BATCH 11: training batch loss: 0.19507914781570435\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 11: validation score 0.6686686686686687\n",
      "\n",
      "EPOCH 4 BATCH 16: training batch loss: 0.1821039915084839\n",
      "EPOCH 4 BATCH 21: training batch loss: 0.1453617811203003\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 21: validation score 0.7697697697697699\n",
      "\n",
      "EPOCH 4 BATCH 26: training batch loss: 0.11732702702283859\n",
      "EPOCH 4 BATCH 31: training batch loss: 0.11001285910606384\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 31: validation score 0.7812812812812813\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 4/20 [14:32<58:05, 217.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4: EPOCH_LOSS: 0.15728480117516713\n",
      "EPOCH 5 / 20: \n",
      "----------\n",
      "EPOCH 5 BATCH 1: training batch loss: 0.04939047247171402\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 1: validation score 0.7542542542542543\n",
      "\n",
      "EPOCH 5 BATCH 6: training batch loss: 0.07152964174747467\n",
      "EPOCH 5 BATCH 11: training batch loss: 0.047735944390296936\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 11: validation score 0.7762762762762763\n",
      "\n",
      "EPOCH 5 BATCH 16: training batch loss: 0.04651375114917755\n",
      "EPOCH 5 BATCH 21: training batch loss: 0.04827103763818741\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 21: validation score 0.7737737737737739\n",
      "\n",
      "EPOCH 5 BATCH 26: training batch loss: 0.03605096414685249\n",
      "EPOCH 5 BATCH 31: training batch loss: 0.04144803434610367\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 31: validation score 0.8053053053053053\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [18:12<54:35, 218.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5: EPOCH_LOSS: 0.05325121010044912\n",
      "EPOCH 6 / 20: \n",
      "----------\n",
      "EPOCH 6 BATCH 1: training batch loss: 0.01777680590748787\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 1: validation score 0.8033033033033034\n",
      "\n",
      "EPOCH 6 BATCH 6: training batch loss: 0.028621939942240715\n",
      "EPOCH 6 BATCH 11: training batch loss: 0.017159976065158844\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 11: validation score 0.8163163163163163\n",
      "\n",
      "EPOCH 6 BATCH 16: training batch loss: 0.015828000381588936\n",
      "EPOCH 6 BATCH 21: training batch loss: 0.027962787076830864\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 21: validation score 0.8278278278278278\n",
      "\n",
      "EPOCH 6 BATCH 26: training batch loss: 0.012633442878723145\n",
      "EPOCH 6 BATCH 31: training batch loss: 0.028347201645374298\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 31: validation score 0.8408408408408409\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [21:51<51:00, 218.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6: EPOCH_LOSS: 0.02046482579445129\n",
      "EPOCH 7 / 20: \n",
      "----------\n",
      "EPOCH 7 BATCH 1: training batch loss: 0.009113723412156105\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 1: validation score 0.8518518518518519\n",
      "\n",
      "EPOCH 7 BATCH 6: training batch loss: 0.007660998031497002\n",
      "EPOCH 7 BATCH 11: training batch loss: 0.007400162518024445\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 11: validation score 0.8573573573573574\n",
      "\n",
      "EPOCH 7 BATCH 16: training batch loss: 0.039520591497421265\n",
      "EPOCH 7 BATCH 21: training batch loss: 0.006520340219140053\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 21: validation score 0.8628628628628628\n",
      "\n",
      "EPOCH 7 BATCH 26: training batch loss: 0.006400039419531822\n",
      "EPOCH 7 BATCH 31: training batch loss: 0.006625950336456299\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 31: validation score 0.8698698698698699\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 7/20 [25:29<47:21, 218.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7: EPOCH_LOSS: 0.009216613719823423\n",
      "EPOCH 8 / 20: \n",
      "----------\n",
      "EPOCH 8 BATCH 1: training batch loss: 0.00529870018362999\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 1: validation score 0.8663663663663663\n",
      "\n",
      "EPOCH 8 BATCH 6: training batch loss: 0.004937482997775078\n",
      "EPOCH 8 BATCH 11: training batch loss: 0.00445716455578804\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 11: validation score 0.8678678678678678\n",
      "\n",
      "EPOCH 8 BATCH 16: training batch loss: 0.004417847841978073\n",
      "EPOCH 8 BATCH 21: training batch loss: 0.004184745252132416\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 21: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 8 BATCH 26: training batch loss: 0.004191633313894272\n",
      "EPOCH 8 BATCH 31: training batch loss: 0.003971368074417114\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 31: validation score 0.8708708708708709\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 8/20 [29:07<43:39, 218.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8: EPOCH_LOSS: 0.004781028499604913\n",
      "EPOCH 9 / 20: \n",
      "----------\n",
      "EPOCH 9 BATCH 1: training batch loss: 0.0037139318883419037\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 1: validation score 0.8688688688688688\n",
      "\n",
      "EPOCH 9 BATCH 6: training batch loss: 0.0033907070755958557\n",
      "EPOCH 9 BATCH 11: training batch loss: 0.0035041458904743195\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 11: validation score 0.8693693693693695\n",
      "\n",
      "EPOCH 9 BATCH 16: training batch loss: 0.0034758523106575012\n",
      "EPOCH 9 BATCH 21: training batch loss: 0.0030763372778892517\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 21: validation score 0.8688688688688688\n",
      "\n",
      "EPOCH 9 BATCH 26: training batch loss: 0.0032164156436920166\n",
      "EPOCH 9 BATCH 31: training batch loss: 0.0028019100427627563\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 31: validation score 0.8718718718718719\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [32:46<40:04, 218.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9: EPOCH_LOSS: 0.0032836719676181004\n",
      "EPOCH 10 / 20: \n",
      "----------\n",
      "EPOCH 10 BATCH 1: training batch loss: 0.0025871433317661285\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 1: validation score 0.8718718718718719\n",
      "\n",
      "EPOCH 10 BATCH 6: training batch loss: 0.0024315454065799713\n",
      "EPOCH 10 BATCH 11: training batch loss: 0.0027035772800445557\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 11: validation score 0.8743743743743744\n",
      "\n",
      "EPOCH 10 BATCH 16: training batch loss: 0.0027777813374996185\n",
      "EPOCH 10 BATCH 21: training batch loss: 0.002689346671104431\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 21: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 10 BATCH 26: training batch loss: 0.002537999302148819\n",
      "EPOCH 10 BATCH 31: training batch loss: 0.0027081966400146484\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 31: validation score 0.8778778778778779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 10/20 [36:25<36:24, 218.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10: EPOCH_LOSS: 0.002644904143828619\n",
      "EPOCH 11 / 20: \n",
      "----------\n",
      "EPOCH 11 BATCH 1: training batch loss: 0.0021275468170642853\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 1: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 11 BATCH 6: training batch loss: 0.0024839192628860474\n",
      "EPOCH 11 BATCH 11: training batch loss: 0.0022313855588436127\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 11: validation score 0.8753753753753754\n",
      "\n",
      "EPOCH 11 BATCH 16: training batch loss: 0.0020842961966991425\n",
      "EPOCH 11 BATCH 21: training batch loss: 0.002110622823238373\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 21: validation score 0.8738738738738738\n",
      "\n",
      "EPOCH 11 BATCH 26: training batch loss: 0.0024727769196033478\n",
      "EPOCH 11 BATCH 31: training batch loss: 0.0022511854767799377\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 31: validation score 0.8768768768768769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [40:05<32:50, 218.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11: EPOCH_LOSS: 0.0022431016578949668\n",
      "EPOCH 12 / 20: \n",
      "----------\n",
      "EPOCH 12 BATCH 1: training batch loss: 0.0019358843564987183\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 1: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 12 BATCH 6: training batch loss: 0.001895911991596222\n",
      "EPOCH 12 BATCH 11: training batch loss: 0.0018979758024215698\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 11: validation score 0.8738738738738738\n",
      "\n",
      "EPOCH 12 BATCH 16: training batch loss: 0.001804158091545105\n",
      "EPOCH 12 BATCH 21: training batch loss: 0.002009693533182144\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 21: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 12 BATCH 26: training batch loss: 0.0017952285706996918\n",
      "EPOCH 12 BATCH 31: training batch loss: 0.001892082393169403\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 31: validation score 0.8768768768768769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 12/20 [43:45<29:14, 219.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12: EPOCH_LOSS: 0.0019175499163519543\n",
      "EPOCH 13 / 20: \n",
      "----------\n",
      "EPOCH 13 BATCH 1: training batch loss: 0.0017303302884101868\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 1: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 13 BATCH 6: training batch loss: 0.0016671381890773773\n",
      "EPOCH 13 BATCH 11: training batch loss: 0.0016333498060703278\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 11: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 13 BATCH 16: training batch loss: 0.0019605159759521484\n",
      "EPOCH 13 BATCH 21: training batch loss: 0.0016023926436901093\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 21: validation score 0.8743743743743744\n",
      "\n",
      "EPOCH 13 BATCH 26: training batch loss: 0.0015513822436332703\n",
      "EPOCH 13 BATCH 31: training batch loss: 0.0016402974724769592\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 31: validation score 0.8753753753753754\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [47:24<25:34, 219.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13: EPOCH_LOSS: 0.001694159942806826\n",
      "EPOCH 14 / 20: \n",
      "----------\n",
      "EPOCH 14 BATCH 1: training batch loss: 0.0016076378524303436\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 1: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 14 BATCH 6: training batch loss: 0.0014940351247787476\n",
      "EPOCH 14 BATCH 11: training batch loss: 0.001475319266319275\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 11: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 14 BATCH 16: training batch loss: 0.0015341416001319885\n",
      "EPOCH 14 BATCH 21: training batch loss: 0.0014026351273059845\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 21: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 14 BATCH 26: training batch loss: 0.0016283243894577026\n",
      "EPOCH 14 BATCH 31: training batch loss: 0.0014258809387683868\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 31: validation score 0.8763763763763763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [51:02<21:54, 219.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14: EPOCH_LOSS: 0.0014880233347785096\n",
      "EPOCH 15 / 20: \n",
      "----------\n",
      "EPOCH 15 BATCH 1: training batch loss: 0.001422695815563202\n",
      "\n",
      ">>>>>>  EPOCH 15 BATCH 1: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 15 BATCH 6: training batch loss: 0.001368064433336258\n",
      "EPOCH 15 BATCH 11: training batch loss: 0.0013185366988182068\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-298fc68466cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-f26b0bddc670>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, criterion, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mval_batch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mval_batch_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch_labels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                         \u001b[0mval_batch_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_batch_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-e8acaaad8291>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    932\u001b[0m         \"\"\"\n\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_res.to(device)\n",
    "train_model(model_res, dataloaders, dataset_sizes, criterion, optimizer, device, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=196, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_res = models.resnet18(pretrained=True, progress=False)\n",
    "num_features = model_res.fc.in_features\n",
    "model_res.fc = nn.Linear(num_features, 196)\n",
    "model_res.load_state_dict(torch.load('./model/best_model_9_30.pt'))\n",
    "model_res.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1 / 100: \n",
      "----------\n",
      "EPOCH 1 BATCH 1: training batch loss: 0.0024226494133472443\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 1: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 1 BATCH 6: training batch loss: 0.0022922679781913757\n",
      "EPOCH 1 BATCH 11: training batch loss: 0.0025090686976909637\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 11: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 1 BATCH 16: training batch loss: 0.002293657511472702\n",
      "EPOCH 1 BATCH 21: training batch loss: 0.002331729978322983\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 21: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 1 BATCH 26: training batch loss: 0.002421341836452484\n",
      "EPOCH 1 BATCH 31: training batch loss: 0.002515047788619995\n",
      "\n",
      ">>>>>>  EPOCH 1 BATCH 31: validation score 0.8768768768768769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  1%|          | 1/100 [03:39<6:01:32, 219.12s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1: EPOCH_LOSS: 0.0023080417231467363\n",
      "EPOCH 2 / 100: \n",
      "----------\n",
      "EPOCH 2 BATCH 1: training batch loss: 0.0022991150617599487\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 1: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 2 BATCH 6: training batch loss: 0.0022609271109104156\n",
      "EPOCH 2 BATCH 11: training batch loss: 0.0021486952900886536\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 11: validation score 0.8778778778778779\n",
      "\n",
      "EPOCH 2 BATCH 16: training batch loss: 0.0022125840187072754\n",
      "EPOCH 2 BATCH 21: training batch loss: 0.002396300435066223\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 21: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 2 BATCH 26: training batch loss: 0.0021733902394771576\n",
      "EPOCH 2 BATCH 31: training batch loss: 0.002283640205860138\n",
      "\n",
      ">>>>>>  EPOCH 2 BATCH 31: validation score 0.8778778778778779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 2/100 [07:19<5:58:44, 219.64s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 2: EPOCH_LOSS: 0.0023148440500932025\n",
      "EPOCH 3 / 100: \n",
      "----------\n",
      "EPOCH 3 BATCH 1: training batch loss: 0.0021152272820472717\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 1: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 3 BATCH 6: training batch loss: 0.0022590123116970062\n",
      "EPOCH 3 BATCH 11: training batch loss: 0.002402428537607193\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 11: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 3 BATCH 16: training batch loss: 0.0024523548781871796\n",
      "EPOCH 3 BATCH 21: training batch loss: 0.0025380849838256836\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 21: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 3 BATCH 26: training batch loss: 0.00246988981962204\n",
      "EPOCH 3 BATCH 31: training batch loss: 0.002333134412765503\n",
      "\n",
      ">>>>>>  EPOCH 3 BATCH 31: validation score 0.8748748748748749\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 3/100 [11:01<5:55:46, 220.07s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 3: EPOCH_LOSS: 0.00231114020934692\n",
      "EPOCH 4 / 100: \n",
      "----------\n",
      "EPOCH 4 BATCH 1: training batch loss: 0.0023648515343666077\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 1: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 4 BATCH 6: training batch loss: 0.0023350119590759277\n",
      "EPOCH 4 BATCH 11: training batch loss: 0.0023581460118293762\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 11: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 4 BATCH 16: training batch loss: 0.002348918467760086\n",
      "EPOCH 4 BATCH 21: training batch loss: 0.002380676567554474\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 21: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 4 BATCH 26: training batch loss: 0.0022438615560531616\n",
      "EPOCH 4 BATCH 31: training batch loss: 0.0022866614162921906\n",
      "\n",
      ">>>>>>  EPOCH 4 BATCH 31: validation score 0.8773773773773774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 4/100 [14:39<5:51:10, 219.49s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 4: EPOCH_LOSS: 0.0023277913254254067\n",
      "EPOCH 5 / 100: \n",
      "----------\n",
      "EPOCH 5 BATCH 1: training batch loss: 0.002347756177186966\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 1: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 5 BATCH 6: training batch loss: 0.0022527240216732025\n",
      "EPOCH 5 BATCH 11: training batch loss: 0.002324022352695465\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 11: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 5 BATCH 16: training batch loss: 0.0023034103214740753\n",
      "EPOCH 5 BATCH 21: training batch loss: 0.0022068992257118225\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 21: validation score 0.8753753753753754\n",
      "\n",
      "EPOCH 5 BATCH 26: training batch loss: 0.0025487877428531647\n",
      "EPOCH 5 BATCH 31: training batch loss: 0.002287343144416809\n",
      "\n",
      ">>>>>>  EPOCH 5 BATCH 31: validation score 0.875875875875876\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 5/100 [18:18<5:47:21, 219.38s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 5: EPOCH_LOSS: 0.002299661392922158\n",
      "EPOCH 6 / 100: \n",
      "----------\n",
      "EPOCH 6 BATCH 1: training batch loss: 0.0022866949439048767\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 1: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 6 BATCH 6: training batch loss: 0.0022495463490486145\n",
      "EPOCH 6 BATCH 11: training batch loss: 0.002534877508878708\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 11: validation score 0.8753753753753754\n",
      "\n",
      "EPOCH 6 BATCH 16: training batch loss: 0.002323053777217865\n",
      "EPOCH 6 BATCH 21: training batch loss: 0.0020553842186927795\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 21: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 6 BATCH 26: training batch loss: 0.0023522302508354187\n",
      "EPOCH 6 BATCH 31: training batch loss: 0.002381611615419388\n",
      "\n",
      ">>>>>>  EPOCH 6 BATCH 31: validation score 0.8763763763763763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 6/100 [21:59<5:44:45, 220.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 6: EPOCH_LOSS: 0.0023077031871578\n",
      "EPOCH 7 / 100: \n",
      "----------\n",
      "EPOCH 7 BATCH 1: training batch loss: 0.002179119735956192\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 1: validation score 0.8743743743743744\n",
      "\n",
      "EPOCH 7 BATCH 6: training batch loss: 0.002111438661813736\n",
      "EPOCH 7 BATCH 11: training batch loss: 0.0022977888584136963\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 11: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 7 BATCH 16: training batch loss: 0.002377428114414215\n",
      "EPOCH 7 BATCH 21: training batch loss: 0.0023704804480075836\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 21: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 7 BATCH 26: training batch loss: 0.0023864805698394775\n",
      "EPOCH 7 BATCH 31: training batch loss: 0.002191733568906784\n",
      "\n",
      ">>>>>>  EPOCH 7 BATCH 31: validation score 0.8778778778778779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  7%|▋         | 7/100 [25:41<5:41:36, 220.39s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 7: EPOCH_LOSS: 0.002322631615873154\n",
      "EPOCH 8 / 100: \n",
      "----------\n",
      "EPOCH 8 BATCH 1: training batch loss: 0.0025483593344688416\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 1: validation score 0.8753753753753754\n",
      "\n",
      "EPOCH 8 BATCH 6: training batch loss: 0.0023077428340911865\n",
      "EPOCH 8 BATCH 11: training batch loss: 0.002176627516746521\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 11: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 8 BATCH 16: training batch loss: 0.0023509562015533447\n",
      "EPOCH 8 BATCH 21: training batch loss: 0.0019525401294231415\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 21: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 8 BATCH 26: training batch loss: 0.002307586371898651\n",
      "EPOCH 8 BATCH 31: training batch loss: 0.002043049782514572\n",
      "\n",
      ">>>>>>  EPOCH 8 BATCH 31: validation score 0.8773773773773774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  8%|▊         | 8/100 [29:22<5:38:13, 220.58s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 8: EPOCH_LOSS: 0.002320223026214404\n",
      "EPOCH 9 / 100: \n",
      "----------\n",
      "EPOCH 9 BATCH 1: training batch loss: 0.002436768263578415\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 1: validation score 0.8768768768768769\n",
      "\n",
      "EPOCH 9 BATCH 6: training batch loss: 0.0023983344435691833\n",
      "EPOCH 9 BATCH 11: training batch loss: 0.0024052858352661133\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 11: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 9 BATCH 16: training batch loss: 0.002301398664712906\n",
      "EPOCH 9 BATCH 21: training batch loss: 0.002397451549768448\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 21: validation score 0.8783783783783784\n",
      "\n",
      "EPOCH 9 BATCH 26: training batch loss: 0.00204317644238472\n",
      "EPOCH 9 BATCH 31: training batch loss: 0.0022291354835033417\n",
      "\n",
      ">>>>>>  EPOCH 9 BATCH 31: validation score 0.8768768768768769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  9%|▉         | 9/100 [33:03<5:34:41, 220.68s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 9: EPOCH_LOSS: 0.0023084252446263403\n",
      "EPOCH 10 / 100: \n",
      "----------\n",
      "EPOCH 10 BATCH 1: training batch loss: 0.002204727381467819\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 1: validation score 0.8778778778778779\n",
      "\n",
      "EPOCH 10 BATCH 6: training batch loss: 0.0022401735186576843\n",
      "EPOCH 10 BATCH 11: training batch loss: 0.002146150916814804\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 11: validation score 0.8753753753753754\n",
      "\n",
      "EPOCH 10 BATCH 16: training batch loss: 0.0021053776144981384\n",
      "EPOCH 10 BATCH 21: training batch loss: 0.0023716650903224945\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 21: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 10 BATCH 26: training batch loss: 0.0023864805698394775\n",
      "EPOCH 10 BATCH 31: training batch loss: 0.0023332126438617706\n",
      "\n",
      ">>>>>>  EPOCH 10 BATCH 31: validation score 0.8763763763763763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 10%|█         | 10/100 [36:43<5:30:56, 220.63s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 10: EPOCH_LOSS: 0.0022841166929566527\n",
      "EPOCH 11 / 100: \n",
      "----------\n",
      "EPOCH 11 BATCH 1: training batch loss: 0.002184908837080002\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 1: validation score 0.8748748748748749\n",
      "\n",
      "EPOCH 11 BATCH 6: training batch loss: 0.0024826526641845703\n",
      "EPOCH 11 BATCH 11: training batch loss: 0.0024357065558433533\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 11: validation score 0.8783783783783784\n",
      "\n",
      "EPOCH 11 BATCH 16: training batch loss: 0.0021926648914813995\n",
      "EPOCH 11 BATCH 21: training batch loss: 0.0023105107247829437\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 21: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 11 BATCH 26: training batch loss: 0.0021863430738449097\n",
      "EPOCH 11 BATCH 31: training batch loss: 0.0023039132356643677\n",
      "\n",
      ">>>>>>  EPOCH 11 BATCH 31: validation score 0.8778778778778779\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 11%|█         | 11/100 [40:21<5:25:52, 219.69s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 11: EPOCH_LOSS: 0.0022994168871851477\n",
      "EPOCH 12 / 100: \n",
      "----------\n",
      "EPOCH 12 BATCH 1: training batch loss: 0.0023618489503860474\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 1: validation score 0.8763763763763763\n",
      "\n",
      "EPOCH 12 BATCH 6: training batch loss: 0.0022510401904582977\n",
      "EPOCH 12 BATCH 11: training batch loss: 0.002332352101802826\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 11: validation score 0.8778778778778779\n",
      "\n",
      "EPOCH 12 BATCH 16: training batch loss: 0.002359669655561447\n",
      "EPOCH 12 BATCH 21: training batch loss: 0.0023058615624904633\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 21: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 12 BATCH 26: training batch loss: 0.0021202415227890015\n",
      "EPOCH 12 BATCH 31: training batch loss: 0.0021897144615650177\n",
      "\n",
      ">>>>>>  EPOCH 12 BATCH 31: validation score 0.8768768768768769\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 12%|█▏        | 12/100 [44:01<5:22:27, 219.86s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 12: EPOCH_LOSS: 0.002290084078727109\n",
      "EPOCH 13 / 100: \n",
      "----------\n",
      "EPOCH 13 BATCH 1: training batch loss: 0.002298075705766678\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 1: validation score 0.8778778778778779\n",
      "\n",
      "EPOCH 13 BATCH 6: training batch loss: 0.0023619085550308228\n",
      "EPOCH 13 BATCH 11: training batch loss: 0.002280961722135544\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 11: validation score 0.8788788788788788\n",
      "\n",
      "EPOCH 13 BATCH 16: training batch loss: 0.0022147931158542633\n",
      "EPOCH 13 BATCH 21: training batch loss: 0.002361152321100235\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 21: validation score 0.8748748748748749\n",
      "\n",
      "EPOCH 13 BATCH 26: training batch loss: 0.0021268464624881744\n",
      "EPOCH 13 BATCH 31: training batch loss: 0.0023382343351840973\n",
      "\n",
      ">>>>>>  EPOCH 13 BATCH 31: validation score 0.8753753753753754\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 13%|█▎        | 13/100 [47:41<5:19:00, 220.00s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 13: EPOCH_LOSS: 0.002298501758343047\n",
      "EPOCH 14 / 100: \n",
      "----------\n",
      "EPOCH 14 BATCH 1: training batch loss: 0.002193272113800049\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 1: validation score 0.8743743743743744\n",
      "\n",
      "EPOCH 14 BATCH 6: training batch loss: 0.0022624097764492035\n",
      "EPOCH 14 BATCH 11: training batch loss: 0.002322610467672348\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 11: validation score 0.8753753753753754\n",
      "\n",
      "EPOCH 14 BATCH 16: training batch loss: 0.0022866465151309967\n",
      "EPOCH 14 BATCH 21: training batch loss: 0.0022300034761428833\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 21: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 14 BATCH 26: training batch loss: 0.002128433436155319\n",
      "EPOCH 14 BATCH 31: training batch loss: 0.002163410186767578\n",
      "\n",
      ">>>>>>  EPOCH 14 BATCH 31: validation score 0.8773773773773774\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 14%|█▍        | 14/100 [51:22<5:15:53, 220.38s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 14: EPOCH_LOSS: 0.002263395517068851\n",
      "EPOCH 15 / 100: \n",
      "----------\n",
      "EPOCH 15 BATCH 1: training batch loss: 0.0021770410239696503\n",
      "\n",
      ">>>>>>  EPOCH 15 BATCH 1: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 15 BATCH 6: training batch loss: 0.002538807690143585\n",
      "EPOCH 15 BATCH 11: training batch loss: 0.0022925473749637604\n",
      "\n",
      ">>>>>>  EPOCH 15 BATCH 11: validation score 0.875875875875876\n",
      "\n",
      "EPOCH 15 BATCH 16: training batch loss: 0.002354852855205536\n",
      "EPOCH 15 BATCH 21: training batch loss: 0.0023666396737098694\n",
      "\n",
      ">>>>>>  EPOCH 15 BATCH 21: validation score 0.8788788788788788\n",
      "\n",
      "EPOCH 15 BATCH 26: training batch loss: 0.0022348836064338684\n",
      "EPOCH 15 BATCH 31: training batch loss: 0.0023312829434871674\n",
      "\n",
      ">>>>>>  EPOCH 15 BATCH 31: validation score 0.8763763763763763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 15%|█▌        | 15/100 [55:03<5:12:14, 220.40s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 15: EPOCH_LOSS: 0.002290520105730962\n",
      "EPOCH 16 / 100: \n",
      "----------\n",
      "EPOCH 16 BATCH 1: training batch loss: 0.0024439357221126556\n",
      "\n",
      ">>>>>>  EPOCH 16 BATCH 1: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 16 BATCH 6: training batch loss: 0.0022276416420936584\n",
      "EPOCH 16 BATCH 11: training batch loss: 0.002574838697910309\n",
      "\n",
      ">>>>>>  EPOCH 16 BATCH 11: validation score 0.8783783783783784\n",
      "\n",
      "EPOCH 16 BATCH 16: training batch loss: 0.0022207386791706085\n",
      "EPOCH 16 BATCH 21: training batch loss: 0.0021018274128437042\n",
      "\n",
      ">>>>>>  EPOCH 16 BATCH 21: validation score 0.8778778778778779\n",
      "\n",
      "EPOCH 16 BATCH 26: training batch loss: 0.0023655779659748077\n",
      "EPOCH 16 BATCH 31: training batch loss: 0.002298180013895035\n",
      "\n",
      ">>>>>>  EPOCH 16 BATCH 31: validation score 0.8763763763763763\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      " 16%|█▌        | 16/100 [58:42<5:08:04, 220.06s/it]\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 16: EPOCH_LOSS: 0.002284391745421532\n",
      "EPOCH 17 / 100: \n",
      "----------\n",
      "EPOCH 17 BATCH 1: training batch loss: 0.0022891834378242493\n",
      "\n",
      ">>>>>>  EPOCH 17 BATCH 1: validation score 0.8773773773773774\n",
      "\n",
      "EPOCH 17 BATCH 6: training batch loss: 0.002269543707370758\n",
      "EPOCH 17 BATCH 11: training batch loss: 0.002225469797849655\n",
      "\n",
      ">>>>>>  EPOCH 17 BATCH 11: validation score 0.8773773773773774\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-1c49afeb2b9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0000001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-e6437338c724>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloaders, dataset_sizes, criterion, optimizer, device, epochs)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;31m#             _, preds = torch.max(outputs, 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0midentity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    336\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    337\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 338\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model_res.parameters(), lr=0.0000001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_model(model_res, dataloaders, dataset_sizes, criterion, optimizer, device, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
